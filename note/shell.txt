
https://www.gnu.org/software/bash/manual/bash.html#Redirections    Bash Reference Manual
https://github.com/khwajaimran/Linux/blob/master/Learning%20the%20Bash%20Shell%2C%202nd%20Edition%20-%20Cameron%20Newham%20%26%20Bill%20Rosenblatt.pdf  Learning the Bash Shell, 2nd Edition
https://github.com/Ricky-Wilson/Programming-books/blob/master/PDF/Learning%20the%20bash%20Shell%2C%203rd%20Edition.pdf Learning the bash Shell, 3rd Edition.pdf
http://bbs.chinaunix.net/forum.php?mod=viewthread&tid=218853&page=1&authorid=7696299  shell 十三問







shell命令行快捷键
移动光标
ctrl + a   # 命令行中光标定位行头 同 home 键
ctrl + e   # 命令行中光标定位行尾 同 end 键
Ctrl + b   # 左移一个字符
Ctrl + f   # 右移一个字符
Alt + b    # 左移一个单词  同  Esc + b 同 ctrl + 左键
Alt + f    # 右移一个单词  同  Esc + f 同 ctrl + 右键
Ctrl + xx  # 在命令行首和光标之间移动

编辑命令
Ctrl + h   # 删除光标左边的字符
Ctrl + d   # 删除光标右边的字符（注意       当前命令行没有任何字符时，会注销系统或结束终端）
ctrl + u   # 删除当前光标左边的所有字符 不含当前光标字符
ctrl + k   # 删除当前光标右边所有字符 含当前光标字符
Ctrl + w   # 删除光标左边的单词（空格隔开） 不含当前光标字符
Alt + d    # 删除光标右面的单词 含当前光标字符
Esc + d    # 由光标位置开始，删除单词，直到该单词结束  含当前光标字符
Ctrl + y   # 粘贴之前删除的内容到光标后
Ctrl + _   # 回复之前的状态。撤销操作。
Alt + .    # 使用上一条命令的最后一个参数
Ctrl + a + Ctrl + k 或 Ctrl + e + Ctrl + u 或 Ctrl + k + Ctrl + u 组合可删除整行。

Alt + c    # 光标处字符更改为大写字母 并跳到单词后
Alt + u    # 从光标处到单词尾全部更改为全部大写字母 并跳到单词后
Alt + l    # 从光标处到单词尾全部更改为全部小写字母 并跳到单词后
Ctrl + t   # 交换光标处和之前的字符
Alt + t    # 交换光标处和之前的单词
Alt + Backspace       与 Ctrl + w 相同，分隔符有些差别。

控制命令
Ctrl + l   # 清屏 只是向下滚屏 clear命令真正清空
Ctrl + o   # 执行当前命令，并选择上一条命令
Ctrl + s   # 暂停屏幕输出
Ctrl + q   # 恢复屏幕输出
Ctrl + c   # 终止命令
Ctrl + z   # 挂起命令 若重新放回前台 则 fg
Ctrl + d   # 通常代表 键盘输入结束(End Of File, EOF 戒 End OfInput)的意思；也可以用来取代exit
ctrl + m   # Enter
Tab        # 命令补全 和 档案补齐 的功能
shift + Page UP/Page Down # 翻屏

查找历史命令
Ctrl + r   # 逆向搜索命令历史 随着输入会显示历史命令中的一条匹配命令，Enter执行匹配命令；ESC在命令行显示而不执行匹配命令
Ctrl + g   # 从历史搜索模式（Ctrl – r）退出
Ctrl + p   # 显示当前命令的上一条历史命令
Ctrl + n   # 显示当前命令的下一条历史命令
Alt + .    # 使用上一条命令的最后一个参数

Bang (!) 命令
!!         # 执行上一条命令
!blah      # 执行最近的以 blah 开头的命令，如 !ls
!blah:p    # 仅打印最近的以 blah 开头的命令，而不执行
!$         # 上一条命令的最后一个参数，与 Alt + . 相同
!$:p       # 打印输出 !$ 的内容
!*         # 上一条命令的所有参数
!*:p       # 打印输出 !* 的内容
^blah      # 删除上一条命令中的 blah
^blah^foo  # 将上一条命令中的 blah 替换为 foo 并执行
^blah^foo^ # 将上一条命令中所有的 blah 都替换为 foo 并执行
!-n        # 执行倒数第n条命令，!-1 执行上一条命令， !-5 执行倒数第5条命令 
!n         # 执行第n条命令，!681 执行第681条命令

重复执行操作动作
Esc + 操作次数 操作动作    #指定操作次数，重复执行指定的操作。



shell部分特殊符号
**   # 次方运算 如 let "sus=2**3"  echo $sus -> 8     echo $((3**3)) -> 27
:    # 内置命令 啥也不做，只起到占位符的作用 如在写脚本时，语法结构需要，可用:来做占位符，否则执行报错。
       如 if [ "today" == "2011-08-29" ]; then  : ;  else  : ;  fi
-    # 在管线命令中，替代stdout与stdin
       如 tar -cvf - /home/ | tar -xvf - -C /tmp/  # 将/home打包，打包数据传送到stdout -，通过管道作为后面指令的stdin -




stty -a # 终端机的环境设置 列出所有的按键与按键内容
  intr    # ^C(同 ctrl+c) 送出一个 interrupt 中断信号给目前正在 run 的程序
  quit    # ^\ 送出一个 quit 信号给目前正在 run 的程序
  erase   # ^H 向后删除字符
  kill    # ^U 删除在目前指令列上的所有文字
  eof     # ^D End of file 的意思，代表「结束输入」
  start   # ^Q 在某个程序停止后，重新启动它的 output
  stop    # ^S 停止目前屏幕的输出
  susp    # ^Z 送出一个 terminal stop 的喜好给正在 run 的程序
  注 在windows ^S保存，在Linux用vim时，^S 整个画面死锁，因为^S 是stop功能，停止目前屏幕的输出了，恢复是 start，^Q

set [-/+][uvCHhmBx]   # bash 还有自己的一些终端机设置 -开启选项 +关闭选项
  u # 预设不启用。若启用后，当使用未设置变量时，会显示错误信息
  v # 预设不启用。若启用后，在信息被输出前，会先显示信息的原始内容
  x # 预设不启用。若启用后，在指令被执行前，会显示指令内容（前面有 ++ 符号）
  h # 预设启用。与历史命令有关
  H # 预设启用。与历史命令有关
  m # 预设启用。与工作管理有关
  B # 预设启用。与括号[] 的作用有关
  C # 预设不启用。若使用 > 等，则若文件存在时，该文件不会被覆盖
  如 set -u  echo $undefvar 则报错    set +u  echo $undefvar 不报错
     set -x  echo $PATH   #要输出的指令都会被先打印到屏幕上，前面会多出 + 号
echo $-     # 显示目前所有的 set 设置

/etc/inputrc 与 /etc/DIR_COLORS* 与 /usr/share/terminfo/*   # 也都是与终端机有关的环境配置文件



history              # 列出目前内存内的所有 history 记忆
history [n]          # n 列出最近n条命令
history [-c]         # -c 将目前的shell中的所有history内容全部消除
history [-raw] file  # -a 将当前会话的历史行追加到历史文件中，不指定file则默认写入~/.bash_history  -r 读取历史文件并将内容追加到历史列表中  -w 将当前历史强制写入到历史文件中
history按序号记录，无法记录指令下达时间。
bash登录，系统主动读取~/.bash_history；bash退出，系统将内存记录更新到~/.bash_history，最大存储最后HISTSIZE条
多重登录时，后推出的bash历史记录若大于1000，会覆盖前面先推出的的





shell 已经成为UNIX标准的一部分，主要分为两大主流
  sh                             由Stephen Bourne开发
          burne shell (sh)
          burne again shell (bash)
  csh
          c shell (csh)     由Bill Joy开发
          tc shell (tcsh)
          korn shell (ksh)  由David Korn开发


shell都有相同的目的       在UNIX下为用户提供一个界面。为了达到这个目标，shell都提供了相同的基本功能
命令行解释功能 启动程序 输入输出重定向 管道连接 文件名置换 变量维护 环境控制 shell编程


/etc/issue   # 进站信息 在tty1~tty6登录时顶部显示的信息,而不是登录后显示的信息  root身份修改
man issue 中查看到 agetty ，再 man agetty 得到如下的信息
  \d # 本地端时间的日期
  \l # 显示第几个终端机接口
  \m # 显示硬件的等级（i386、i486、i586...）
  \n # 显示主机的网络名称
  \O # 显示 domain name
  \r # 操作系统的版本（相当于 uname -r）
  \t # 显示本地端时间的时间
  \S # 操作系统的名称
  \v # 操作系统的版本

/etc/update-motd.d/ # ubuntu 户登录后会自动加载此目录下的shell脚本，包含欢迎信息 文件名数字开头, 数字越小越先加载
/etc/motd           # centos 欢迎信息


当完成系统登入(login)，就取得一个互动模式的 shell ，也称为 login shell 或 primary shell。
若从行程(process)角度来说，我们在 shell 下的命令，均是 shell 所产生的子行程。称之为 fork 。
如果是执行脚本(shell script)的话，脚本中的命令则是由另外一个非互动模式的子 shell (sub shell)來执行的。
也就是 primary shell 产生 sub shell 的行程，sub shell 再产生 script 中所有命令的行程。


Shell 是一个程序，一般都是放在 /bin 或 /usr/bin 目录下
[username@host directory]$    # Linux Shell 默认命令提示符  root下为 #
/etc/shells    # 记录当前 Linux 系统可用的 Shell
echo $SHELL    # 查看系统默认shell

一个标准的shell命令行格式为       command-name options argument
command-name查找优先级       指明路径的外部命令  命令別名(alias)  函数(function)  shell內建命令(built-in)  $PATH之下的外部命令

shell 下每个 command 或 function，结束时都会返回父行程一个值，为 return value(RV) 。可用 $? 查看最新的一个。
RV 取值范围 0-255，可有由程式(或 script)的作者自行定义
  script 中，用 exit RV 指定其值，若没指定，在结束时以最后一道命令之 RV 为其值。
  function 中，用 return RV 来代替 exit RV 即可。
RV 的作用，是用来判断行程的退出状态(exit status)，只有两种
  0     为"真"( true )
  非 0  为"假"( false )

如 ls exist.file ; $ echo $?   ->  0       # exist.file 存在
   ls no.file    ; $ echo $?   ->  1       # no.file  不存在



Linux命令_多条命令执行 如下是分隔符
1. ;  各命令的执行结果 不会影响其它命令的执行 各个命令都会执行 但不保证每个命令都执行成功 如:ls;pwd
2. && 前面命令执行成功 即 $? == 0 才会去执行后面的命令 如:ls&&pwd
3. || 前面命令执行失败 即 $? != 0 才会去执行后面的命令 如:lsa||pwd  lsa没有这个
4. |  命令行中的为匿名管道 将一个命令输出导向另一个命令输入 流水线处理文本流 如:env|grep LANG


Linux命令短格式选项和长格式选项
  短格式选项是长格式选项的简写，用一个减号 - 和一个字母表示，例如 ls -l
  长格式选项是完整的英文单词，用两个减号 -- 和一个单词表示，例如 ls --all
  一般情况下，短格式选项是长格式选项的缩写，也就是一个短格式选项会有对应的长格式选项。当然也有例外

linux命令行如何换行,一行命令太长,看的不清晰    在行未  \ + ENTER 就可以实现换行


ls -l | while read line ; do echo $line; done    #多行命令
或
ls -l | while read line
do
 echo $line
done



bash命令 – 命令解释器
bash [参数] 文件名    # -c 从字符串中读入命令 -i 使用交互式模式 -n 不执行 仅检查脚本是否正确 -x 显示执行过程详细信息 -v 执行脚本前，先将其内容输出到屏幕上 --help 显示帮助信息 --version 显示版本信息
bash -n File.sh # 检查脚本语法是否正确
bash -x File.sh # 执行脚本文件并输出执行过程信息
bash -c -x 'echo " 123 124" | grep 1' # 执行命令 并显示详细过程
+ echo ' 123 124'
+ grep 1
 123 124



Shell 通过 PS1 和 PS2 这两个环境变量来控制提示符的格式
PS1="[\t][\u]\$ "     # 修改PS1则临时生效  添加至.bashrc则永久生效  添加至/etc/profile 所有用户生效

# Windows上永久修改GitBash中的相应变量
cd git_install_folder/Git/etc    #进行入安装Git的目录中的etc/目录下。
vim bash.bashrc                  # 在 bash.bashrc 文件的末尾添加如下命令
export PS1='\[\e[36;1m\]jeffxu@Coding:\[\e[33;1m\]\w\[\e[35m\]\$\[\e[0m\]

PS1变量颜色格式 最好将以下的包含在 \[  \] 之内
\e[F;B;Cm     # 字体颜色设置  \e[为颜色提示开始  F为字体颜色 30-37  B为字体背景颜色或控制 C为控制字符
\e[0m         # 通知终端将颜色设置重置为默认，否则字体格式会一直延续下去。 同 \e[m
\e[Xm         # 只有一项 X可取值 F B C
\e[F1;F2m     # 2个F值则F2会替换掉F1  对B类似 不过对于控制字符可同时起作用 如 \e[4;5m 下划线加闪烁
\e[B;F;C;Fm   # B F C顺序随意 因为他们的数值不冲突
a\e]31mx\e[mz # \e] 会忽略掉会面的一切 直到  \e[m 或 \a \r \n 出现 暂称之为中断
a\e]x         # 若没有中断 \e] shell可能会出现不显示输入 排序错乱等现象
a\[z          # \[ 或 \] 只出现了一部分 测试没啥问题 最好能补全

F      B     颜色         C        控制的作用
30     40    黑色         0        使设置的颜色无效(OFF)
31     41    红色         1        高亮显示
32     42    绿色         4        underline
33     43    黄色         5        闪烁
34     44    蓝色         7        反白显示 反显
35     45    紫红         8        不可见  消隐
36     46    青蓝
37     47    白色

\a     铃声字符 同\007
\d     格式为“日 月 年”的日期
\e     ASCII 转义字符 同\033
\h     本地主机名
\H     完全合格的限定域主机名
\j     shell 当前管理的作业数
\1     shell 终端设备名的基本名称
\n     ASCII 换行字符
\r     ASCII 回车
\s     shell 的名称
\t     格式为“小时:分钟:秒”的24小时制的当前时间
\T     格式为“小时:分钟:秒”的12小时制的当前时间
\@     格式为 am/pm 的12小时制的当前时间
\u     当前用户的用户名
\v     bash shell 的版本
\V     bash shell 的发布级别
\w     当前工作目录
\W     当前工作目录的基本名称
\!     该命令的 bash shell 历史数   此命令的历史编号
\#     该命令的命令数量     该命令的命令号
\$     超级用户(root UID=0)，为#；普通用户，为$。
\nnn   对应于八进制值 nnn 的字符
\\     斜杠
\[     开始一个非打印字符序列，可用于将终端控制序列嵌入到提示中 这个序列应该出现在不移动光标的字符序列（如颜色转义序列）之前。它使 bash 能够正确计算自动换行。
\]     结束一个非打印字符序列 这个序列应该出现在非打印字符序列之后。
所有的特殊字符均以反斜杠\开头，目的是与普通字符区分开来。可以在命令提示符中使用以上任何特殊字符的组合。




ANSI 转义码(ANSI Escape code)
ANSI 转义序列是命令行终端下用来控制光标位置、字体颜色以及其他终端选项的一项 in-bind signaling 标准。通常是在文本中嵌入确定的字节序列（符合带内信令的定义），大部分以 ESC 转义字符和 "[" 字符开始，终端会把这些字节序列解释为相应的指令，而不是普通的字符编码。
在终端中，ASCII编码中有些字符是不能用来打印显示的，比如 '\a' ( 0x7 ) 代表响铃，'\n' (0x0A)  代表换行，这些字符被称为控制符。控制符 '\e' (0x1B)，这个字符代表 ESC ，即键盘上 ESC 按键的作用。ESC 是单词 escape 的缩写，即逃逸的意思。文本中出现这个转义字符，代表其后方的字符是 ANSI Escape code 编码。

ANSI颜色(ANSI color)
ANSI 转义码中有专门控制字符颜色的控制符
构建16257（及更高版本）的Windows 10控制台主机中已经支持ANSI颜色控制了，默认不开启，需要配置注册表如下值
HKEY_CURRENT_USER\Console\VirtualTerminalLevel   设置为 1
否则 需要 下载 ANSICON v1.89 安装个dll
  不介绍Windows程序控制台中使用Windows.h库中的setconsoletextattribute函数
  仅介绍\033控制字符(ESC)的方法。该方法可以直接适用于printf()函数中。
  其中，\033(八进制)即ESC符号，Windows中为\027(十进制)，\x1b(十六进制)
  \033[参数1; 参数2; 参数3 m   # 开始格式 以字母m结尾
  正常的printf中的参数及内容    # 内容格式
  \033[0m                     # 结束格式  如果没有这个则上面设置的一直生效

echo -e "\e[37;44;3;1m测试字符串\e[0m"
  -e 启用 echo 命令控制符转码    如 echo -e "a\ndddd"  自动换行
  \e 代表开始ANSI Escape code
  [ 代表转义序列开始符 CSI，Control Sequence Introducer
  37;44;4;1 代表以;分隔的文本样式控制符，37文本前景色为白色，44背景为蓝色，3代表斜体，1代表加粗
  m 代表结束控制符序列
  \e[0m 代表重置文本样式。
  \x1b[0m  \x1B[0m  \033[0m  \u001b[0m  # 等价 因为\e控制符的16进制码为0x1B，8进制码为033

echo -c xxx   表示统计符合条件的行数

 == = ANSI控制码的说明 == =
 \033[0m 关闭所有属性
 \033[1m 设置字体高亮度
 \033[2m 低亮（减弱）显示
 \033[3m 没有任何效果
 \033[4m 下划线
 \033[5m 闪烁          win无效
 \033[6m 没有任何效果
 \033[7m 反显
 \033[8m 消隐          win无效
 \033[30m~\33[37m 设置字体颜色   30:黑 31:红 32:绿 33:黄 34:蓝 35:紫 36:浅蓝 37:白色 38:无 39:无
 \033[40m~\33[47m 设置背景颜色   40:黑 41:红 42:绿 43:黄 44:蓝 45:紫 46:浅蓝 47:白色 48:无 49:无

 单值控制码 不能与其他控制码联用
 \033[nA 光标上移n行
 \033[nB 光标下移n行
 \033[nC 光标右移n行
 \033[nD 光标左移n行
 \033[x;yH设置光标位置                    左上角坐标为1 1
 \033[2J 清屏
 \033[K 清除从光标到行尾的内容
 \033[s 保存光标位置
 \033[u 恢复光标位置
 \033[? 25l 隐藏光标
 \033[? 25h 显示光标


printf("以下是测试文字       \n");          = printf "以下是测试文字       \n"  # bash下 下同
printf("\033[0m默认文字\033[0m\n");
printf("\033[1m高亮文字\033[0m\n");
printf("\033[2m低亮文字\033[0m\n");
printf("\033[3m无效文字\033[0m\n");
printf("\033[4m下划线文字\033[0m\n");
printf("\033[5m闪烁文字(无效)\033[0m\n");           win下无效 linux有效
printf("\033[6m无效文字\033[0m\n");
printf("\033[7m反显文字\033[0m\n");
printf("\033[8m消隐文字(无效)\033[0m\n");           win下无效 linux有效

printf("\n\033[31;1m字体颜色\033[0m测试文字\n");
printf("\033[30m低亮黑色文字\033[0m\t\033[30;1m高亮黑色文字\033[0m\n");
printf("\033[31m低亮红色文字\033[0m\t\033[31;1m高亮红色文字\033[0m\n");
printf("\033[32m低亮绿色文字\033[0m\t\033[32;1m高亮绿色文字\033[0m\n");
printf("\033[33m低亮黄色文字\033[0m\t\033[33;1m高亮黄色文字\033[0m\n");
printf("\033[34m低亮蓝色文字\033[0m\t\033[34;1m高亮蓝色文字\033[0m\n");
printf("\033[35m低亮紫色文字\033[0m\t\033[35;1m高亮紫色文字\033[0m\n");
printf("\033[36m低亮浅蓝文字\033[0m\t\033[36;1m高亮浅蓝文字\033[0m\n");
printf("\033[37m低亮白色文字\033[0m\t\033[37;1m高亮白色文字\033[0m\n");
printf("\033[38m测试文字\033[0m\n");                没有任何效果 原样输出
printf("\033[39m测试文字\033[0m\n");                没有任何效果 原样输出

printf("\n\033[31;1m背景颜色\033[0m测试文字\n");
printf("\033[40m低亮文字黑色背景\033[0m\t\033[40;1m高亮文字黑色背景\033[0m\n");
printf("\033[41m低亮文字红色背景\033[0m\t\033[41;1m高亮文字红色背景\033[0m\n");
printf("\033[42m低亮文字绿色背景\033[0m\t\033[42;1m高亮文字绿色背景\033[0m\n");
printf("\033[43m低亮文字黄色背景\033[0m\t\033[43;1m高亮文字黄色背景\033[0m\n");
printf("\033[44m低亮文字蓝色背景\033[0m\t\033[44;1m高亮文字蓝色背景\033[0m\n");
printf("\033[45m低亮文字紫色背景\033[0m\t\033[45;1m高亮文字紫色背景\033[0m\n");
printf("\033[46m低亮文字浅蓝背景\033[0m\t\033[46;1m高亮文字浅蓝背景\033[0m\n");
printf("\033[47m低亮文字白色背景\033[0m\t\033[47;1m高亮文字白色背景\033[0m\n");
printf("\033[48m测试文字\033[0m\n");                 win没有任何效果 原样输出 linux全部黑色
printf("\033[49m测试文字\033[0m\n");                 没有任何效果 原样输出






echo
默认情况下 最后自动加一个换行 如 echo   # 只有一个空白行
  -e        启用反斜线控制字符的转換(參考下表)
  -E        关闭反斜线控制字符的转換(预设如此)
  -n        取消行末之換行符(同 -e 选项下的 \c 字符)

echo 命令所支持的反斜线控制字符如下表
  \a       ALERT / BELL (从系统喇叭送出铃声)
  \b       BACKSPACE ，也就是向左退格键
  \c       取消行末之換行符
  \E       ESCAPE，跳脫键
  \f       FORMFEED，换页字符
  \n       NEWLINE，换行字符
  \r       RETURN，回车键
  \t       TAB，表格跳位键
  \v       VERTICAL TAB，垂直表格跳位键
  \n       ASCII 八进位编码(以 x 开头为十六进位)
  \\       反斜线本身
  (表格资料來自 O'Reilly 出版社之 Learning the Bash Shell, 2nd Ed.)

echo "haicoder.net"              # 输出字符并换行
echo -n "haicoder.net"           # 输出字符不换行
echo -e "hello \nhaicoder.net"   # 解析转义字符
echo -e "a\tb\tc\nd\te\tf"       # 使用转义字符
a       b       c
d       e       f
echo -e "\141\011\142\011\143\012\144\011\145\011\146"    #使用 ASCII 八进位编码 同上
echo -e "\x61\x09\x62\x09\x63\x0a\x64\x09\x65\x09\x66"    #使用 ASCII 十六进位编码 同上

echo $RANDOM         # 随机数  为/dev/random 文件的变量  0-32767



printf
printf 不会像 echo 自动添加换行符，我们可以手动添加 \n 无大括号，直接以空格分隔
printf format-string [arguments...]    # 类似于c语言





Linux shell通配符 (wildcards)  GLOB partten
Unix早期有一个/etc/glob文件保存通配符模板,可追溯到 UNIX V6,后来Bash内置了这个功能,但名字被保留。参考 man 7 glob
shell 通配符 / glob 模式通常用来匹配目录以及文件，而不是文本
通配符采有特定的符号，表示特定的含义，特殊符号称为元 meta 字符。
通配符与正则表达式是两个完全不同的东西，通配符只是bash提供的一个功能，正则表达式是一种字符串处理的表达方式。
通配符是由shell处理的(不是由所涉及到命令语句处理的), 它只会出现在命令的“参数”里(不用在命令名称里，也不用在操作符上)。当shell在“参数”中遇到了通配符时，shell会将其当作路径或文件名去在磁盘上搜寻可能的匹配       若符合要求的匹配存在，则进行代换(路径扩展)；否则就将该通配符作为一个普通字符传递给“命令”，然后再由命令进行处理。总之，通配符实际上就是一种shell实现的路径扩展功能。在通配符被处理后, shell会先完成该命令的重组，然后再继续处理重组后的命令，直至执行该命令。

*               # 匹配 0 或多个字符  如 a*b a与b之间可以有任意长度的任意字符 也可以一个也没有 如aabcb axyzb a012b ab
?               # 匹配任意一个字符   如 a?b a与b之间必须也只能有一个字符 可以是任意字符 如aab abb acb a0b
~               # 当前用户家目录     如 ~xingmu  用户xingmu家目录
. or ~+         # 当前工作目录
~-              # 前一个工作目录
[list]          # 匹配 list 中的任意单一字符    如 a[xyz]b a与b之间必须也只能有一个字符 但只能是x或y或z 如axb ayb azb
[^list]         # 匹配除 list 外的任意单一字符  如 a[!0-9]b a与b之间必须也只能有一个字符 但不能是阿拉伯数字 如axb aab a-b
[!list]         # 同[^list]          如 echo report[!1-3].txt
[start-end]     # 表示一个连续的范围  如 a[0-9]b 0与9之间必须也只能有一个字符 如a0b a1b... a9b
[!start-end]    # 匹配连续范围外的任意单个字符 echo report[!1-3].txt -> report4.txt report5.txt
{str1,str2}     # 匹配大括号里面的所有模式 模式之间使用逗号分隔  如 echo d{a,e,i,u,o}g -> dag deg dig dug dog
  1 {...}与[...]有一个很重要的区别。如果匹配的文件不存在，[...]会失去模式的功能，变成一个单纯的字符串，而{...}依然可以展开。
    ls [ab].txt  -> ls: [ab].txt: No such file or directory # 不存在 a.txt 和 b.txt  [ab].txt就会变成一个普通的文件名
    ls {a,b}.txt -> ls: a.txt: No such file or directory ls: b.txt: No such file or directory  {a,b}.txt可以照样展开
  2 大括号可以嵌套   # 如 echo {j{p,pe}g,png} -> jpg jpeg png
  3 大括号也可以与其他模式联用  先进行大括号扩展，然后进行*扩展  # 如 echo {cat,d*} -> cat dawg dg dig dog doug dug
{start..end}    # 会匹配连续范围的字符
  1 echo {11..15} -> 11 12 13 14 15     echo d{a..d}g -> dag dbg dcg ddg
  2 echo {a1..3c} -> {a1..3c}   # 遇到无法解释的扩展，模式会原样输出
  3 echo .{mp{3..4},m4{a,b,p,v}} -> .mp3 .mp4 .m4a .m4b .m4p .m4v  # 与逗号联用，可以写出复杂的模式
[[:digit:]]     # 任意数字，相当于0-9
[[:lower:]]     # 任意小写字母,表示 a-z
[[:upper:]]     # 任意大写字母,表示 A-Z
[[:alpha:]]     # 任意大小写字母
[[:alnum:]]     # 任意数字或字母
[[:blank:]]     # 水平空白字符
[[:space:]]     # 水平或垂直空白字符
[[:punct:]]     # 标点符号
[[:print:]]     # 可打印字符
[[:cntrl:]]     # 控制（非打印）字符
[[:graph:]]     # 图形字符
[[:xdigit:]]    # 十六进制字符
[^[:upper:]]    # 非大写字符之外的单个字符；
[^0-9]          # 非数字的单个字符
[^[:alnum:]]    # 非数字和字母的单个字符

注意
  1 ls a*.txt -> ab.txt  # Bash命令里面有通配符 先通配符扩展 后执行命令  Bash先将a*.txt扩展成ab.txt 然后再执行ls ab.txt
  2 echo r* -> r* (不存在 r 开头的文件名) # 若通配符不匹配 会原样输出  特例 这条规则对{...}不适用
  3 ls */*.txt # 所有通配符只匹配单层路径 不能跨目录匹配 即无法匹配子目录里面的文件 ?或*这样的通配符不能匹配路径分隔符/
  4 touch 'fo*' > fo* # 单引号会转义所有字符 且单引号中间不允许再出现单引号 双引号允许出现特定的 shell 元字符 $ ` \
  5 在使用花括号 {} 的时候 里面的单个字符串需要使用单引号或者双引号括住 否则就会视为多个的单个字符





Linux shell 元字符 meta
在使用通配符时如果没有进行转义可能就会被辨识为元字符
IFS     # 默认由 space tab enter 三者之一/多组成 (Internal Field Seperator)
CR      # 由 enter 产生
=       # 设定变量   变量名=值  注意无空格
$       # 作变量或运算替换   $变量名 推荐${变量名} $0...$9 代表shell文件的參數
>       # 重导向标准输出  *
<       # 重导向标准输入  *
|       # 命令管线  *
&       # 重导向文件描述符，或将命令静默执行  *   如 2>&1     cmd &
( )     # 将其内的命令置于 nested subshell 执行，或用于运算或命令替换  *       如 (pwd)  $(pwd)=`pwd`
{ }     # 将其内的命令置于 non-named function 中执行，或用在变量替换的界定范围  如 { pwd; }  $(PATH)
;       # 在前一个命令结束时，而忽略其返回值，继续执行下一个命令 命令結束符 *
&&      # 在前一个命令结束时，若返回值为 true，继续执行下一个命令  *
||      # 在前一个命令结束时，若返回值为 false，继续执行下一个命令  *
!       # 执行 history 中的命令  *

* 标记的都是作用在命令名直接。可以看到shell 元字符，基本是作用在命令上面，用作多命令分割（或者参数分割）。
因此看到与通配符有相同的字符，但是实际上作用范围不同。所以不会出现混淆。
从技术细节来看，shell 根据 IFS 將 command line 所输入的文字分解为"字段"(word)。
然后再针对特殊字符(meta)先作处理，最后再重组整行 command line 。

man bash
       metacharacter
              A character that, when unquoted, separates words.  One of the following:
              |  & ; ( ) < > space tab newline
       control operator
              A token that performs a control function.  It is one of the following symbols:
              || & && ; ;; ;& ;;& ( ) | |& <newline>

'|&' 等价于 '2>&1|' ，前者是后者的简写，将标准错误输出(stderr)隐式重定向到标准输出(stdout)是在命令指定的任何重定向之后执行的。

case word in [ [(] pattern [ | pattern ] ... ) list ;; ] ... esac 语法中
;; 相当于break 即第一次匹配之后就退出整个case
;& 替代 ;; 表示  在第一次匹配之后 后面的条件不管匹配与否 执行里面的语句
;;& 替代 ;; 表示 在第一次匹配之后 后面的条件若匹配 则执行里面的语句
举例如下
case b in a) echo a;; b) echo b;; a) echo a2;; b) echo b2 ;; *) echo no ;; esac   # b
case b in a) echo a;& b) echo b;& a) echo a2;& b) echo b2 ;& *) echo no ;& esac   # b a2 b2 no
case b in a) echo a;;& b) echo b;;& a) echo a2;;& b) echo b2 ;;& *) echo no ;;& esac # b b2 no
case b in a) echo a;;& b) echo b;;& a) echo a2;;& b) echo b2 ;; *) echo no ;;& esac # b b2
case b in a) echo a;;& b) echo b;;& a) echo a2;; b) echo b2 ;; *) echo no ;;& esac # b b2


元字符优先级
1 重定向属于各个命令
2 管道连接两个命令
3 && || ; 优先级相同
4 小括号、大括号可以将命令组合成一个整体，但它们有特殊意义
  4.1 小括号使得命令在子 Shell 环境下执行
  4.2 大括号使得命令在当前 Shell 环境下执行

# 重定向属于第二个命令，不属于第一个命令或命令整体
echo haha | echo hhh >/tmp/a.log
lsdasd | echo hehe 2>/dev/null   # 仍然会报错
lsdasd 2>/dev/null| echo hehe    # 不会报错





shell转义符
想让通配符，或者元字符变成普通字符。就需要用到引用(quoting)了。 shell提供的引用有三种
''       # 硬转义(hard quote) 内部所有的shell元字符、通配符都会被关掉。注意不允许出现'(单引号)，即使使用了反斜线转义也不允许。
""       # 软转义(soft quote) 内部只允许出现特定的shell 元字符 ($,`,\)  $参数代换 `命令代替 \转义单个字符，如果开启了"!"引用历史命令时，则感叹号也除外。
\        # 反斜杠 (escape) 去除其后紧跟的元字符或通配符的特殊意义。

man bash
There are three quoting mechanisms: the escape character, single quotes, and double quotes.

如
ls \*.txt   -> ls: 无法访问 *.txt: 没有那个文件或目录
ls '*.txt'  -> ls: 无法访问 *.txt: 没有那个文件或目录
ls 'a.txt'  -> a.txt
ls *.txt    -> a.txt  b.txt

a='1      # 同 "   由于<enter>被置于hard quote中 因此不再作为CR字符处理 这里的 <enter> 只是一个换行符(new-line)而已
> 2       # 由于 command line没有 CR 字符 因此进入第二个shell prompt (PS2，以 > 表示) command line 并不会结束
> 3'      # 第三行的<enter>不在hard quote里面 因此并没有被关闭 此时command line 碰到 CR 字符 于是结束 交给 shell 处理
echo $a   # 由于变量没在soft quote中 因此当变量替换完成后并作为命令行重组时 <enter>会被解释为 IFS 而不是 New Line 字符
1 2 3
echo "$a" # 同echo '$a'
1
2
3

A=B\      # 第一个 <enter> 跟第二个 <enter> 均被 escape 字符关闭了，因此也不作为 CR 來处理
> C\
>         # 第三个 <enter> 由于沒被跳脫，因此作为 CR 结束 command line
$ echo $A
BC

一个<enter> 鍵所产生的字符就有可能是
CR
IFS
NL(New Line)
FF(Form Feed)
NULL


关于转义字符 \
在双引号中即可变普通字符的特殊字符  空格 * # 换行符
  空格 '\ `  # 这是转义空格。如果路径中包含空格，那么使用 \ 转义可以避免路径被分割成 Shell 的两个参数。
  星号 '*`   # 单独使用 * 表示当前路径下枚举的所有文件或文件夹。如希望保持 * 的原意，要将其包裹在引号内，或者使用转义 \*。
  井号 #     # 表示注释。
  换行符     # 在引号中，也可以直接换行。这样换行符就是字符串的一部分。
在双引号中依然被 Shell 解释的特殊字符  " $ ` \  若要当成普通字符则需要转义  \" \$ \` \\
任意字符也可以使用 \ 转义，虽然没用，但也是一个特性  echo \H\e\l\l\o\ \"\W\a\l\t\e\r\l\v\"  -> Hello "Walterlv"


grep -n \. file     # 不能识别file中 .
grep -n \\. file    # 可以识别file中 .
grep -n '.' file    # 不能识别file中 .
grep -n '\.' file   # 可以识别file中 .
grep "\\\\" file    # shell把四个\,转义成2个\传递给grep，grep再把2个\转义成一个\查找
grep '\\' file      # shell没转义，直接把2个\传递给grep，grep再把2个\转义成一个\查找
linux中的单引号和双引号的确对转义字符有不同的分别，但前提是转义系统保留字，例如:$,>,<等(系统保留字）
grep天生支持正则表达式，所以在grep看来，它的转义字符包括两部分，一部分就是系统保留字，另一部分就是正则表达式的转义字符.
如^是正则转义字符，但由于它非系统保留字，所以单引号和双引号对它都是一样的，但是不加引号就不起作用(貌似不加也没事)。
对于系统保留字，grep依然满足不同引号的不同用法，如       "$boy"和'$boy‘'那可就不一样；但对正则表达式的转义字符，则对引号不敏感。
因此这告诉我们，以后将系统保留字与正则表达式混用时，正则表达式尽量按照规则来写
如果grep搜索内容中有空格，则需要使用单引号或者双引号把搜素内容引起来！建议使用grep时都老老实实的多输入两个单引号。






shell中$后加引号有什么用($"string"和$'string')
http://www.cnblogs.com/f-ck-need-u/p/7048359.html

某些服务管理脚本中看到$"$string"或$"string"，经过一些测试，又发现引号外面的$有和没有是一样的。翻了下man bash，找到了解释。
1.如果没有特殊定制bash环境或有特殊需求，$"string"和"string"是完全等价的，使用$""只是为了保证本地化。
以下是man bash关于$""的解释
  A  double-quoted  string  preceded by a dollar sign ($"string") will cause the string to be translated according to the current locale.  If the current locale is C or POSIX, the dollar sign is ignored.  If the string is translated and replaced, the replacement is double-quoted.
2.还有$后接单引号的$'string'，这在bash中被特殊对待       会将某些反斜线序列(如\n，\t，\"，\'等)继续转义，而不认为它是字面符号(如果没有$符号，单引号会强制将string翻译为字面符号，包括反斜线)。

简单的例子
[root@xuexi ~]# echo 'a\nb'
a\nb
[root@xuexi ~]# echo $'a\nb'
a
b

以下是man bash里关于$'的说明
Words of the form $'string' are treated specially.  The word expands to string, with backslash-escaped characters replaced as specified  by  the ANSI C standard.  Backslash escape sequences, if present, are decoded as follows:
  \a     alert (bell)
  \b     backspace
  \e
  \E     an escape character
  \f     form feed
  \n     new line
  \r     carriage return
  \t     horizontal tab
  \v     vertical tab
  \\     backslash
  \'     single quote
  \"     double quote
  \nnn   the eight-bit character whose value is the octal value nnn (one to three digits)
  \xHH   the eight-bit character whose value is the hexadecimal value HH (one or two hex digits)
  \uHHHH the Unicode (ISO/IEC 10646) character whose value is the hexadecimal value HHHH (one to four hex digits)
  \UHHHHHHHH
         the Unicode (ISO/IEC 10646) character whose value is the hexadecimal value HHHHHHHH (one to eight hex digits)
  \cx    a control-x character








shell命令执行过程概述
var='hello world'
echo -e $var $(((2+3)/5))

1 读取命令行
2 解析命令行       发现有变量$var,替换成值 hello world;发现有数学运算,替换成值 1,替换后得到 echo -e hello world 1 命令行
3 命令行解析完成后，调用命令
  3.1 创建一个子 shell 进程，父 shell 进程被阻塞，它要等待子进程的退出，并且此时子进程获得终端控制权
  3.2 在子 shell 进程中通过 exec 加载磁盘中的 echo 命令
  3.3 exec 加载命令时，会搜索 echo 命令，然后调用它，于是替换子 shell 进程并得到 echo 进程
4 echo 进程开始执行，它要识别选项和参数，于是输出 hello world 1 到终端
5 echo 进程退出，并记录一个退出状态码
6 echo 退出后就回到了 shell 进程，shell 进程会去读取子进程的退出状态码，shell 进程读完 echo 进程记录的退出状态码后，echo 进程完全消失，shell 进程准备执行下一个命令





shell命令执行过程详细
0  read command
1  split into tokens         # 用meta来分割字符串   复杂命令分解成简单命令
2  check 1st token           # 检查有无语法错误
3  check 1st                 # expand alias   别名扩展
4  brace expansion           # 括号扩展                    ——
5  tilde expansion           # ~ 解析                      ↑
6  parameter expansion       # 变量替换    ——
7  command substitution      # 命令替换   双引号          单引号
8  arithmetic substitution   # 算术扩展    ——
9  word spliting             # 单词拆分                     ↓
10 pathname expansion        # wildcard 匹配  文件名扩展    ——
11 command lookup:funtions, built-in command, executable file   # 搜索命令
12 run command               # make argument into next command  执行命令

双引号扩展包括6-8项，单引号为4-10项，无论单双引号转义符告诉各个命令自身内部是一体的，但其本身并不是命令中文本的一部分。


            ————————————————————————————————eval命令—————————————————————————————————————————
            ↓                                                                               |
  如  |-> 复杂命令行分解   无 | --->   大括号扩展                                              |
  果  |     ↓             引 |            ↓                                                  |
  是  |   简单命令结构     号 |        波浪号扩展                                              |
  别  |     ↓                |            ↓                                                  |
  名  |-- 别名扩展            | --->   变量替换                                               |
            |             双 |            ↓                                                  |
            |             引 |        算数扩展         --------> 引号去除 ---> 搜索命令 ---> 执行命令
            ↓             号 |            ↓           |            ↑
           根据引用决定扩展 ---        命令替换         |            |
            |                             ↓           |            |
            |                         单词拆分         |            |
            |                             ↓           |            |
            |                         文件名扩展 ------             |
            |-------------------------------------------------------
                      单引号


下例
name="longshuai"
a=24
touch ~/i{a,b}.sh
echo -e "some files:" ~/i* "\nThe date:$(date +%F)\n$name's age is $((a+4))" >/tmp/a.log
假设在执行该命令前，已赋值变量"name=longshuai"和"a=24"，于是重定向到/tmp/a.log中的结果为
some files: /root/ia.sh /root/ib.sh
The date:2017-08-14
longshuai's age is 28

1 读取命令行

2 解析引用并分割命令行为各个单词，各单词称为token。其中重定向所在的token会被保存下来，直到扩展步骤(5)结束后才进行相关处理，如进行扩展、截断文件等。
shell中有3种引用方式       反斜线引用、单引号引用和双引号引用。
  反斜线转义       使得元字符变为普通的字面字符。但这只能对反斜线后一个字符进行转义。
  单引号引用       单引号内的所有字符全部变为字面符号符号。但注意       单引号内不能再使用单引号，即使使用了反斜线转义也不允许。
  双引号引用       使双引号内所有字符变为字面符号，但"\"、"$"、"`"(反引号)除外，如果开启了"!"引用历史命令时，则感叹号也除外。
解析引用后，于是就可以将命令行进行单词分割，分割后的每一部分都称为一个token。分隔时，不仅分割单个命令，还分割命令列表，所以分隔符包括       空格、tab、分号、管道符号、&、&&、||、重定向符号、圆括号等。
于是上述命令分割为以下几个token        #分割
echo # -e # "some files:" # ~/i* # "\nThe date:$(date +%F)\n$name's age is $((a+4))" # >/tmp/a.log
(注       虽然换行符是shell划分命令行token的元字符，但是shell并不认识这里的\n，shell只认识我们直接手动敲下的回车键，而这里\n是由echo -e选项识别的换行符，因此这里的\n不是shell解析命令行时划分token的换行符，于是\n也被认为是双引号包围的token的一部分)
如果分割时发现了管道符号，或者是命令列表等组合了多个命令的情况，则每个命令都的token都相互独立。

3 检查命令行结构。主要检查是否有命令列表、是否有shell编程结构的命令，如if判断命令、循环结构的for/while/select/until，这些命令属于保留关键字，需要特殊处理。

4 对第一个token进行别名扩展。如果检查出它是别名，则扩展后回到(2)再次进行token分解过程。如果检查出它是函数，则执行函数体中的复合命令。如果它既是别名，又是函数(即命令别名和函数同名称的情况)，则优先执行别名。在概念上，别名的临时性最强，优先级最高。

5 进行各种扩展。扩展顺序为       大括号扩展；波浪号扩展；参数、变量、算术扩展和命令替换，如果系统支持，此步还进行进程替换；单词拆分；文件名扩展。
不同引号的引用方式，将改变扩展的起始步骤，没有任何引号时将从头到尾全部扩展，使用单引号时将完全不会进行任何扩展，使用双引号时将从变量替换开始继续扩展。
  5.1 大括号扩展       如/tmp/{a,b}.log扩展为/tmp/a.log和/tmp/b.log。
  5.2 波浪号扩展       扩展为家目录。如root用户下的~/.ssh扩展为/root/.ssh。
  5.3 变量扩展       即操作和替换变量值。如$a替换为它的值24， ${name:-longshuai} 替换为longshuai。
  5.4 算术扩展       计算算术值，并将计算结果替换到对应位置处。例如$((a+4))替换为28。
  5.5 命令替换       此过程将执行命令替换中的命令，并将结果替换到token的对应位置处。
  5.6 进程替换       将进程的执行结果替换到对应位置。类似于命令替换。替换格式为"<(cmd_list)"和">(cmd_list)"，例如 cat <(cat /etc/hosts) 。redhat系列应该都支持进程替换。
经过以上几种扩展后，得到如下结果
echo # -e # "some files:" # ~/i*     "\nThe date:$(date +%F)\n$name's age is $((a+4))" # >/tmp/a.log
                  波浪号替换 ↓                命令替换 ↓  变量替换 ↓       算术扩展 ↓
echo # -e # "some files:" # /root/i* "\nThe date:2023-08-01\nloangshuai's age is 28" # >/tmp/a.log
  5.7 单词拆分       扫描变量扩展、命令替换和算术扩展的结果，对非引号内的结果按照$IFS的值对这些结果进行单词分割。
注意，如果没有进行扩展，或者扩展结果使用引号包围了，则不会进行此步的单词拆分。
默认情况下，$IFS值为" \t\n"，所以扩展结果中每遇到空格、制表符、换行符都将被分割为两个单词。
这一步其实很容易犯错，典型的是test命令。例如变量 name="Ma longshuai" ，则 test $name == "longshuai" 将报错，因为变量扩展后该语句变为 test Ma longshuai == "longshuai" ，由于是变量替换，所以随后进行单词拆分，使得Ma和longshuai被拆分为两个单词，但实际上它们共同组成变量name的值。
所以，为了正确操作变量替换和命令替换，尽量将它们使用引号包围。例如 test "$name" == "longshuai" ，这时将不会进行单词拆分。
  5.8 文件名扩展       对每个token进行搜索，将搜索"*"、"?"和"["符号，搜索到了将进行文件名扩展。例如将上面的"/root/i*"扩展为"/root/ia.sh /root/ib.sh"。

6 引号去除。经过上面的过程，该扩展的都扩展了，不需要的引号在此步就可以去掉了。
所以得到如下结果。
echo # -e # "some files:" # /root/i* # "\nThe date:2023-08-01\nlongshuai's age is 28" # >/tmp/a.log
                                ↓
                            /root/ia.sh
                            /root/ib.sh

7 搜索和执行命令。
单词分割后，复杂的命令行将由各个简单命令结构组成。于是可以搜索每个简单命令结构的第一个token中的命令，同时还带有一系列命令选项。例如上面的"echo"和"-e"。
如果命令中不含任何斜杠
  7.1 则先判断是否有此名称的shell function存在，如果有则调用它，否则进行下一步搜索。
  7.2 判断该命令是否为bash内置命令，如果是则执行它，否则进行下一步搜索。
  7.3 从$PATH的路径下搜索该命令，如果搜索到了，则执行，否则报错。
如果命令中包含一个或多个斜杠，则进行相对路径扩展、绝对路径查找，找到了则执行，否则报错。

8 返回退出状态码。



另一种分析
1 读取命令行，并将读取的字符内容交给词法解析器

2 词法解析阶段
  2.1 解析引用 (即识别双引号、单引号和反斜线)，并根据空白符号和 bash 元字符，将读取的内容划分成 token (在 Shell 语法中也成为 word)
    划分 token 的元字符有       | & ; ( ) < > space tab
    解析引用是为了防止被引用的整体部分被分割成多个 token
    比如 echo "ls|cat" 不会因为里面有竖线就将引号包围的部分划分成多个 token
  2.2 根据控制元字符，将复杂命令结构划分成简单命令结构
    即将多个或复杂的命令行，划分成简单的一个一个命令
    控制元字符有       || & && ; ;; ( ) | |& <newline>
  2.3 检查第一个 token
    如果第一个 token 是别名，则进行别名扩展
      别名替换本不该是词法解析阶段完成的，因为涉及了 Bash 自身的语法支持，但因为别名扩展会直接影响命令行结构，所以在词法解析阶段处理它才更合理
    如果第一个 token 是带有等号 = 且等号前的字符符合变量命名规范，则本条命令是一个变量赋值
    如果是 shell 函数、shell 内置命令、shell 保留关键字，则做相应处理
因为上面的命令行中，没有复杂命令结构，只是单个 echo 命令行，而且第一个 token 没有别名，所以，划分 token 后的结果如下
echo -e "some files:" ~/i* "\nThe date:$(date +%F)\n$name's age is $((a+4))" >/tmp/a.log
                               ↓
echo # -e # "some files:" # ~/i* # "\nThe date:$(date +%F)\n$name's age is $((a+4))" # >/tmp/a.log

3 word 扩展阶段 (各种 Shell 扩展和替换)
称为 word 扩展是因为下面这些操作都可能会改变 word (即 token) 的数量。
所谓扩展或替换，指的是 Shell 会分析各个 token 中的某些特殊符号，并进行对应的值替换。
Shell 按照下面列出来的先后顺序进行各种扩展行为
  大括号扩展
  波浪号扩展
  变量替换
  算术替换
  命令替换
  单词拆分
  引号移除
此外，对于支持命名管道的 Shell，还支持进程替换。因为进程替换中的命令是异步执行的，而且它不会将执行结果替换到命令行中，而是以虚拟文件的方式作为命令的标准输入或标准输出，所以不要考虑进程替换在哪个阶段执行，这没有意义。尽管官方手册说，进程替换可能在波浪号扩展、变量替换、算术扩展、命令替换这四个阶段的任何一个阶段执行。

下面是各个扩展阶段的分析
  (1). 大括号扩展
    例如 echo hey{1..3} 在这一阶段替换后变成 echo hey1 hey2 hey3
  (2). 波浪号扩展，最常见的是 ~ 扩展成家目录，此外还有 ~+、~- 等也是波浪号扩展
    例如，对于 root 用户执行的命令 ls ~/.ssh ~/.bashrc 来说，在这一阶段替换后会得到 ls /root/.ssh /root/.bashrc
  (3). 变量替换，最常见的是将变量的值替换到变量引用位置处，此外还有各种变量操作也是变量扩展
    例如，ls /$USER 在这一阶段替换后变成 ls /root
    再例如，echo ${#USER} 在这一阶段替换后变成 echo 4
  (4). 算术替换，即将算术运算的评估结果替换到算术表达式位置处
  (5). 命令替换，即执行命令替换中的命令，并将命令的标准输出替换在命令替换位置处
    例如，echo $(hostname -I) 在这一阶段替换后会变成 echo 192.168.100.11
    如果命令替换的命令有多行，则默认会压缩成单个空格。可使用双引号保护命令替换的结果         *****
    例如 echo $(echo -e 'a\nb') 会替换成 echo a b
    echo "$(echo -e 'a\nb')" 会替换成 echo $'a\nb'
  (6). 单词拆分 (word splitting)
    Shell 重新扫描变量替换、算术扩展、命令替换后的结果，如果这三种替换是使用双引号包围的，则不会拆分开，如果它们没有使用双引号包围，则  根据 IFS 变量的值再次对它们划分单词
    例如 n="name age";test $n -eq "name age" 是错的，因为单词拆分后得到 test name age -eq "name age"，这会语法报错，但如果加上双  引号包围 "$n"，则得到 test "name age" -eq "name age"
    如果没有变量替换、算术扩展、命令替换，则不会执行单词拆分
  (7). 路径名扩展，也即通配符扩展
    通配符包括 * [] ?
    例如 /root 下有 ia.sh 和 ib.sh 文件，那么 ls /root/i*.sh，路径扩展后命令变成 ls /root/ia.sh /root/ib.sh
  (8). 引号去除，即移除为了保护 Shell 解析的那一层引号
    命令在开始执行之前，所有不需要的引号 (即 Shell 层次的引号) 都会被移除
    例如 cat "/proc/self/cmdline" 查看到的结果是 cat /proc/self/cmdline

整个扩展过程如下所示
echo -e "some files:" ~/i* "\nThe date:$(date +%F)\n$name's age is $((a+4))" >/tmp/a.log
                               ↓  划分tocken 命令行分解 别名扩展
echo # -e # "some files:" # ~/i* # "\nThe date:$(date +%F)\n$name's age is $((a+4))" # >/tmp/a.log
                  波浪号替换 ↓                命令替换 ↓  变量替换 ↓       算术扩展 ↓
echo # -e # "some files:" # /root/i* "\nThe date:2023-08-01\nlongshuai's age is 28" # >/tmp/a.log
             | 引号移除           ↓  路径扩展
             |              /root/ia.sh
             ↓              /root/ib.sh
echo # -e # some files: # /root/i* \nThe date:2023-08-01\nlongshuai's age is 28 # >/tmp/a.log


关于 word splitting 和路径扩展，有一个注意事项

touch "aa aaa.txt"
touch "bb bbb.txt"
for i in *.txt;do
  echo $i
done

因为在单词分割时，*.txt 还没有扩展，等到路径扩展时，aa aaa.txt 自然会被作为一个元素整体。
而下面代码是有问题的，因为命令替换在单词分割之前

touch "aa aaa.txt"
touch "bb bbb.txt"
for i in $(ls *.txt);do
  echo $i
done

改进方式是修改 IFS 的值
(IFS=$'\n';for i in $(ls *.txt);do echo $i;done)

当 Shell 处理完各种 Shell 扩展之后，意味着 Shell 的解析完成了，接下来准备让命令运行起来。

4 搜索命令并执行

Shell 首先判断第一个 token (即命令):
  (1). 如果命令中不含任何斜杠
    先判断是否有此名称的 shell function 存在，如果有则调用它，否则进行下一步搜索
    判断该命令是否为 bash 内置命令，如果是则执行它，如果不是，则当作外部命令处理
  (2). 如果命令中包含一个或多个斜杠，则当作外部命令处理

如果发现要执行的是外部命令
  (1).Shell 通过 fork 创建一个子 shell 进程，然后父 Shell 进程自身进入阻塞并等待子进程终止，同时会让出终端的控制权
  (2). 子 Shell 进程通过 exec 去调用外部命令并替换当前子 Shell 进程
    exec 调用外部命令时，会搜索命令，如果 token 中包含了斜线，则从相对路径或绝对路径中查找，否则从 $PATH 中搜索，如果找不到，则报错
    替换子 Shell 进程后，就不再称为子 Shell 进程，而称之为对应命令的进程 (比如 echo 进程)
命令退出后回到父 Shell，父 Shell 去获取命令退出状态码并赋值给变量 $?，然后就可以执行下一条命令。



eval命令
正常情况下，当搜索到命令时将会执行命令，但如果搜索到的命令为eval时，则处理方式有所不同。
它的语法格式为       eval command arguments
按照前文所述shell解析过程，将最终得到eval command和一系列扩展后的选项、参数，当搜索命令时，搜索到的结果为eval命令，于是eval命令将除了eval命令(以及eval的选项)的所有token再次传递给shell进行二次解析。但重定向所在token除外，因为重定向token早已被shell保存下来，所以不会再次截断文件。
也就是说，"command arguments"被当作eval命令的参数，被传递给shell进行解析、执行。

示例
a=24;name='long$a'     # 单引号 禁止$a被扩展
echo $name             # 结果为"long$a"
eval echo $name        # long24

首先shell按照正常过程解析，在变量替换时由于使用了单引号，所以$name第一次变量替换的结果为"long$a"，直到命令搜索时发现搜索到的命令是eval命令，执行eval命令，该命令将其参数 echo long$a 再次传递给shell，相当于在标准输入中输入了 echo long$a ，于是shell进行二次解析，这次的变量替换将$a替换为24，最后搜索命令发现是echo命令，于是最终得到"long24"。

关于eval，更多的用法是间接变量$$var的用法，在bash shell中需要在第一个$前加上反斜线，即 \$$var ，这么做的原因是显然的       防止第一次shell解析时被当作特殊变量"$$"被扩展。

a=b ; b=haha ; eval echo \$$a    # 输出 haha





基本正则 grep
1 基本元字符
.   # 匹配任意单个字符   如grep "r..t" /etc/passwd ,表示匹配r和t中间有两个任意字符的内容。
[]  # 匹配指定范围内的任意单个字符   如grep "[0-9]" /etc/inittab ,表示匹配0到9中任意一个数字
[^] # 匹配指定范围外的任意单个字符   如grep "[^0-9]" file ,表示出了数字，都匹配
2 次数匹配 注意       grep默认工作在贪婪模式下，即尽可能长的匹配
*   # 匹配其前面的字符任意次   如ooo*匹配oo、ooo等，不能写oo*，*作用于第二个o   [0-9][0-9]* 包含任意数字
.*  # 表示匹配任意字符任意长度(包含0次)  如grep "a.*b" test.txt
\?  # 匹配其前面的字符1次或0次   如grep "a\?b" test1
\{n\}    # 匹配连续 n 个前一个字符
\{n,\}   # 匹配至少 n 个以上的前一个字符；效果上感觉和 \{n\} 是一样的
\{m,n\}  # 匹配其前面的字符至少m次，至多n次   如grep "a\{2,\}" test1  表示匹配至少2次    \{0,3\} 匹配0至三次
3 字符集合
[:digit:]    # 所有数字          [0-9]       如grep "[[:digit:]]" /etc/resolv.conf
[:lower:]    # 所有小写字母       [a-z]
[:upper:]    # 所有大写字母       [A-Z]
[:alpha:]    # 表示所有字母（包含大小写） [a-zA-Z]
[:alnum:]    # 表示所有字母和数字        [0-9a-zA-Z]
[:xdigit:]   # 代表 16 进制的数值类型，包括 0-9、A-F、a-f 的数字与字符

[:blank:]    # 代表空格与tab
[:space:]    # 表示空格或tab键  任何会产生空白的字符，包括空格、tab、CR 等
[:punct:]    # 所有标点符号

[:cntrl:]    # 代表键盘上面的控制按键，包括 CR、LF、TAB、Del 等
[:graph:]    # 除了空格符（空格键与 tab 键）外其他的所有按键
[:print:]    # 代表任何可以被打印出来的字符

4 位置锚定
^   # 锚定行首，此字符后面的任意内容必须出现在行首  如grep "^root" /etc/passwd 查找/etc/passwd中以root开头的行
$   # 锚定行尾，此字符前面的任意内容必须出现在行尾  如grep "bash$" /etc/passwd 查找/etc/passwd中以bash结尾的行
^$  # 空白行   如grep "^$" /etc/php.ini |wc -l  统计/etc/php.ini文件中有多少空白行
\<或\b   # 锚定词首，其后面的任意字符必须作为单词首部出现   如grep "\<ro" file 等价于 grep "\bro" file
\>或\b   # 锚定词尾，其前面的任意字符必须作为单词尾部出现   如grep "ot\>" file 等价于 grep "ot\b" file
\<条件\>或\b条件\b   # 查找某个独立的单词  如grep "\<r..t\>" /etc/passwd  查找/etc/passwd文件中以r开头，t结尾，中间包含两个任意字符的单词  注意与grep "r..t" /etc/passwd结果的区别
5 grep的分组
\(\)
\(ab\)         # 表示ab整体作为匹配字符
\(ab\)*        # 表示ab整体作为匹配字符，且匹配任意次
\(ab\)\{1,\}   # 表示ab整体作为匹配字符，且匹配至少一次
分组还可以后向引用
\1             # 引用第1个左括号以及与之对应的右括号所包括的所有内容   如grep "\(l..e\).*\1r" test2
\2             # 引用第2个左括号以及与之对应的右括号所包括的所有内容
\3             # 引用第3个左括号以及与之对应的右括号所包括的所有内容

a[a-z]\{0,2\}c  # [a-z]\{0,2\}要看成一组来理解，表示0-2个字母，这一组可以匹配 空 a aa ab这种


扩展的正则表达式  grep -E = egrep
1 字符匹配  扩展模式下的字符匹配与基本正则表达式的字符匹配相同
.      # 表示任意单个字符
[]     # 表示范围内人任意单个字符，如[0-9]，表示任意单个数字
[^]    # 表示范围外的任意单个字符，如[^0-9]，表示出数字外的任意单个字符
2 次数匹配  次数匹配就有些不一样了
*      # 匹配前面字符任意次    与基本正则表达式意义相同
?      # 匹配其前字符0次或1次  其前面相比不需要 \ 转义
+      # 匹配其前字符至少一次  等于基本正则表达式的  \{1, \}    ?+ = *
{m,n}  # 匹配其前字符至少m次 最多n次   等于基本正则表达式的\{m,n\}
3 位置锚定
与基本正则表达式完全意义
4分组  基本正则表达式中支持分组，而在扩展正则表达式中，分组的功能更加强大，也可以说才是真正的分组
()     #分组 后面可以使用\1 \2 \3...引用前面的分组
除了方便后面引用外，分组还非常方便的可以使用上述次数匹配方法进行匹配具有相同条件的数据
如egrep '^(barlow).*\1' /etc/passwd   搜索/etc/passwd中以barlow开头，而后面还存在barlow的行
5 或者
|      #表示或  如a|b 匹配a或b  如B|barlow 匹配B或barlow |匹配的是其整个左边或者右边 如(B|b)arlow 匹配Barlow或者barlow


fgrep
不解析正则表达式 直接搜索文本 仅作为一般字符串处理 所有 meta 均失去功能
echo 'abc123{1,2}sd' | fgrep '{1,2}' # 匹配{1,2}





shell 中各种括号的作用()、(())、[]、[[]]、{}
http://blog.csdn.net/taiyang1987912/article/details/39551385
1 单小括号 ()
  1.1 命令组。括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。 如pwd;(cd code/;pwd);(cd code/; pwd);pwd
  1.2 命令替换。等同于`cmd`，shell扫描一遍命令行，发现了$(cmd)结构，便将$(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。 如ls $(find ./ -name 12 )
  1.3 用于初始化数组。如       array=(a b c d)

2 双小括号 (())
  2.1 整数扩展。这种扩展计算是整数型的计算，不支持浮点型。((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，那么返回的退出状态码为1，或者 是"假"，而一个非零值的表达式所返回的退出状态码将为0，或者是"true"。若是逻辑判断，表达式exp为真则为1,假则为0。如 echo $((1+2))  echo $?   echo $((1<2))
  2.2 只要括号中的运算符、表达式符合C语言运算规则，都可用在$((exp))中，甚至是三目运算符。作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。如       echo $((16#5f)) 结果为95 (16进位转十进制)
  2.3 单纯用 (()) 也可重定义变量值，比如 a=5; ((a++)) 可将 $a 重定义为6
  2.4 常用于算术运算比较，双括号中的变量可以不使用$符号前缀。括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则,比如可以直接使用for((i=0;i<5;i++)), 如果不使用双括号, 则为for i in `seq 0 4`或者for i in {0..4}。再如可以直接使用if (($i<5)), 如果不使用双括号, 则为if [ $i -lt 5 ]。

3 单中括号 []
  3.1 bash 的内部命令，[和test是等同的。如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。if/test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试，并且根据比较的结果来返回一个退出状态码。if/test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。
  3.2 Test和[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq，-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用，对于字符串比较可以使用转义形式，如果比较"ab"和"bc"       [ ab \< bc ]，结果为真，也就是返回状态为0。[]中的逻辑与和逻辑或使用-a 和-o 表示。
  3.3 字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。
  3.4 在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。
  3.5 通配符扩展 允许匹配方括号中任何一个单个字符 如 ls /[eh][to][cm]* 执行 ls /etc /home 注       在mkdir命令下不能扩展

4 双中括号[[]]
  4.1 [[是 bash 程序语言的关键字。并不是一个命令，[[]] 结构比[]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。
  4.2 支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，比如[[ hello == hell? ]]，结果为真。[[]] 中匹配字符串或通配符，不需要引号。
  4.3 使用[[ ... ]]条件判断结构，而不是[ ... ]，能够防止脚本中的许多逻辑错误。比如，&&、||、<和> 操作符能够正常存在于[[]]条件判断结构中，但是如果出现在[]结构中的话，会报错。比如可以直接使用if [[ $a != 1 && $a != 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] && [ $a != 2 ]或者if [ $a -ne 1 -a $a != 2 ]。
  4.4 bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。

例子
if ($i<5)      此处有问题,改为if (($i<5))
if [ $i -lt 5 ]
if [ $a -ne 1 -a $a != 2 ]
if [ $a -ne 1] && [ $a != 2 ]
if [[ $a != 1 && $a != 2 ]]

for i in $(seq 0 4);do echo $i;done
for i in `seq 0 4`;do echo $i;done
for ((i=0;i<5;i++));do echo $i;done
for i in {0..4};do echo $i;done

5 大括号、花括号 {}
  5.1常规用法
    5.1.1 大括号拓展。(通配(globbing))将对大括号中的文件名做扩展。在大括号中，不允许有空白，除非这个空白被引用或转义。
      第一种       对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt。
      第二种       对大括号中以点点（..）分割的顺序文件列表起拓展作用，如       touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt
ls {ex1,ex2}.sh       -> ex1.sh  ex2.sh
ls {ex{1..3},ex4}.sh  -> ex1.sh  ex2.sh  ex3.sh  ex4.sh
ls {ex[1-3],ex4}.sh   -> ex1.sh  ex2.sh  ex3.sh  ex4.sh

    5.1.2 代码块，又被称为内部组，这个结构事实上创建了一个匿名函数 。
    与小括号中的命令不同，大括号内的命令不会新开一个子shell运行，即脚本余下部分仍可使用括号内变量。
    括号内的命令间用分号隔开，最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。如 { pwd;}

  5.2 几种特殊的替换结构
    ${var:-string}
    ${var:+string}
    ${var:=string}
    ${var:?string}
    在上面这种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。详见下面 变量栏

  5.3 四种模式匹配替换结构
    # 是去掉左边(在键盘上#在$之左边)
    % 是去掉右边(在键盘上%在$之右边)
    #和%中的单一符号是最小匹配，两个相同符号是最大匹配。详见下面 变量栏

  5.4 字符串提取和替换
    ${var:num}
    ${var:num1:num2}
    ${var/pattern/pattern}
    ${var//pattern/pattern}
    详见下面 变量栏

6 符号$后的括号
  6.1 ${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。
  6.2 $(cmd) 命令替换，和`cmd`效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。
  6.3 $((expression)) 和`exprexpression`效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。

7 使用
  7.1 多条命令执行
   1 单小括号，(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。
   2 单大括号，{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。
对 {} 和 () 而言, 括号中的重定向符只影响该条命令， 而括号外的重定向符影响到括号中的所有命令。





Shell中的重定向 < << > >> &< >& 都是重定向操作符
默认三个文件处于打开状态，标准输入(键盘输入),标准输出(输出到屏幕),标准错误(输出到屏幕)，分别对应文件描述符0,1,2
名称                 代码    操作符          Java中表示   Linux 下文件描述符(Debian 为例)
标准输入(stdin)       0      <   <<          System.in   /dev/stdin -> /proc/self/fd/0 -> /dev/pts/0
标准输出(stdout)      1      >,>> 或 1>,1>>  System.out  /dev/stdout -> /proc/self/fd/1 -> /dev/pts/0
标准错误输出(stderr)  2      2>    2>>       System.err  /dev/stderr -> /proc/self/fd/2 -> /dev/pts/0

输出重定向
> file     # 标准输出重定向，与 1> 相同 注意 1 与 > 之间不能有空格 1可省   2> 把标准错误重定向
n>file     # redirect file descriptor n to file
>> file    # 标准输出重定向(追加)   2>> file 把标准错误重定向到一个文件中(追加)
n>>file    # redirect file descriptor n to file. Create file if non-existent, else overwrite.
n>| file   # redirect file descriptor n to file. Create file even if noclobber is enabled.
2>&1       # 标准错误输出 重定向到 标准输出 或 2>& 1 其中 >& 为一个整体 如 > file 2>&1 把标准输出和错误一起重定向到一个文件中  >> file 2>&1 把标准输出和错误一起重定向到一个文件中(追加)
&>file     # 把标准输出 和 标准错误输出 都重定向到文件file中 同 >& file 或 &> file
|&         # 管道 包含标准输出和标准错误 等价于 2>&1 |
/dev/null  # 表示一个空设备 如 > file 2> /dev/null 标准输出定向到文件，屏蔽掉错误输出

输入重定向
< file             # 以file文件作为标准输入
n<file             # redirect file descriptor n from file
< file > file2     # 以file文件作为标准输入，以file2作为标准输出
<< delimiter       # 从标准输入中读入，以  delimiter 为结束符。这就是 Bash 的 HereDoc 用法
n<<word            # redirect to file descriptor n until word is read
n<<-word           # redirect to file descriptor n until word is read; ignore leading tabs
cat < file > file  # file被洗掉 这只是个只是 priority 的问题，在 IO Redirection 中stdout 与 stderr的管道先准备好，才会从stdin读。> file 先将 file 清空，然后才读 < file ，但这时file已被清空了，因此就变成读不进任何资料了。

绑定重定向
>&m        # 把标准输出重定向到文件描述符 m 中 等同于 1>&m  如 ls >&1
m>&n       # 把往文件描述符 m 的输出重定向到文件描述符 n 上  如2>&1
<&n        # redirect standard input from file descriptor n
n<&m       # redirect file descriptor n input from file descriptor m
<&-        # 关闭标准输入
2>&-       # 关闭标准错误输出，和 2>/dev/null 有类似功效
n<&-       # close file descriptor n for standard input
n>&-       # close file descriptor n for standard output
n<>file    # open file for reading and writing as file descriptor n
print &un args    # redirect arguments to file descriptor n. If n is greater than 2, it must first be opened with exec. If n is not specified, the default file descriptor argument is 1 (standard output).
read &un args     # read input line from file descriptor n. If n is greater than 2, it must first be opened with exec. If n is not specified, the default file descriptor argument is 0 (standard input).

其他
cat file1 | tee file2 file3   #tee 命令 可以同时重定向到多个文件
exec 1>file1  # 当前shell永久重定向 如 1 bash 打开一个shell 2 exec 1>file1 永久重定向 3 exit 推出当前shell
exec 4>file1  # 创建文件描述符  默认shell可以有9个打开的文件描述符 默认提供0 1 2 还可以用3-8 只是默认没有打开
exec 4>&-     # 关闭文件描述符

注
  1 file 表示文件    数字 m n 表示文件描述符
  2 The noclobber option prevents you from overwriting existing files with the > operator. 阻止覆盖已存在文件
    set -o noclobber   # 设置当前shell的noclobber属性 同set -C  关闭 set +o noclobber 同 set +C  详见 set --help
    设置了这个选项之后 xxx > existfile 会失败   但是 xxx >| existfile 可以

实验
exec 6>&1     # 将标准输出与fd 6绑定
ls  /proc/self/fd/  # 0  1  2  3  6  出现文件描述符6
exec 1>suc.txt   # 将接下来所有命令标准输出，绑定到suc.txt文件（输出到该文件）
ls -al        # 执行命令，发现什么都不返回了，因为标准输出已经输出到suc.txt文件了
exec 1>&6     # 恢复标准输出
exec 6>&-     # 关闭fd 6描述符
ls /proc/self/fd/   #0  1  2  3

2>&1 一般总要放到后面 如 xxx >log 2>&1  可以按照下面的方式理解
  过程 1. 本来1->屏幕  2. 执行>log后 1--log  3. 执行2>&1后 2->1 因为1->log 所以2->log
  若写为 2>&1 >log  过程 1. 本来1->屏幕  2. 执行2>&1后 2->1 因为1->屏幕 所以2->屏幕  3. 执行>log后 1->log 2不变 2->屏幕
>log 2>&1 的简写 &>log (更佳) 或 >&log 这3种写法等价 bash文档中有说明






环境变量
Linux 修改环境变量设置的三种方式
/etc/profile 文件     # 对所有的用户的都起作用的环境变量
~/bashrc 文件         # 仅用于当前用户有效的场景
var=value             # 仅当前命令行/控制台/shell可用   可用export导出用户环境变量

shell的两种变量
1 私有变量只在当前shell可见 通过赋值语句定义
  A1="1234"
  delcare A2="2345"   # delcare 可省
2.用户环境变量在所有shell可见 可通过export把私有变量导成用户环境变量
  A1="1234"           # 私有变量
  export A1           # 先定义再导出用户环境变量
  export A3="34"      # 直接定义用户环境变量



echo $PATH            # 显示单一环境变量
env                   # 显示当前用户环境变量
set                   # 显示当前shell所有变量，含私有变量和用户环境变量，按变量名称排序
export                # 显示当前导出成用户环境变量的shell变量，并显示变量的属性(是否只读)，按变量名称排序
export -n xxx         # 删除xxx的导出属性 并没有删除此变量 只是它的属性由用户环境变量变为私有变量
declare               # 同set
unset                 # 删除指定的私有变量或用户环境变量


              [env环境变量]  撤销导出属性
                  ↑  |   export -n aaa
                  |  |                     export aaa=123  定义本地变量的同时导出
  export aaa      |  ↓                     aaa=123         定义本地变量
   导出变量    [set本地变量]                unset aaa        删除变量 不管有没导出

进程的维度理解
set设置当前shell进程的本地变量，只在当前shell的进程内有效，不会被子进程继承和传递。
env仅为将要执行的子进程设置环境变量。
export将shell本地变量提升为当前shell进程的环境变量，从而被子进程自动继承，但export的变量无法改变父进程的环境变量。
source运行脚本的时候，不会启用一个新的shell进程，而是在当前shell进程环境中运行脚本。
exec运行脚本或命令的时候，不会启用一个新的shell进程，并且exec后续的脚本内容不会得到执行，即当前shell进程结束了。

进程和环境变量
进程是一个程序执行的上下文集合，这个集合包括程序代码、数据段、堆栈、环境变量、内核标识进程的数据结构等。
  一个进程可以生成一个子进程，子进程从父进程处继承环境变量。
  环境变量是一组特殊的字符型变量，由于具有继承性质，经常用于父子进程传递参数，这一点在shell编程中尤为突出。

fork和exec
在unix系统中进程通过依次调用fork()和exec()系统调用来实现创建一个子进程。
fork就是克隆，在内存中将当前进程的内存镜像复制一份，只修改新进程的进程号(PID)。
  fork复制整个进程，包括进程运行到哪句代码，父子进程都会继续执行fork后面的代码，从fork开始父子进程才分道扬镳。
exec是一组函数的统称，并且exec的准确定义是，用磁盘上的一个新的程序替换当前的进程的正文段、数据段、堆栈段。
  所以exec并不产生新的进程，而是替换。进程将从新代码的main开始执行，运行一个完全不同的程序，但保留了原来环境变量。
exec函数分两类，一可以设置并传递新环境变量的，二不能传递新环境变量的，只能继承原环境变量的。
  在运行新的程序时，可选择改变新程序的环境变量的，而不只是继承。
  int execve(const char * filename,char * const argv[ ],char * const envp[ ]);  # 通过envp参数设置环境变量
对父进程，可以通过waitpid()函数等待子进程退出，并获得退出状态。
进程可通过setenv或putenv更改自己的环境变量，但环境变量的继承只能单向，即从父进程继承给fork出来的子进程。
  子进程即使修改了自己的环境变量也无法动摇到父进程的环境变量。

shell
shell没有特殊，也是一个进程，在命令行中敲入一个命令，Enter后，shell进程通过fork和exec创建一个子进程（小部分命令不需要启动子进程，称为build-in命令），并且等待(waitpid)这个子进程完成退出。进程的内存镜像显然就包含环境变量。
如 shell命令行中执行ls -al，shell实际执行如下伪代码
  pid = fork();
  if(pid == 0) {
    exec("ls -al"); //子进程中，调用exec
  } else if(pid > 0) {
    waitpid(pid);   //父进程中，waitpid等待子进程退出
  }
默认情况下，在命令行中执行一个shell脚本，shell进程会创建一个sub-shell子进程来执行这个shell脚本，且等待这个子进程执行结束。
set,source,export都是shell的build-in命令，命令本身不会创建新进程。
set跟进程创建无关，也跟环境变量无关，只是当前shell进程内部维护的本地变量，用于变量的引用和展开，不能遗传和继承。
export命令调用putenv将本地变量提升为当前shell的环境变量。环境变量的继承只是单向的，sub-shell中export的变量在父shell中是看不到的。
source ./test.sh   # 让一个脚本中export变量改变父进程的环境变量
source执行脚本，fork和exec不会被调用，当前shell直接对test.sh解释执行。若test.sh中有export，就会改变当前shell的环境变量。
env XXX=crash ./test.sh  # 临时启用环境变量XXX 而不影响后面的命令 因为export几乎会影响到其后的所有命令
env不是shell的build-in命令，所以shell执行env的时候还是需要创建子进程的
env的作用从本质上说，相当于shell先fork，然后在子进程中运行env，子进程env调用execve运行test.sh时，多传了一个XXX=crash的环境变量（上文提到过execve是可以改变默认的继承行为的），这样test.sh可以看到这个XXX环境变量，但由于没有调用putenv改变父shell的环境变量，所以后续启动的进程并不继承XXX。
exec不调用fork，直接调用exec执行！当前shell的代码执行到exec后，代码被替换成了exec要执行的程序，自然地，后续的shell脚本不会得到执行，因为shell本身都被替换掉了。
1.sh    例子
#!/bin/bash
A=B
echo "PID for 1.sh before exec/source/fork:$$"
export A
echo "1.sh: \$A is $A"
case $1 in
    exec)
        echo "using exec…"
        exec ./2.sh;;
    source)
        echo "using source…"
        . ./2.sh;;
    *)
        echo "using fork by default…"
        ./2.sh;;
esac
echo "PID for 1.sh after exec/source/fork:$$"
echo "1.sh: \$A is $A"

2.sh
#!/bin/bash
echo "PID for 2.sh: $$"
echo "2.sh get \$A=$A from 1.sh"
A=C
export A
echo "2.sh: \$A is $A"

然后，分别跑如下参数来观察结果
$ ./1.sh fork     # PID 1 before 315   PID for 2 316   2 get $A=B   2 $A is C   PID 1 after 315   1 $A is B
$ ./1.sh source   # PID 1 before 315   PID for 2 315   2 get $A=B   2 $A is C   PID 1 after 315   1 $A is C
$ ./1.sh exec     # PID 1 before 315   PID for 2 315   2 get $A=B   2 $A is C


 [export]      [no source]                [source]           [exec]            [env]
____________  ____________            _______________    _______________    _______________
|   envs   |  |   envs   |__  fork    |   envs      |    |   envs      |    |   envs       |__  fork
|          |  |          |  ↘________ |             |    |             |    |              |  ↘_______
|   A=x    |  |          |   | envs | |             |    |             |    |              |   | envs |
|__________|  |__________|   |______| |_____________|    |_____________|    |______________|   | A=x  |
|    ↑     |  |./x.sh    |-→ |      | |source ./x.sh|    |exec ./x.sh  |    |env A=x ./x.sh|-→ |______|
|export A=x|  |          |←- |______| |  _________  |    |_____________|    |              |←- |______|
|          |  |          |            | | ./x.sh  | |    |   ./x.sh    |    |              |
|__________|  |__________|            | |_________| |    |             |    |______________|
                                      |_____________|    |_____________|


环境变量配置文件(Ubuntu16.04)
/etc/profile        # 用于设置系统级的环境变量和启动程序，在这个文件下配置会对所有用户生效。当用户登录(login)时，文件会被执行，并从/etc/profile.d目录的配置文件中查找shell设置。如果对/etc/profile修改的话必须重启才会生效
/etc/bash.bashrc    # 每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取。如果想对所有使用bash的用户修改某个配置并在以后打开的bash都生效的话可以修改这个文件，修改之后不用重启，重新打开一个bash即可生效。
~/.profile          # 每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件.
~/.bashrc           # 该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该该文件被读取.
~/.bash_logout      # 当每次退出系统(退出bash shell)时,执行该文件，通常存放清理工作的命令。

全局配置文件
  /etc/profile
  /etc/profile.d/*.sh
  /etc/bashrc
个人配置文件
  ~/.bash_profile
  ~/.bashrc 由上可知，bash 的
profile 类文件作用
  1.设定环境变量
  2.运行命令或脚本（登录时运行的脚本）。
bashrc 类文件配置作用
  1.设定本地变量。
  2.定义命令别名

登陆shell ----> /etc/profile ----> ~/.bash_profile ---->  开始才做bash
                |---> /etc/inputc              |(~/.bash_login ~/.profile)
                |---> /etc/profile.d/*.sh      |---> ~/.bashrc           <---- 非登陆shell
                       |--> /etc/sysconfig/i18n           |-->/etc/bashrc

~/.bash_logout                                                                     # shell登出时读取
/etc/profile –> /etc/profile.d/*.sh –> ~/.bash_profile–> ~/.bashrc –> /etc/bashrc  # 登陆shell执行顺序
~/.bashrc –> /etc/bashrc –> /etc/prodile.d/*.sh                                    # 非登陆shell执行顺序
source ~/.bash_profile 等价 . ~/.bash_profile   # source 脚本 shell环境变量修改之后需要立即生效

su [-lm] [-c 命令] [username]
  -  # "su -" 代表使用login-shell的变量文件读取方式来登陆系统；若使用者名称没有加上，则代表切换为root的身份
  -l # 与 - 类似，但后面需要加欲切换的使用者账号！也是 login-shell 的方式
  -m # -m 与 -p 一样，表示使用目前的环境配置，而不读取新使用者的配置文件
  -c # 仅进行一次命令，所以 -c 后面可以加上命令  如 su -l lixiang -c "pwd"
  注 "su" 表示切换到root用户，以non-login shell的形式登陆；而"su -" 表示以login-shell切换root用户。

登陆shell(login shell)             取得 bash 时需要完整的登陆流程
  通过ssh连接，或由tty1 ~ tty6 登陆，需要输入用户的账号与密码，此时取得的 bash 就称为login shell
  su - username 或 su -l username   # 指定用户登录
  bash -l xx.sh      # 登录模式  bash默认是非登录的，--login选项(简写为-l)为登录式

非登陆shell(non-login shell)       取得 bash 接口的方法不需要重复登陆的举动
  登陆 Linux 后， 再启动终端Terminal，该终端接口并没有输入账号与密码,那个 bash 的环境就 non-login shell
  在原本的bash环境下再次使用bash命令，建立一个bash子进程，同样也没有输入账号密码，那第二个bash是 non-login shell
  su username
  图形终端下打开的命令窗口
  自动执行的 shell 脚本
  bash xx.sh         # 非登录模式

交互式shell(interactive shell)
  终端上shell等待输入，立即执行提交的命令。shell与用户进行交互。登录、执行一些命令、退出。当退出后，shell也终止了。

非交互式shell(non-interactive shell)
  以shell script(非交互)方式执行。shell不与你交互，而是读取存放在文件中的命令并执行。当读到文件结尾EOF，shell就终止了。

tty       # 显示 /dev/pts/4  当前从ssh登陆到服务器
ps        # 显示当前tty        ps -ef|grep pts|grep bash 显示所有的

echo $0            # 显示 -bash 为登陆shell   显示 /bin/bash 为非登陆shell
shopt login_shell  # 显示 login_shell    on为登录shell  off为非登录式    如在脚本中则显示off

echo $-   # himBHs  i表示交互式   echo 'echo $-' | bash  或 bash ./test.sh (.sh中echo $-) 显示 hBs  非交互
echo $PS1 # 非空为交互式 非交互式会清空该变量 如 bash ./test.sh (.sh中echo PS1)为非交互式

通过 Linux 控制台（不是桌面环境自带的终端）或者 ssh 登录 Shell 时（这才是正常登录方式），为交互式的登录 Shell。
在 Linux 桌面环境下打开终端时，为交互式的非登录 Shell。

()中的命令或命令替换进入子Shell时，子Shell会继承父Shell的交互和登录属性。
  bash
  (echo $PS1;shopt login_shell)   # 非登录交互式模式
  bash -l
  (echo $PS1;shopt login_shell)   # 登录交互式模式

ssh 执行远程命令，但不登录时，为非交互非登录式。
  ssh localhost 'echo $PS1;shopt login_shell'       # 非交互非登录模式
  ssh name@ip 'echo $PS1;shopt login_shell'         # 即便是让输入密码 也是非交互非登录模式






shell 脚本(script) 示例 0.sh
https://haicoder.net/shell/shell-function-return.html

执行一个 Shell 脚本，有四种方式，即使用点，.、使用绝对路径或相对路径执行、使用 sh 执行和使用 source 执行。

Shell 中，命令分为内建命令和外部命令
内置命令
Bash 自身提供的命令，而不是文件系统中的某个可执行文件。执行内建命令相当于调用当前 Shell 进程的一个函数。
外部命令
执行外部命令时会触发磁盘 I/O，需要 fork 出一个单独的进程来执行，执行完成后再退出。通常内建命令会比外部命令执行得更快。

help xxx       # help显示内建命令的简要帮助信息
xxx --help     # 外部命令 使用--help参数
man xxx        # 所有命令的详细信息
info xxx       # 所有命令的更见详细描述
type xxx       # 查看命令类型 -a 查询指令搜寻的顺序 同时显示位置 -t 显示(file表示外部命令 alias别名 builtin内置命令) -p 外部指令显示完整文件名

alias                # 查看当前系统所有别名  -p 以可重用的格式打印所有的已定义的别名  一般定义在 ~/.bashrc
alias new_cmd="cmd"  # 设置别名  如 alias lsl='ls -l'
unalias new_cmd      # 删除别名  如 unalias lsl



read [-options] [variables]
从标准输入中读取数据并赋值给变量。默认从键盘读取用户输入的数据；若进行了重定向，可从文件中读取数据。
options    # 命令使用的选项
variables  # 用来存储数据的变量，可以有一个，也可以有多个
options 和 variables 都是可选的，如果没有提供变量名，那么读取的数据将存放到环境变量 REPLY 中。
-a         # array 把读取的数据赋值给数组 array，从下标 0 开始。
-d         # delimiter 用字符串 delimiter 指定读取结束的位置，而不是一个换行符（读取到的数据不包括 delimiter）。
-e         # 在获取用户输入的时候，对功能键进行编码转换，不会直接显式功能键对应的字符。
-n         # num 读取 num 个字符，而不是整行字符。但是分隔符仍然有效
-N         # 在准确读取了 num 个字符之后返回，除非遇到文件结束符或者读超时，任何的分隔符都被忽略
-p         # prompt 显示提示信息，提示内容为 prompt。
-r         # 原样读取（Raw mode），不把反斜杠字符解释为转义字符。
-s         # 静默模式（Silent mode），不会在屏幕上显示输入的字符。当输入密码和其它确认信息的时候，这是很有必要的。
-t         # seconds 设置超时时间，单位为秒。若用户没有在指定时间内输入完成，read 将会返回一个非 0 的退出状态，表示读取失败。
-u         # fd 使用文件描述符 fd 作为输入源，而不是标准输入，类似于重定向。
read -p "please input info > " name url age      # 读取3个变量
read -n 1 -p "Enter a char > " char              # 读取单个字符
read -t 20 -sp "Enter password in 20 seconds > " pass1 && printf "\n"  # 输入密码 不回显 超过20s不输入程序自动结束

读取文件的几种方式
1 按字符数量读取 每次读取一个或多个字符 直到把整个文件读完
read -n 1 data <a.txt       # 只读一个字符
read -n 100 data < a.txt    # 读100个字符，但如果不足100字符时遇到换行符则停止读取
read -N 100 data < a.txt    # 强制读取100字符，遇到换行符也不停止

while read -N 3 data;do     # 正确 按字符数量读取，直到读完文件，将文件放在 while 结构的后面，而不能放在 while 循环的条件位置
  echo "$data"
done <a.txt

while read -N 3 data < a.txt;do  # 错误
  echo "$data"
done

2 按分隔符读取
read -d "m" data <a.txt     # 一直读取，直到遇到字符m才停止，并将读取的数据保存到data变量中

while read -d "m" data ;do  # 如果要按分隔符读取并读完整个文件，则使用 while 循环
  echo "$data"
done <a.txt

3 按行读取
read line <a.txt            # read 默认情况下就是按行读取的，一次读取一行

while read line;do          # 如果要求按行读取完整个文件，则使用 while 循环
  echo "$line"
done <a.txt

4 一次性读整个文件
  1 按照字符数量读取，且指定的字符数要大于文件的总大小
  2 按分隔符读取，且指定的分隔符是文件中不存在的字符，这样的话会一直读取，因为找不到分隔符而读完整个文件
read -N 1000000 data <a.txt  # 指定超出文件大小的字符数量
echo "$data"

read -d "_" data <a.txt      # 指定文件中不存在的字符作为分隔符
echo "$data"





内置命令列表
:          # 扩展参数列表，执行重定向操作
.          # 读取并执行指定文件中的命令（在当前 shell 环境中）
alias      # 为指定命令定义一个别名
bg         # 将作业以后台模式运行
bind       # 将键盘序列绑定到一个 readline 函数或宏
break      # 退出 for、while、select 或 until 循环
builtin    # 执行指定的 shell 内建命令
caller     # 返回活动子函数调用的上下文
cd         # 将当前目录切换为指定的目录
command    # 执行指定的命令，无需进行通常的 shell 查找
compgen    # 为指定单词生成可能的补全匹配
complete   # 显示指定的单词是如何补全的
compopt    # 修改指定单词的补全选项
continue   # 继续执行 for、while、select 或 until 循环的下一次迭代
declare    # 声明一个变量或变量类型。
dirs       # 显示当前存储目录的列表
disown     # 从进程作业表中刪除指定的作业
echo       # 将指定字符串输出到 STDOUT
enable     # 启用或禁用指定的内建shell命令
eval       # 将指定的参数拼接成一个命令，然后执行该命令
exec       # 用指定命令替换 shell 进程
exit       # 强制 shell 以指定的退出状态码退出
export     # 设置子 shell 进程可用的变量
fc         # 从历史记录中选择命令列表
fg         # 将作业以前台模式运行
getopts    # 分析指定的位置参数
hash       # 查找并记住指定命令的全路径名
help       # 显示帮助文件
history    # 显示命令历史记录
jobs       # 出活动作业
kill       # 向指定的进程 ID(PID) 发送一个系统信号
let        # 计算一个数学表达式中的每个参数
local      # 在函数中创建一个作用域受限的变量
logout     # 退出登录 shell
mapfile    # 从 STDIN 读取数据行，并将其加入索引数组
popd       # 从目录栈中删除记录
printf     # 使用格式化字符串显示文本
pushd      # 向目录栈添加一个目录
pwd        # 显示当前工作目录的路径名
read       # 从 STDIN 读取一行数据并将其赋给一个变量
readarray  # 从 STDIN 读取数据行并将其放入索引数组
readonly   # 从 STDIN 读取一行数据并将其赋给一个不可修改的变量
return     # 强制函数以某个值退出，这个值可以被调用脚本提取
set        # 设置并显示环境变量的值和 shell 属性
shift      # 将位置参数依次向下降一个位置
shopt      # 打开/关闭控制 shell 可选行为的变量值
source     # 读取并执行指定文件中的命令（在当前 shell 环境中）
suspend    # 暂停 Shell 的执行，直到收到一个 SIGCONT 信号
test       # 基于指定条件返回退出状态码 0 或 1
times      # 显示累计的用户和系统时间
trap       # 如果收到了指定的系统信号，执行指定的命令
type       # 显示指定的单词如果作为命令将会如何被解释
typeset    # 声明一个变量或变量类型。
ulimit     # 为系统用户设置指定的资源的上限
umask      # 为新建的文件和目录设置默认权限
unalias    # 刪除指定的别名
unset      # 刪除指定的环境变量或 shell 属性
wait       # 等待指定的进程完成，并返回退出状态码



流程结构
if         # 条件判断
if  condition
then
    statement(s)
fi

if  condition; then     # then 和 condition 写在一行 需要加一个分号
    statement(s)
fi



if else    # 条件判断2
if condition
then
   statement
else
   statementn
fi



elif       # 条件判断3
if  condition1
then
   statement1
elif condition2
then
    statement2
elif condition3
then
    statement3
fi



if elif else  # 条件判断4
if  condition1
then
   statement1
elif condition2
then
    statement2
elif condition3
then
    statement3
else
   statementn
fi



case in
支持两种分支结构，分别是 if else 语句和 case in 语句。当分支较多，且判断条件比较简单时，case in 语句较方便。
case expression in
    pattern1)
        statement1
        ;;
    pattern2)
        statement2
        ;;
    pattern3)
        statement3
        ;;
    ……
    *)
        statementn
esac

case、in 和 esac 都是 Shell 关键字，expression 表示表达式，pattern 表示匹配模式。
expression 可以是一个变量、一个数字、一个字符串，一个数学计算表达式，命令的执行结果，只要能够得到 expression 的值就可以。
pattern 可以是一个数字、一个字符串，甚至是一个简单的正则表达式。
case 会将 expression 的值与 pattern1、pattern2、pattern3 逐个进行匹配
expression 和某个模式匹配成功，就会执行这模式后面对应的所有语句，直到遇见双分号;;才停止；跳出 case，执行 esac 后面的语句。
expression 没有匹配到任何一个模式，就执行 *) 后面的语句，直到遇见双分号 ;; 或 esac 结束。 *) 相当于 if 语句中的 else 。
这里的 ;; 和 *) 就相当于其它编程语言中的 break 和 default。



while      # 循环1  当条件成立时，一直执行循环里的逻辑
while condition
do
  statements
done



until循环  # 循环2 当条件不成立时才进行循环，一旦判断条件成立，就终止循环。跟 while 相反
until condition
do
  statements
done


for        # 循环3
for ((express1; express2; express3))
do
  statements
done



for in     # 循环4
for variable in value_list
do
  statements
done
从 value_list 中取出一个值赋给变量 variable，然后进入循环体执行 statements。直到取完 value_list 中的所有值。



select in  # 循环5
select variable in value_list
do
    statements
done
增强交互性，它可以显示出带编号的菜单，用户输入不同的编号就可以选择不同的菜单，并执行不同的功能。
注意，select 是无限循环（死循环），输入空值，或者输入的值无效，都不会结束循环，只有遇到 break 语句，
  或者按下 Ctrl+D 组合键才能结束循环。



continue   # 循环时，在某种条件满足的情况下，需要跳过本次循环，继续执行下一次循环
for ((i = startIndex; i < endIndex; i++))
do
    if ((condition))
    then
        continue;
    fi
    # do something
done



break      # 循环时，在某种条件满足的情况下，需要终止循环的继续执行
for ((i = startIndex; i < endIndex; i++))
do
    if ((condition))
    then
        break;
    fi
    # do something
done





变量
shell 中每一个变量的值都是字符串，无论你给变量赋值时有没有使用引号，值都会以字符串的形式存储。
variable=value           # 定义变量 赋值号 = 的周围不能有空格
variable='value'
variable="value"         # 如果 value 包含了空白符，那么就必须使用引号包围起来。
echo $variable           # 使用变量 只要在变量名前面加美元符号即可
echo ${variable}         # 变量名外面的大括号是可选的，加大括号是为了帮助解释器识别变量的边界

variable=`ls /etc`       # 命令结果赋值给变量 同下
variable=$(ls /etc)

unset variable           # 删除变量 unset 命令不能删除只读变量

local name="test"        # 局部变量（使用local修饰的变量在函数体外无法访问，并且local只能在函数体内使用）
url=xxx
readonly url             # 将变量声明为只读的 不能删除与修改

删除只读变量              # 测试失败 可能是权限问题
cat << EOF| gdb
attach $$
call unbind_variable("只读变量")
detach
EOF

变量的值为变量名
aa=25 bb=aa
echo \$$bb               # $aa 普通shell只对命令做一次解析
eval echo \$$bb          # 25
# 执行过程
# 一次扫描时(同上)       $bb获取到了bb的值aa成功替换 ，替换后整个命令变成了
# echo $aa
# 第二次扫描时        发现命令$aa ,执行替换获取到25，执行echo 25 ,输出 25



变量有三种状态 未定义(unset) 空值(null) 非空值(not null)     分别表示为   - 0 x
str=${var-DEF}    # var 为 -   则str=DEF  var不变       var 为 0 x  则str=$var  var不变
str=${var:-DEF}   # var 为 - 0 则str=DEF  var不变       var 为   x  则str=$var  var不变
str=${var+DEF}    # var 为 -   则str=空  var不变        var 为 0 x  则str=DEF   var不变
str=${var:+DEF}   # var 为 - 0 则str=空  var不变        var 为   x  则str=DEF   var不变
str=${var=DEF}    # var 为 -   则str=DEF  var=DEF       var 为 0 x  则str=$var  var不变
str=${var:=DEF}   # var 为 - 0 则str=DEF  var=DEF       var 为   x  则str=$var  var不变
str=${var?DEF}    # var 为 -   则stderr打印DEF 程序退出  var 为 0 x  则str=$var  var不变
str=${var:?DEF}   # var 为 - 0 则stderr打印DEF 程序退出  var 为   x  则str=$var  var不变
str=${!DEF*}      # 匹配所有以DEF开头的变量 如 声明了变量var var2 var3 则${!va*} 返回 "var var2 var3"
str=${!DEF@}      # 同 ${!DEF*}

-  # 不存在则给默认值，存在则使用原始值
+  # 存在则给默认值，不存在不给值
=  # 不存在则改变变量值，会影响原始变量的值；存在则使用原始值
?  # 不存在则报错，存在则使用原始值

str=12343456
${#str}                # 字符串$str的长度  ${#str} -> 8
${str:pos}             # 从$pos开始提取右侧子串 下标从左向右 从 0 开始  ${str:3} -> 43456
${str:0-pos}           # 从$pos开始提取右侧子串 下标从右向左 从 1 开始  ${str:0-3} -> 456
${str:pos:length}      # 从$pos开始提取右侧长度为$length的子串 下标从左向右 从 0 开始  ${str:3:2} -> 43
${str:0-pos:length}    # 从$pos开始提取右侧长度为$length的子串 下标从右向左 从 1 开始  ${str:0-3:2} -> 45
${str#sub}             # 从$str开头开始删除最短匹配$sub的子串 取右边部分  ${str#*34} -> 3456
${str##sub}            # 从$str开头开始删除最长匹配$sub的子串 取右边部分  ${str##*34} -> 56
${str%sub}             # 从$str结尾开始删除最短匹配$sub的子串 取左边部分  ${str%34*} -> 1234
${str%%sub}            # 从$str结尾开始删除最长匹配$sub的子串 取左边部分  ${str%%34*} -> 12
${str/sub/replace}     # 使用$replace, 来代替第一个匹配的$sub     ${str/34/ab} -> 12ab3456
${str/sub}             # 若没有指定新值，则第一个匹配的字串会被删除 ${str/34} -> 123456
${str/*} 或 ${str/@}   # 删除所有   ${str/*} -> 空   ${str/@} -> 12343456
${str//sub/replace}    # 使用$replace, 代替所有匹配的$sub         ${str//34/ab} -> 12abab56
${str//sub}            # 若没有指定新值，则所有匹配的字串会被删除   ${str//34} -> 1256
${str//*} 或 ${str//@} # 删除所有   ${str//*} -> 空   ${str//@} -> 12343456
${str/#sub/replace}    # 若$str的前缀匹配$sub 就用$replace来代替匹配到的$sub  ${str/#12/ab} -> ab343456
${str/%sub/replace}    # 若$str的后缀匹配$sub 就用$replace来代替匹配到的$sub  ${str/%56/ab} -> 123434ab
str=$str1$str2         # 拼接字符串
name=1,2!3.123 ${name/[[:punct:]]} 12!3.123  # 使用范围符号删除
name=1,2!3.123 ${name//[[:punct:]]} 123123   # 使用范围符号删除
echo `expr index "$string" io`  # 输出 4 查找字符 i 或 o 的位置 string="runoob is" 注意 ` 是反引号




数组
数组中可以存放多个值。bash 只支持一维数组 不支持多维数组 初始化时不需要定义数组大小 数组元素的下标由 0 开始。
array_name=(value1 value2 ... valuen)      # 语法格式 数组用括号来表示 元素用"空格"符号分割开
array_name[0]=value0;array_name[1]=value1  # 使用数字下标来定义数组

关联数组
declare -A array_name  # 语法格式 可以使用任意的字符串或整数作为下标来访问数组元素
  如 declare -A site=(["A"]="A.a" ["B"]="B.b" ["C"]="C.c") # -A 选项就是用于声明一个关联数组 主键唯一
  或 declare -A site;  site["A"]="A.a";site["B"]="B.b";

${array_name[index]}                     # 读取数组单个元素
${array_name[@]} 或 ${array_name[*]}     # 获取数组所有元素
${!array_name[@]} 或 ${!array_name[*]}   # 获取数组的所有键
${#array_name[@]} 或 ${#array_name[*]}   # 获取数组的长度  使用 @ 或 * 将数组转成列表 再次使用 # 获取数组长度
array_new=(${array1[@]}  ${array2[@]})   # 数组拼接  使用 @ 将数组转成列表，再次将两个数组写在一起，实现了数组的拼接
unset array_name[index]                  # 删除数组指定下标的元素
unset array_name                         # 删除整个数组



declare
declare 和 typeset 都是 Shell 内建命令，用法相同，都用来设置变量的属性。不过 typeset 已经被弃用了，建议使用 declare。
declare [+/-] [aAfFgilprtux] [变量名=变量值]
选项      含义
-f [name]           # 列出之前由用户在脚本中定义的函数名称和函数体。
-F [name]           # 仅列出自定义函数名称。
-g name             # 在 Shell 函数内部创建全局变量。
-p [name]           # 显示指定变量的属性和值。
-a name             # 声明变量为普通数组。
-A name             # 声明变量为关联数组（支持索引下标为字符串）。
-i name             # 将变量定义为整数型。
-r name[=value]     # 将变量定义为只读（不可修改和删除），等价于 readonly name。
-x name[=value]     # 将变量设置为环境变量，等价于 export name[=value]。
其中，- 表示设置属性，+表示取消属性，aAfFgilprtux 都是具体的选项。
declare -i m n ret  # 将多个变量声明为整数
declare -i sum=100+300+50  # echo ${sum} -> 450 若没有-i 则  echo ${sum} -> 100+300+50
declare -r n=10     # 将变量声明为只读变量



单引号 '
单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；
单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。

双引号 "
双引号里可以有变量,除$ \ ' " 这几个字符仍是特殊字符并保留其特殊功能外，其余字符仍作为普通字符对待。
双引号里可以出现双引号，只要它被转义了就行  如  \"  解析为 "
其他的转义字符跟单引号一样 原样保存在变量中 单引号 \' 也会保存为 \'

反引号 `
反引号括起来的字符串被shell解释为命令行，执行时，shell首先执行该命令行，并以它的标准输出结果取代整个反引号部分。
反引号还可以嵌套使用。但需注意，嵌套使用时内层的反引号必须用反斜杠（\）将其转义。如下
$ abc=`echo The number of users is \`who| wc -l\``
$ echo $abc
The number of users is 2
在反引号之间的命令行中也可以使用shell的特殊字符。Shell为得到``中命令的结果，它实际上要去执行``中指定的命令。执行时，命令中的特殊字符，如$，”，?等又将具有特殊含义，并且``所包含的可以是任何一个合法的Shell命令，如
$ ls
note readme.txt Notice Unix.dir
$ TestString="`echo $HOME ` ` ls [nN]*`"
$ echo $TestString
/home/yxz note Notice
题外话:反引号是一个老的用法，$()才是新的用法，推荐使用$()，所以上面的的用法可以改成
$ TestString="$(echo $HOME) $(ls [nN]*)"
$ echo $TestString
/home/yxz note Notice



[]
条件表达式 同 test ，且两边和每个组件都需要有空格，例如: [ $a == $b ] # [$a==$b] 错误
if [ 1 -gt 2 ]; then echo 11; else echo 22; fi   # 使用 [...] 判断语句中大于使用 -gt，小于使用 -lt
if ((1 < 2)); then echo 11; else echo 22; fi     # 使用 ((...)) 作为判断语句，大于和小于可以直接使用 > 和 <。


[[]]
1 逻辑运算符 可放入其内 而[] 不行
if [[ 1 -lt 2 && 2 -lt 3 ]]; then echo 11; else echo 22; fi
if [ 1 -lt 2 ] && [ 2 -lt 3 ]; then echo 11; else echo 22; fi  # 同上
if (( 1 < 2 && 2 < 3 )); then echo 11; else echo 22; fi

2 判断条件
[[]] 检测某个条件是否成立。test 能做的，[[]] 也能做，且做的更好；test 做不到的，[[]] 还能做到。[[]] 是 test 的升级版。
[[ expr ]] # 判断 expr 成立时，退出状态为 0，否则为非 0。注意 [[]] 两端的空格是必须的，否则会导致语法错误。
[[]] 是 Shell 内置关键字，不是命令，在使用时没有给函数传递参数的过程，故 test 命令的某些注意事项在 [[]] 中就不存在了，具体有
  不需要把变量名用双引号""包围起来，即使变量是空值，也不会出错。
  不需要、也不能对 >、< 进行转义，转义后会出错。


算术运算符
Shell 不能直接进行算数运算，必须使用数学计算命令。
如果不特别指明，每一个变量的值都是字符串，无论你给变量赋值时有没有使用引号，值都会以字符串的形式存储。
下表列出了常用的算术运算符 假定变量 a 为 10 变量 b 为 20
运算符  说明                          举例
+       加法                          `expr $a + $b` 结果为 30。
-       减法                          `expr $a - $b` 结果为 -10。
*       乘法                          `expr $a \* $b` 结果为  200。
/       除法                          `expr $b / $a` 结果为 2。
%       取余                          `expr $b % $a` 结果为 0。
=       赋值                          a=$b 把变量 b 的值赋给 a。
==      相等 两数字相同返回true        [ $a == $b ] 返回 false。
!=      不相等 两数字不相同返回true     [ $a != $b ] 返回 true。
**     幂运算
++、–   自增和自减，可以放在变量的前面也可以放在变量的后面
!、&&、||             逻辑非（取反）、逻辑与（and）、逻辑或（or）
<、<=、>、>=          比较符号（小于、小于等于、大于、大于等于）
==、!=、=             比较符号（相等、不相等；对于字符串，= 也可以表示相当于）
<<、>>                向左移位、向右移位
~、|、 &、^           按位取反、按位或、按位与、按位异或
=、+=、-=、*=、/=、%= 赋值运算符，例如 a+=1 相当于 a=a+1，a-=1 相当于 a=a-1
注意       条件表达式要放在[]之间

运算操作符/运算命令  说明
(())               用于整数运算，效率很高，推荐使用。不能对小数（浮点数）或者字符串进行运算。
let                用于整数运算，和 (()) 类似。
$[]                用于整数运算，不如 (()) 灵活。
expr               可用于整数运算，也可以处理字符串。比较麻烦，需要注意各种细节，不推荐使用。
bc                 Linux下一个计算器程序，可处理整数和小数。Shell 本身只支持整数运算，想计算小数就得使用 bc 这个外部的计算器。
declare -i         将变量定义为整数，然后再进行数学运算时就不会被当做字符串了。功能有限，仅支持最基本的数学运算（加减乘除和取余），不支持逻辑运算、自增自减等，所以在实际开发中很少使用。
说明  推荐只使用 (()) 和 bc 即可，(()) 可以用于整数计算，bc 可以小数计算。

(()) 双小括号是 Bash Shell 中专门用来进行整数运算的命令
((expr))  # expr表达式可以有一个或多个，多个表达式之间以逗号,分隔，以最后一个表达式的值作为整个 (()) 命令的执行结果。
使用 $ 获取 (()) 命令的结果，这和使用 $ 获得变量值是类似的。
((a=10+66)) ((b=a-15))    # 这种写法可以在计算完成后给变量赋值 使用变量时不用加$前缀，(()) 会自动解析变量名。
a=$((10+66)) b=$((a-15))  # 在 (()) 前面加上$获取 (()) 命令的执行结果，即获取整个表达式的值。不加则出错
((a>7 && b==5))           # (()) 也可以进行逻辑运算，在 if 语句中常会使用逻辑运算。
echo $((a+10))            # 需要立即输出表达式的运算结果时，可以在 (()) 前面加$符号。
((a=3+5, b=a+10))         # 对多个表达式同时进行计算。
$((a++)) $((++a))         # 前自增/后自增
$((--a)) $((a–-))         # 前自减/后自减

let命令  和双小括号 (()) 的用法是类似的，它们都是用来对整数进行运算
let expr      # 其中的 expr 可以不加引号，也可以加单引号和双引号。
let "expr"    # 当表达式中含有 Shell 特殊字符（例如 |）时，需要用双引号 "" 或者单引号 '' 将表达式包围起来。
let 'expr'
let ret=expr  # 将表达式 expr 的运行结果保存到变量 ret 中
let 也支持一次性计算多个表达式，并且以最后一个表达式的值作为整个 let 命令的执行结果。但是，对于多个表达式之间的分隔符，
  let 和 (()) 是有区别的       let 命令以空格来分隔多个表达式；(()) 以逗号,来分隔多个表达式。

expr 命令是 evaluate expressions 的缩写，译为 “表达式求值”。
expr 是一个功能强大，并且比较复杂的命令，它除了可以实现整数计算，还可以结合一些选项对字符串进行处理，
  例如计算字符串长度、字符串比较、字符串匹配、字符串提取等。
语法 expr exprisson
exprisson中的运算符、数字、变量和小括号的左右两边至少要有一个空格，否则会报错。
exprisson有些特殊符号必须用反斜杠 \ 进行转义（屏蔽其特殊含义），比如乘号 * 和小括号 ()，如果不用 \ 转义，
  那么 Shell 会把它们误解为正则表达式中的符号（ * 对应通配符，() 对应分组）。
exprisson使用变量时要加 $ 前缀。
expr 10 + 20   # 注意空格  expr 10+20 则出错 只打印 10+20
expr 4 \* 5    # 注意转义字符 *
expr 2 + \( 4 \* 5 \)   # 注意转义字符 * ()

bc 命令可以很方便的进行浮点运算，当然整数运算也是支持的。
bc 甚至可以称得上是一种编程语言了，它支持变量、数组、输入输出、分支结构、循环结构、函数等基本的编程元素。
https://haicoder.net/shell/shell-bc.html
Shell中bc借助管道使用 bc 计算器。语法 echo "expression" | bc
echo "5+3" | bc
echo "(2+6)*3" | bc


关系运算符
关系运算符只支持数字，不支持字符串，除非字符串的值是数字。
下表列出了常用的关系运算符，假定变量 a 为 10，变量 b 为 20
运算符  说明                                                       举例
-eq     检测两个数是否相等，相等返回 true。                        [ $a -eq $b ] 返回 false。
-ne     检测两个数是否不相等，不相等返回 true。                    [ $a -ne $b ] 返回 true。
-gt     检测左边的数是否大于右边的，如果是，则返回 true。           [ $a -gt $b ] 返回 false。
-lt     检测左边的数是否小于右边的，如果是，则返回 true。           [ $a -lt $b ] 返回 true。
-ge     检测左边的数是否大于等于右边的，如果是，则返回 true。       [ $a -ge $b ] 返回 false。
-le     检测左边的数是否小于等于右边的，如果是，则返回 true。       [ $a -le $b ] 返回 true。

布尔运算符
下表列出了常用的布尔运算符，假定变量 a 为 10，变量 b 为 20
运算符  说明                                                       举例
!       非运算，表达式为 true 则返回 false，否则返回 true。        [ ! false ] 返回 true。
-o      或运算，有一个表达式为 true 则返回 true。                  [ $a -lt 20 -o $b -gt 100 ] 返回 true。
-a      与运算，两个表达式都为 true 才返回 true。                  [ $a -lt 20 -a $b -gt 100 ] 返回 false。

逻辑运算符
以下介绍 Shell 的逻辑运算符，假定变量 a 为 10，变量 b 为 20
运算符  说明          举例
&&      逻辑的 AND    [[ $a -lt 100 && $b -gt 100 ]]  返回 false
||      逻辑的 OR     [[ $a -lt 100 || $b -gt 100 ]]  返回 true
-a      逻辑的 AND    [ $a -lt 100 -a $b -gt 100 ]    返回 true
-o      逻辑的 OR     [ $a -lt 100 -o $b -gt 100 ]    返回 true
!       逻辑的 NOT    [[ !($a -lt 100) ]]             返回 false


字符串运算符
下表列出了常用的字符串运算符，假定变量 a 为 "abc"，变量 b 为 "efg"
运算符  说明                                            举例
= 或 == 检测两个字符串是否相等，相等返回 true。         [ $a = $b ] 返回 false。
!=      检测两个字符串是否不相等，不相等返回 true。     [ $a != $b ] 返回 true。
-z      检测字符串长度是否为0，为0返回 true。           [ -z $a ] 返回 false。
-n      检测字符串长度是否不为 0，不为 0 返回 true。    [ -n "$a" ] 返回 true。
$       检测字符串是否不为空，不为空返回 true。         [ $a ] 返回 true。
str1 > str2 判断 str1 是否大于 str2 \>是转义字符，这样写是为了防止>被误认为成重定向运算符   [ $str1 \> $str2 ]
str1 < str2 判断 str1 是否小于 str2。 同样，\<也是转义字符


文件测试运算符
文件测试运算符用于检测 Unix 文件的各种属性。属性检测描述如下
操作符  说明                                                                        举例
-b file 检测文件是否是块设备文件，如果是，则返回 true。                          [ -b $file ] 返回 false。
-c file 检测文件是否是字符设备文件，如果是，则返回 true。                        [ -c $file ] 返回 false。
-d file 检测文件是否是目录，如果是，则返回 true。                                [ -d $file ] 返回 false。
-e file 检测文件（包括目录）是否存在，如果是，则返回 true。                       [ -e $file ] 返回 true。
-f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。
-g file 检测文件是否设置了 SGID 位，如果是，则返回 true。                        [ -g $file ] 返回 false。
-L file检测文件是否存在并且是一个符号链接。
-k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。              [ -k $file ] 返回 false。
-p file 检测文件是否是有名管道，如果是，则返回 true。                            [ -p $file ] 返回 false。
-u file 检测文件是否设置了 SUID 位，如果是，则返回 true。                        [ -u $file ] 返回 false。
-r file 检测文件是否可读，如果是，则返回 true。                                  [ -r $file ] 返回 true。
-w file 检测文件是否可写，如果是，则返回 true。                                  [ -w $file ] 返回 true。
-x file 检测文件是否可执行，如果是，则返回 true。                                [ -x $file ] 返回 true。
-s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。                  [ -s $file ] 返回 true。
-S file 判断该文件是否存在，并且是否为套接字文件，是W返回 true。                  [ -s $file ] 返回 true。

文件比较
选项             作用
file1 -nt file2  判断 file1 的修改时间是否比 file2 的新。
file1 -ot file2  判断 file1 的修改时间是否比 file2 的旧。
file1 -ef file2  判断 file1 是否和 file2 的 inode 号一致，这个用于判断硬链接是很好的方法



函数
1 使用函数前，必须先声明与定义函数。
函数定义
function func1() {          # 若关键字function省略 则()不能省略 否则 () 可省
    statements              # {} 包围的为函数体
    [return value]          # value必须为数字 return是Shell 关键字 若省则函数返回值为最后一条命令的退出状态
}

2 函数调用
func1 param1 param2 param3  # 函数名 参数
echo $?                     # 函数返回值 $? 是一个特殊变量 用来获取上一个命令的退出状态 或上一个函数的返回值

3 函数返回值
  1 通过全局变量的方式 函数内对全局变量赋值
  2 函数内 return value     只能返回数字
    函数内 echo xx1;echo xx2;return $?
      外部 以$(func param1 param2) 或者 `func param1 param2` 捕获之 可以赋值给一个变量
      注意 函数内echo不打印 而是把它们整合成一个变量放回 中间以空格分隔

4 函数参数
在Linux bash中，可以用以下三种方式解析命令行参数
直接处理       使用$1,$2,$3…进行解析
getopts: 单个字符选项的情况，例如       -n 10 -f file.txt等选项
getopt       处理单个字符或长选项（long-option），例如       –prefix=/home等
经验       小型脚本可以直接处理，大多数情况使用getopts，getopt的功能更加强大。

eval
  1 把字符串当命令执行
bash-4.2$ # script="cat getopt.sh"
bash-4.2$  # eval $script
#!/bin/bash
rr=$(getopt ab:cd -a yyy -b test1 -cd test2 test3)
echo $rr

bash-4.2$  # eval "ll .."
total 3780
-rw-r--r--   1 root root    4096 Mar 13  2020 ?
drwxr-xr-x   2 root root    4096 Dec 24  2020 bin
……

  2 变量套用(最多两层)
bash-4.2$  # t=tttt
bash-4.2$  # tttt=tttttt
bash-4.2$  # eval echo \$$t
tttttt

set
将$1 $2 $3……设为固定的值  举例如下
bash-4.2$ # cat test.sh
#!/bin/bash
echo $1 $2 $3
set -- aa bb cc
echo $1 $2 $3
bash-4.2$ # sh test.sh a b c
a b c
aa bb cc

shift
将参数左移n个，也可以理解为删除前n个参数($0不受影响)
默认为1，shift 或 shift 1  都是取消 $1 ，而原本的 $2 则变为 $1、$3 变为 $2 ...
同理 shift 3 是取消前面三个参数，也就是原本的 $4 将变为 $1 所以使用 shift 9 则 原本的 $10 将变为 $1 举例如下
bash-4.2$ # cat test.sh
#!/bin/bash
set -- aa bb cc dd ee ff gg hh
echo $1 $2 $3 $4 $5 $6 $7 $8
shift 3
echo $1 $2 $3 $4 $5 $6 $7 $8
bash-4.2$ # sh test.sh
aa bb cc dd ee ff gg hh
dd ee ff gg hh

4.1 类似脚本参数 ./xx.sh p1 p2 p3   脚本中 $0 也表示当前脚本的文件名
函数内部可以使用 $n 来接收，例如，$0 当前脚本的文件名./xx.sh $1 表示第一个参数 p1，$2 表示第二个参数 p2，依次类推。
$# 传递的参数的个数           # 3
$* 一次性获取所有的参数       # "p1" "p2" "p3"  #将接收到的每个参数看做一份数据 彼此之间以空格来分隔 （传递了n个参数）
"$*" 一次性获取所有的参数     # "p1 p2 p3"      #以"$1 $2 … $n"的形式输出所有参数 （传递了一个参数）
$@ 一次性获取所有的参数       # 同$*
"$@" 一次性获取所有的参数     # "p1" "p2" "p3"  #以"$1" "$2" … "$n" 的形式输出所有参数 （传递了n个参数）同$@
$$                          # 脚本运行的当前进程ID号
$!                          # 后台运行的最后一个进程的ID号
$-                          # 显示Shell使用的当前选项，与set命令功能相同
$?                          # 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误

注意 位参(positional parameter) 中的 $10 不是替換第10个参数，而是替換第1个参数($1)然后再补一个 0 于其后
如 ./my.sh a1 a2 a3 a4 a5 a6 a7 a8 a9 aa 中 $10 不是 aa 而是 a10
要抓到 aa，有两种方法
  1 ${} ，也就是用 ${10} 即可。
  2 shift 9


函数参数 默认分隔符为空格 若参数中有空格 处理方式2种
  1 用 "" 把参数包围起来
  2 修改分隔符
    IFS_BAK=$IFS       # 备份默认分隔符
    IFS="!!"           # 指定新的分隔符
    XXX
    IFS=$IFS_BAK       # 恢复系统默认分隔符

4.2 getopts optstring name [arg...]
getopts是bash的内部命令 有两个参数
optstring是一个选项字符串 包括字符和: 每一个字符都是一个有效选项
  字符后面带有: 表示这个选项有自己的参数，其值保存在内置变量 OPTARG 中，需要以空格分隔。如 d:  表示 -d value
  字符后面带有:: 表示这个选项有自己的参数的值可选。  如 d::  表示-d 或者 -d value
  冒号和问号不能被用作选项字符。getopts每次被调用时，它会将下一个选项字符放置到变量中，
  optstring 前面加冒号 则代表忽略错误
  OPTARG 总是存储原始$*中当前要处理的选项的参数 没有则为空  如  -d value 中 OPTARG 存储 value
  OPTIND 存放存储原始$*中下一个要处理的参数的index
  optstring 为 afs   # 识别-a，-f以及-s参数
  optstring 为 a:fs  # 表示a参数后面会有一个值出现，-a value的形式。

举例说明
bash getopts.sh -a 12 -b -c file1 file2     # 调用下面的脚本

#!/bin/bash

echo original parameters=[$*]               # original parameters=[-a 12 -b -c file1 file2]
echo original OPTIND=[$OPTIND]              # original OPTIND=[1]
while getopts ":a:bc" opt                   # 第一个冒号表示忽略错误
do
  case $opt in
    a)
      echo "this is -a option. OPTARG=[$OPTARG] OPTIND=[$OPTIND]"  # this is -a option. OPTARG=[12] OPTIND=[3]
      ;;
    b)
      echo "this is -b option. OPTARG=[$OPTARG] OPTIND=[$OPTIND]"  # this is -b option. OPTARG=[] OPTIND=[4]
      ;;
    c)
      echo "this is -c option. OPTARG=[$OPTARG] OPTIND=[$OPTIND]"  # this is -c option. OPTARG=[] OPTIND=[5]
      ;;
    ?)
      echo "there is unrecognized parameter."
      exit 1
      ;;
  esac
done
shift $(($OPTIND - 1))                      # 通过shift处理 $*中就只保留了除去选项内容的参数
echo remaining parameters=[$*]              # remaining parameters=[file1 file2]
echo \$1=[$1]                               # $1=[file1]
echo \$2=[$2]                               # $2=[file2]


4.3 getopt
getopt是一个外部命令，通常Linux发行版会自带
getopt支持短选项和长选项
增强版getopt比较好用，执行命令getopt -T; echo $?,如果输出4，则代表是增强版
如果短选项带argument且参数可选时，argument必须紧贴选项，例如-carg而不能是-c arg
如果长选项带argument且参数可选时，argument和选项之间用“=”，例如-–clong=arg而不能是-–clong arg
-o或--options选项后面是可接受的短选项，如ab:c::，表示可接受的短选项为-a -b -c，-a选项不接参数，-b必须接参数，-c参数为可选的
-l或--long选项后面是可接受的长选项，用逗号分开，冒号的意义同短选项。
-n选项后接选项解析错误时提示的脚本名字

举例说明
#!/bin/bash

echo original parameters=[$@]

ARGS=`getopt -o ab:c:: --long along,blong:,clong:: -n "$0" -- "$@"`
if [ $? != 0 ]; then
  echo "Terminating..."
  exit 1
fi

echo ARGS=[$ARGS]
eval set -- "${ARGS}"               # 将规范化后的命令行参数分配至位置参数($1,$2,...)
echo formatted parameters=[$@]

while true
do
  case "$1" in
    -a|--along)
      echo "Option a";
      shift
      ;;
    -b|--blong)
      echo "Option b, argument $2";
      shift 2
      ;;
    -c|--clong)
      case "$2" in
        "")
          echo "Option c, no argument";
          shift 2
          ;;
        *)
          echo "Option c, argument $2";
          shift 2;
          ;;
      esac
      ;;
    --)
      shift
      break
      ;;
    *)
      echo "Internal error!"
      exit 1
      ;;
  esac
done

echo remaining parameters=[$@]      # 处理剩余的参数
echo \$1=[$1]
echo \$2=[$2]

测试结果
短选项
$ bash getopt.sh -a b1 -c2 file1 file2
original parameters=[-a b1 -c2 file1 file2]
ARGS=[ -a -c '2' -- 'b1' 'file1' 'file2']
formatted parameters=[-a -c 2 -- b1 file1 file2]
Option a
Option c, argument 2
remaining parameters=[b1 file1 file2]
$1=[b1]
$2=[file1]

长选项
$ bash getopt.sh --along --blong=1 --clong=2 file1 file2
original parameters=[--along --blong=1 --clong=2 file1 file2]
ARGS=[ --along --blong '1' --clong '2' -- 'file1' 'file2']
formatted parameters=[--along --blong 1 --clong 2 -- file1 file2]
Option a
Option b, argument 1
Option c, argument 2
remaining parameters=[file1 file2]
$1=[file1]
$2=[file2]

长短混合
$ bash getopt.sh -a -b1 --clong=2 file1 file2
original parameters=[-a -b1 --clong=2 file1 file2]
ARGS=[ -a -b '1' --clong '2' -- 'file1' 'file2']
formatted parameters=[-a -b 1 --clong 2 -- file1 file2]
Option a
Option b, argument 1
Option c, argument 2
remaining parameters=[file1 file2]
$1=[file1]
$2=[file2]

可选参数出错的情况
短选项和所带argument中间含有空格
$ bash getopt.sh -a -b 1 -c 2 file1 file2
original parameters=[-a -b 1 -c 2 file1 file2]
ARGS=[ -a -b '1' -c '' -- '2' 'file1' 'file2']
formatted parameters=[-a -b 1 -c -- 2 file1 file2]
Option a
Option b, argument 1
Option c, no argument
remaining parameters=[2 file1 file2]
$1=[2]
$2=[file1]

长选项和所带argument中间含有空格
$ bash getopt.sh --along --blong 1 --clong 2 file1 file2
original parameters=[--along --blong 1 --clong 2 file1 file2]
ARGS=[ --along --blong '1' --clong '' -- '2' 'file1' 'file2']
formatted parameters=[--along --blong 1 --clong -- 2 file1 file2]
Option a
Option b, argument 1
Option c, no argument
remaining parameters=[2 file1 file2]
$1=[2]
$2=[file1]









shell command--------------------------------------------------------------------

文件管理
modification time(mtime)   # 文件内容数据变更时 该时间会被更新
status time(ctime)         # 文件状态改变时 该时间会被更新   如权限被更改了
access time(atime)         # 文件内容被取用时 该时间会被更新 如使用 cat 去读取
.            # 代表此层目录
..           # 上一层目录
-            # 前一个工作目录
~            # 目前用户身份坐在的家目录
~account     # 表示 account 这个用户的家目录

basename /etc/sysconfig/network  # 文件名 network
dirname /etc/sysconfig/network   # 目录名 /etc/sysconfig
pwd [参数]   # 显示当前目录 printing current directory  -P 显示物理地址 默认值 -L 目录为链接路径时显示连接路径
cd [目录名]  # 切换目录 change directory  / 根目录 . 当前目录 .. 父目录 ~ 当前用户主目录 - 上次所在目录
ls [选项] [目录名]    # 列出对应目录清单 list  -l 详细信息 -t 按时间排序 -s 以块数形式显示每个文件分配的尺寸 -S 大小排序 -t 时间排序 -r 反序 -R 连同子目录内容一起列出来 -X 扩展名 -h 易读方式 -i inode号 -d 只看当前目录的信息 -a 显示所有文件 -A 除"."和".."以外的文件 -f 不排序 -F 后缀附加数据信息(*可执行文件 /目录 =socket文件 |FIFO文件) -n 列出UID与GID -full-time 完整时间模式年月日时分输出 --time=[mtime ctime atime] 修改/状态/获取时间
mkdir [选项] [目录名] # 创建目录 make directory -m 直接设置权限mode，不管umask -p 多层目录 -v 每次创建新目录都显示信息verbose
rmdir        # 删除空的目录  -p 多层目录
touch [选项] [文件]   # 更新文件时间或创建新文件 -a 只更改访问时间 atime -c 不创建新文件仅修改存在文件的时间 -m 只更改修改时间 mtime -d 后面可以接欲修订的日期而不用目前的日期 -t 使用指定字符串表示时间而非当前时间 格式为 YYYYMMDDhhmm
rm [选项] [文件/目录名] # 删除 remove -r 递归 -f 强制删除不被提示force -i 交互式删除interactive -v 详细步骤verbose
mv [选项] [源文件/目录名] [目标文件/目录名]  # 移动move  -b 覆盖前备份back -f 强制覆盖 -i 询问覆盖 -u 源文件较新时覆盖update -t 移动多个源文件到同一目录下 此时目录在前 源文件在后target
cp [选项] [源文件/目录名] [目标文件/目录名]  # 复制copy -r 递归 -s 符号链接 -l 硬连接 -t 指定目标目录 目标目录在前 源文件在后target -i 覆盖询问 -f 强制覆盖 -p 属性一起复制 -d 源文件为链接文件则复制链接文件 -u 目标不存在或比源旧才复制

which # 在PATH变量指定的路径中搜索可执行文件 并返回第一个搜索结果  -a PATH下所有的结果 如which gcc  连续两次tab补全功能
whereis [选项] [文件] # 特定的目录中搜索不是全盘查找  -l 列出会去查询的几个主要目录 -b 只搜索二进制文件 -m 只搜索manual路径下的文件 -s 只搜索source来源文件 -u 搜索不在上述三个选项中的其他特殊文件
locate [选项] [文件]  # 定位文件 模糊搜索 依据数据库/var/lib/mlocate/ updatedb指令手动更新数据库 根据/etc/updatedb.config -i 忽略大小写 -c 仅计算找到的文件数量 -l x 仅输出几行 -q 不显示出错信息 -S 输出locate所使用的数据库文件相关信息，包括该数据库记录的文件/目录数量等 -n 最多显示n个 -r 使用正则
find [路径] [表达式]  # 搜索指定的路径 -print 输出到标准输出 -delete 删除搜索到的文件 -exec 对搜索到的文件执行命令 -name 按名字 -type 按类型 (b块设备文件 c字符设备文件 d目录 f普通文件 l符号链接) -perm 按权限 -user 所有者 -mtime 按时间 -size 按大小 -and -or -not 逻辑操作符
  find . -type f \( !-perm 777 -and -perm 644 \)   # ()圆括号在shell中有特殊含义 若命令中使用这需要 \ 进行转义
  find . xxx -exec cat {} \;   # {}就是占位符 表示在find执行中不断替换找到的文件 \; 是-exec命令结束的标记 因为规定-exec必须以 ; 结束 但shell中 ;有特殊含义 必须要转义 所以写成 \;
  find / ! -regex ".*/code.*" -exec grep xxx {} -n -H --color \;  # 从 / 开始 排除路径名中有 code的 查找 xxx

ls -l | grep "^-" | wc -l              # 当前目录下（不包括子目录）文件数量
find ./ -maxdepth 1 -type f | wc -l    # 同上
ls -lR | grep "^-" | wc -l             # 当前目录下包括的文件数量 注意若要统计隐藏文件 则 ls -laR ...
find ./ -type f | wc -l                # 同上 默认含隐藏文件

ln –s 源文件 软连接                 # 如 ln -s abc abc_soft_link
ln -snf 新源文件 软链接地址         # 修改软连接指向 或ln -sf  如 ln -snf abd abc_soft_link
rm -rf 软连接                      # 只删除软连接本身而不是其指向的文件 不用rf同样效果  如 rm -rf abc_soft_link
readlink 软连接文件                # 查看软连接源文件路径  如 readlink abc_soft_link  输出 abc

umask      # 文件权限掩码  -S 以符号形式输出
chown 用户[:组] 文件/目录  # 修改文件所有者 -R 递归
chgrp 组 文件/目录        # 修改文件所在组 -R 递归 如果是目录，则变更该目录以及目录下的所有文件
chmod mode 文件/目录      # 修改文件权限 -R 递归 mode为数字格式 如777 或符号格式[u g o a] [+ - =] [r w x s t] 如u+x
  SUID:4 u+s Set UID 只能对二进制文件设置 执行该程序时执行者将具有该程序拥有者的权限   chmod 4777 xx   chmod u+s xx
  SGID:2 g+s Set GID 设置文件 执行者在执行该文件的过程中将会获得该程序群组的支持
    设置目录 用户在此目录下的有效群组将会变成该目录的群组 用户建立(有wx权限)的新文件的群组与此目录的群组相同
  SBIT:1 o+t Sticky Bit 目前只针对目录有效  用户在该目录下创建的文件或目录(有wx权限)，仅自己与root有权删除

chattr [+-=][ASacdistu] 文件或目录名称  # 配置文件隐藏属性 除了基本9个权限外 ext2/3/4 中完全支持  xfs仅支持 AadiS 选项
  A # 若有存取此文件/目录时，它的访问时间 atime 将不会被修改
  S # 对文件的修改变成同步写入磁盘中，一般默认是异步写入（sync）
  a # 该文件只能增加数据，不能删除也不能修改数据，只有 root 才能设置该属性
  c # 自动将此文件压缩，在读取的时候也将会自动解压缩，但是在存储的时候，会先压缩后再存储（对大文件似乎有用）
  d # 当 dump 程序被执行的时候，可使该标记的文件或目录不被 dump 备份
  i # 让文件不能被删除、改名、设置连接、写入或新增数据，完完全全就是只读文件了。只有 root 能设置该属性
  s # 当文件被删除时，将会被完全的移除这个硬盘空间，所以如果误删，就找不回来了
  u # 与 s 相反，删除后，其实数据还在磁盘中，可以用来救援该文件
lsattr [-adR] 文件或目录   # 显示文件隐藏属性  a 显示隐藏文件的属性 d 若是目录 仅列出目录本身的属性而非目录内的文件名 R 连同子目录的数据也列出来
tree            # 显示路径树状图 /f显示文件


文本处理
cat [选项] [文件]  # 将文件或标准输入组合输出到标准输出 concatenate  -n 输出行号含空白行 -b 只对非空行编号number-noblank -s 多个空白行装转化为一个空白符squeeze-blank  -A=-vET -E 每行结束处显示"$" -v 使用^ 和M- 引用 除LFD和TAB外 -T tab键显示为^I -E 行尾符显示为$
tac [选项] [文件]  # 将每个指定文件按行倒置并写到标准输出 从最后一行开始显示
more [选项] [文件] # 按页显示文件 操作       空格/回车 下一页 b/ctrl+b 上一页 = 当前行号 /xx 向下搜索 q 退出   选项       +n 第n行开始显示 -n 屏幕大小 +/pattern 搜索字符串 从该字符串前2行开始显示 如more +11 +/data a.file
less [选项] [文件] # 显示文件  操作       /xx 向下搜索 ?xx向上搜索 n 重复搜索 N 反向搜索 可用上下键 翻页键 空格 g 第一行 G 最后一行 q 退出  选项       -f 强制打开 -i 忽略大小写 -N 显示每列行号 -s 连续空行显示为一行
  cat more less区别  # cat没有分页 cat 可以合并文件less 其他2个可分页
head [选项] [文件]  # 显示文件开头 默认10行  -q 隐藏文件名 -v 显示文件名 -c x 显示x字节数 -n x 显示行数 x为负 显示文件末尾行
tail [选项] [文件]  # 显示文件末尾 默认10行  -n x 显示行数 -f 跟随文件
wc [选项] [文件]   # 计算数量 word count  -c 字节数 -l 行数 -w 单词数 -m 字符数 -L 最长行的长度
nl [选项] [文件]   # 行号打印 number of line   -b a 空行显示行号 (cat -n) -b t 空行不显示行号 默认 -w 行号拦位数 -n ln 行号在栏位最左方显示 -n rn 行号在栏位最右方显示 不加0 -n rz 行号在栏位最右方显示 加0  如nl -n rz -w 3 a.file

grep [选项] pattern [file]   # 文本搜索 global search regular expression and print out the line  -w 精确匹配 -i 忽略大小写 -n 输出行号 -v 反向匹配 -r 递归 -E 使用扩展正则 没有则只使用基本正则(后面有说明) -color=auto 关键字加颜色 -o 只输出匹配项而非整行 若同一行中有多个匹配项则多行输出 -I 忽略二进制文件 -l 仅列出符合条件的文件名 --include 过滤文件 如--include="*.[hc]"仅过滤.h 和.c文件 如--include=*.{h,cpp}仅过滤.h 和.cpp文件 --exclude xxx 文件名字不匹配 -e 多个查找条件的匹配，逻辑or关系 -c 输出匹配到的总行数(不是匹配到的次数) -q 不显示所有常规输出 -a 将binary文件以text文件的方式搜索数据 -A n 为after 除了列出该行外，后续的n行也列出来 -B n 为befer，除了列出该行外，前面的n行也列出来 -c 打印匹配的数量
  grep -e "\<1" -e "\<a" file  # 查找分别以1 和 a 开头的单词
  grep -rin --include=*.h ifaddrs path  # 在路径path中 文件名字匹配*.h 中搜索ifaddrs
  ps -ef | grep '/home/helife/tomcat-wap/' | grep -v "grep"  # 查看包含 '/home/helife/tomcat-wap/' 但不包含 "grep" 的进程

cut [选项] [文件]  # 文本切分 -b 以字节为单位分割 -c 以字符为单位分割(-c 5 第5个  -c -5 前5个  -c 5- 前5个之后的  -c 2-5 第2-5个) -d 分隔符 默认为制表符 -f 自定义字段(-f 1 第1列 -f 1,3 第1 3列 -f 1-3 前3列) -complement 抽取除-c -f指定的文本外的整行文本  如cut -f 1 -d '' file -complement  cut -c 9-15 截取行的第9到15个字符，这正好是进程号PID (ps -ef 中PID范围)

sed [选项] [操作] [文件]  # 流编辑器 一行行读取 常用于一整行的处理
  选项
    -i[扩展名] 直接修改文件 指定扩展名则备份文件
    -n 安静模式(silent) 只有经过sed特殊处理的那一行(或动作)才会被打印出来 默认所有STDIN数据都会列出到屏幕上
    -e 直接在指令模式上进行sed的动作编辑 同时执行多份script  如sed -e "s/foo/bar/" -e "/FOO/d" 每行先用bar替换foo 在删除FOO
    -f file 执行sed脚本
    -r sed的动作支持是延伸类型正则表达式的语法 默认是基础正则表达式语法
  操作 ' {[n1[,n2]]func}' 最好加单引号   n1,n2 选择进行动作的行数 func是进行的动作 如下
    a str # 新增 str在新一行出现(当前行下)(a后空格可省 多个空格默认无视 下同)   cat 1 | sed '1,2aDD' 前两行下一行都多一行
    c str # 替换 str替换 n1,n2 之间的行   cat 1 | sed '1,2cDD' 前两行替换成DDD
    d     # 删除 后不接任何str   cat 1 | sed '1,2d'   nl file | sed '2,5d'  file显示行号并删除2-5行
    i str # 插入 str在新一行出现(当前行上)   cat 1 | sed '1,2iDD'   前两行上一行都多一行
    p     # 打印 p常与 sed -n 一起运作   cat 1 | sed -n '1,2p'  打印前2行
    s     # 替换 常搭配正则表达式 如 sed -i '1,20s/"str1"/"str2"/g' `grep "str1" -rl --include="*.[hc]" ./`

awk [选项] 'BEGIN{ } 条件类型1{动作1} 条件类型2{动作2} ... END{ }' file # 以行为一次处理的单位 以字段为最小的处理单位 将一行分成数个字段来处理 默认分隔符为空格或tab  一个或多个连续的空格或制表符看做一个定界符，即多个空格看做一个空格
  -F 定义列分隔符     如 -F":" 同 -F:
  -f 指定调用脚本     如 awk -f script.awk
  -v 定义变量
  处理流程
    读入第一行，并将第一行的内容填入 $0、$1... 变量中
    依据 条件类型 的限制，判断是否需要进行后面的 动作
    做完所有的动作与条件类型
    若还有后续的「行」数据，则重复上面 1~3 步骤，直到所有数据都处理完为止
  变量
    $0 整行数据  $1 第一个字段  ...
    NF  每一行字段总数     awk '{print NF}' file 显示每行有多少字段  awk '{print $NF}' file 将每行第NF个字段的值打印出来
    NR  每行的记录号，多文件记录递增
    FS  目前的分割字符，默认是空格    FS="",每个字符都是一段
    RS  输入的记录分隔符， 默认为换行符(即文本是按一行一行输入)
    非变量需要使用双引号引用起来            如 awk '...  "ABC" '
    {}中可设置变量，进行运算 多条命令用 ; 分割  如 awk '...  {total==$1+$2+$3 ; ...} '
    {}中可支持 if()                       如 awk '...  {if(NR==1) printf "%10s %10i % 10.2f\n",$1,$2,$3} '
      awk -F: '{if($1~/mail/) print $1}' /etc/passwd                        简写
      awk -F: '{if($1~/mail/) {print $1}}'  /etc/passwd                     全写
      awk -F: '{if($1~/mail/) {print $1} else {print $2}}' /etc/passwd      if...else...
      awk -F: '{if($1~/mail/) print $1; else {print $2}}' /etc/passwd       同上
    OFS  输出字段分隔符， 默认也是空格，可以改为制表符等  awk '$6 ~ /WAIT/ || NR==1 {print NR,$4,$5,$6}' OFS="\t" netstat.txt  输出字段6匹配WAIT的行，其中输出每行行号，字段4，5,6，并使用制表符分割字段
    ORS  输出的记录分隔符，默认为换行符,即处理结果也是一行一行输出到屏幕
  逻辑运算符号
    >  大于           awk -F: 'NF>2{print $0}' /etc/passwd  显示每行字段数量大于2的行  print $0 同 print
    <  小于           awk -F: '$3+$4 < 200' /etc/passwd
    >= 大于或等于
    >= 小于或等于
    == 等于           awk -F: 'NF==4 {print }' /etc/passwd  显示只有4个字段的行 同 '{if(NF==4) {print }}'
    != 不等于
    ~  匹配，与==相比不是精确比较
    && 逻辑与                  awk -F: '$1~/mail/ && $3>8 {print }' /etc/passwd  逻辑与，$1匹配mail，并且$3>8 同  '{if($1~/mail/ && $3>8) print }'
    || 逻辑或                  awk -F: 'NR==5 || NR==6{print}'  /etc/passwd   显示第5行和第6行
    +  匹配时表示1个或1个以上   # /[0-9][0-9]+/ 两个或两个以上数字  /[0-9][0-9]*/ 一个或一个以上数字
  匹配代码块
    //纯字符匹配          awk '/mail/' /etc/passwd 同 '/mail/{print }' 同 '/mail/{print $0}' 输出匹配mail的行
    !//纯字符不匹配       awk '!/mail/{print $0}' /etc/passwd
    区间匹配              awk -F: '/mail/,/list/{print}' /etc/passwd
    ~//字段值匹配         awk -F: '$1~/mail/{print $1}' /etc/passwd $1匹配指定内容才显示 同'{if($1~/mail/) print $1}'
    !~//字段值不匹配      awk -F: '$1!~/mail/{print $1}' /etc/passwd
    ~/a1|a2/字段值匹配a1或a2   awk '!/mysql|mail/{print}' /etc/passwd
  while
    awk -F: 'BEGIN{i=1} {while(i<NF) print NF,$i,i++}' /etc/passwd
  print
    awk -F":" '{print $1 $3}'  /etc/passwd                  $1与$3相连输出，不分隔
    awk -F":" '{print $1,$3}'  /etc/passwd                  多了一个逗号，$1与$3使用空格分隔
    awk -F":" '{print $1 " " $3}'  /etc/passwd              $1与$3之间手动添加空格分隔
  printf 格式化输出
  如
    last -n 5 | awk '{print $1 "\t lines:" NR "\t columns:" NF}'  # 最后5条登录账户 第几行 当前行有几个字段
    cat /etc/passwd | awk '{FS=":"} $3 < 10 {print $1 "\t" $3}'   # : 分割字段，$1为账户 $3为UID 第一行FS无效
    cat /etc/passwd | awk 'BEGIN {FS=":"} $3 < 10 {print $1 "\t" $3}'  # 第一行FS生效
    cat /etc/passwd | awk -F ':' '$3 < 10 {print $1 "\t" $3}'  # 同 第一行FS生效
    cat /etc/passwd | awk 'NR==1 FS=":" {printf "%10s %10s %10s %10s %10s\n",$1,$2,$3,$4,"total"}' # 显示第一行
  输出处理结果到文件
    route -n|awk 'NR!=1{print > "./fs"}'        在命令代码块中直接输出
     route -n|awk 'NR!=1{print}'  > ./fs        使用重定向进行输出
paste [选项] [文件]  # 与cut相反 将文件按照行合并 以tab分割  -s 将每个文件合并成一行 -d 分隔符 默认为制表符 - 标准输入
tr [选项] SET1 [SET2]  # 标准输入中替换 缩减 删除字符 并将结果写到标准输出 translate -d 删除匹配SET1的字符 -s 去除SET1中指定的在输入文本中连续并重复的字符
  echo "This is 123 !" | tr 'a-z' 'A-Z'  # 小写字符转化为大写  THIS IS 123 !
  echo "This is 123 !" | tr -d '0-9'     # 删除数字   This is  !
  echo "This iiiis 123 !" | tr -s 'i'    # This is 123 !
col [选项]  # 将tab换成对等的空格 或反之  -x tab转空格 -h 空格转tab 默认   如 cat /etc/protocols | col -x | cat -A
expand [选项] file # 将tab转成空格 -t 设置制表符为指定数字的宽度，而不是默认的 8   如 expand -t 6 file
unexpand [选项] file # 将空格转成tab -t 设置制表符宽度为 N 字符而非默认的 8   如 unexpand -t 6 file
sort [选项] [文件]  # 对文件和标准输入的文本从小到大排序  -n 使用数字 默认为文字 -k 指定排序区间 -b 忽略行头的空格 -r 反序 -t 分隔符 默认为制表符 -f 忽略大小写 -M 以月份名字排序 JAN DEC等 -u 去重
  cat /etc/passwd | sort -t ':' -k 3 -n   # 以 : 来分割的第三栏进行排序，指定为数字
  ls -l /usr/include | sort -rn -k 5 | head -n 10   # 列出/usr/include下占用空间最多的前10个文件
uniq [选项] [文件  # 排序后的数据去重 unique 常用于排序后的数据  -i 忽略大小写 -c 每行前添加次数信息 -d 只输出重复出现的行 -u 只显示唯一的行
join [选项] [文件1] [文件2]   # 将2个文件中指定栏位的内容相同的行连接起来 输出到标准输出 常用于排序后的数据  -t 分隔符 默认空格 -i 忽略大小写 -1 第一个文件 默认第一个字段 -2 第二个文件 默认第一个字段 -j filed(= -1 filed -2 filed)
  join -1 3 -2 2 1.txt 2.txt  将文件1的第3段和文件2的第1段 若内容相同则 连接此行 输出格式为3段 1本行文件1的第3段 2本行文件1除去第3段剩余部分 3本行文件2除去第1段剩余部分  注 多行匹配则做笛卡尔积
common [选项] [文件1] [文件2]   # 逐行比较文本 结果有3列 1只在文件1的行 2只在文件2中的行 3 两文件共有的行 与uniq join类似 只能用于排序后的数据 -1 不输出文件1中特有的行 -2 不输出文件2中特有的行 -3 不输出共有的行 如common -12 1.txt 2.txt 只显示2文件共有内容
tee   # 同时将数据流分送到file与stdout  -a 以追加的方式将数据送入file  如 ls -l /home/ | tee ~/hoefile
split [[选项] file PREFIX # 分割文件 -b 分区大小，单位有b、k、m等 -l 以行数进行分区 PREFIX 分区文件命名前缀
  split -b 300k file ss  # 分成 300k 一个文件 ssa ssb ...        cat ss* > ssX 合成

xargs [选项] [command]  # 将标准输入转化为一个特定的参数列表 -i 替换字符串 {}为替换点 -n 每条命令执行使用的参数数量 -d 分隔符 -0 特殊字符(`\空格等)转化为普通字符 -e EOF 参数截至位置 如-e'sync' 注意无空格 -p 执行每个指令的参数时询问
  很多指令其实并不支持管线命令|，因此可以通过 xargs 来提供该指令引用 standard input 。
  xargs产生命令的参数，读入stdin数据，以空格或回车将stdin数据分割成为arguments。注意文件名或者其他内含有空格符的情况。
  有些命里不能接受过多参数，这样命令可能会执行失败，这种情况也可以用xargs来解决。如 ls
  ls f* | xargs rm     #  寻找以f开头的文件，并删除。
  find /sbin perm +700 | xargs ls -l  # 寻找/sbin下所属者权限位为满的文件，并长列出
  ls | xargs           # 若不接任务指令 等于echo
  echo 111x222x333x444x555 | xargs -n2 -dx   # 以x为分隔符 每次最多2个参数 111 222      333 444 形式
  find ./ -name *.stl | xargs -i cp {} .     # 复制

diff [选项] 文件1/目录1 文件2/目录2  # 比较2个ASCII文件  -c上下文模式 -u 统一模式 -a 逐行比较 -r 递归 -N 不存在文件为空文件 -B 忽略空白行的差异 -b 忽略一行当中，仅有多个空白的差异 -i 忽略大小写
cmp [选项] 文件1 文件2  # 用字节单位去对比两个文件  -i 将所有的不同点的字节处都列出来 默认仅输出第一个发现的不同点
patch [选项] 补丁文件  # 接受diff的结果(补丁文件)并把应用更改到文本文件中  -p num 忽略几层文件夹 -E 发现空文件夹时删除 -R 取消打过的补丁 如文件f1 修改后为f2  diff -Naur f1 f2 > diff.txt  patch < diff.txt 更新f1文件  patch -R < diff.txt 取消上面补丁





二进制文件      # 主要针对elf格式
file 文件      # 帮助确定文件类型             file xx.so
ldd 文件       # 显示出所有依赖库和它们的路径 list dynamic dependencies  ldd xx.so  若提示 not a dynamic executable 编译的平台与运行的平台不匹配
ltrace 命令    # 显示运行时从库中调用的所有函数 可以看到被调用的函数名称 传递给该函数的参数 最右边是函数返回的内容 ltrace gcc
hexdump 文件   # 以 ASCII、十进制、十六进制或八进制显示文件内容 hexdump -C /bin/ls | head
xxd 文件       # 查看文件对应的十六进制形式 -a自动跳过空白 默认关闭 -c加数字 每行显示多少字节 默认16 最大256 -g设定几个字节为一块 默认为2 -l显示多少字节的内容 -s接+-和address +表示从地址处开始的内容 -表示距末尾address开始的内容 -b:以二进制形式查看文件内容
od [-t TYPE] 文件 # 默认8进制显示文件
strings 文件   # 打印文件中的可打印字符的字符串    strings /bin/ls
readelf 文件   # 显示有关 ELF 文件的信息    readelf -h /bin/ls 显示头
objdump 文件   # 读取二进制或可执行文件，并将汇编语言指令转储到屏幕上，主要用于反汇编 objdump -d /bin/ls | head
strace 文件    # 跟踪系统调用和信号 strace -f /bin/ls
nm 文件        # 列出对象文件中的符号 从二进制文件中识别变量和函数 用 -g 选项编译  nm hello | tail
strip          # 删除 ELF文件 中一些无用的信息
size           # 显示目标文件中的 section 大小及目标文件大小
ar             # 将目标文件链接为静态库
addr2line      # 将地址转换为文件、行号





系统管理
uptime               # 系统运行时间、用户数、负载
cat /proc/loadavg    # 查看系统负载磁盘和分区
mount | column -t    # 查看挂接的分区状态

w                    # 查看活动用户
id                   # 查看指定用户信息  如 id <用户名>
whoami               # 查看用户

adduser wjg          # 创建新用户
usermod -G sudo wjg  # 将用户添加到sudo组
deluser wjg --removehome  #删除用户
last                 # 查看用户登录日志
groups               # 用户名所在的全部组，没有指定则默认为当前进程用户
newgrp               # 是以另外一个shell变更目前用户的有效群组   exit 离开 newgrp 环境

useradd [-u UID] [-g 初始群组] [-G 次要群组] [-mM] [-c 说明栏] [-d 家目录绝对路径] [-s shell] 新账户 # 新增账户
  -D # 显示默认基本配置 其值保存在/etc/default/useradd  UID/GID密码参数在/etc/login.defs   基准目录/etc/skel/*
  -u # UID 是一组数字。直接指定一个特定的 UID 给该账户
  -g # 字符串的初始组名，该字符串的 GID 在 /etc/passwd 的第 3 个字段内
  -G # 字符串的次要群组，该选项会修改 /etc/group 内的相关字段
  -M # 强制！不要建立用户家目录（系统账户默认值）
  -m # 强制！要建立用户家目录（一般账户默认）
  -c # /etc/passwd 中第 5 字段的说明内容，可以随便设置
  -d # 指定某个目录成为家目录，请务必使用决定路径
  -r # 建立一个系统账户，该账户的 UID 有限制（参考 /etc/login.defs）
  -s # 后面接一个 shell，若没有指定则预设是 /bin/bash
  -e # 后面接一个日期，格式为 YYYY-MM-DD ，此项可写入 shadow 第 8 字段，即是账户失效日期
  -f # 后面接 shadow 的第 7 字段，该密码是否会失效。0 为立刻失效，-1 为永远不失效（密码只会过期而强制域登录时重新设置）
passwd [--stdin] [账户名称]  # 修改自己密码   echo "abc543CC" | passwd --stdin mrcode2
passwd [-l] [-u] [--stdin] [-S] [-n 天数] [-x 天数] [-w 天数] [-i 日期] 账户   # root 功能
  -l # Lock 意思，就是会将 /etc/shadow 第 2 字段前面加上 ! 使密码失效
  -u # Unlock，与 -l 相反
  -S # 列出密码相关参数，也就是 shadow 文件内的大部分信息
  -n # 后面接天数，shadow 第 4 字段，多久不可修改密码
  -x # 后面接天数，shadow 第 5 字段，多久内必须要修改密码
  -w # 后面接天数，shadow 第 6 字段，密码过期天的警告天数
  -i # 后面接天数，shadow 第 7 字段，密码失效天数，当密码过期后多久失效

chage [-ldEImMW] 账户名    # 使密码参数显示更详细
  -l # 列出该账户的详细密码参数      # chage -l xxx
  -d # 后面接日期，修改 shadow 第 3 字段，最近一次修改密码的日期，格式为 YYYY-MM-DD
  -E # 后面接日期，修改 shadow 第 8 字段，账户失效日，格式 YYYY-MM-DD
  -I # 后面接天数，修改 shadow 第 7 字段，密码失效日期
  -m # 后面接天数，修改 shadow 第 4 字段，密码最短保留天数
  -M # 后面接天数，修改 shadow 第 5 字段，密码多久需要修改
  -W # 后面接天数，修改 shadow 第 6 字段，密码过期前警告天数
usermod [-cdefgGlsuLU] username   同 直接修改 /etc/passwd 或 /etc/shadow 文件
  -c # 后面接账户说明， passwd 第 5 字段，账户说明
  -d #  后面接账户的家的目录，passwd 第 6 字段
  -e # 后面接日期，格式为 YYYY-MM-DD，passwd 第 8 字段，失效日期
  -f # 后面接天数，shadow 第 7 字段
  -g # 后面接初始群组，passwd 第 4 字段，GID 字段
  -G # 后面接次要群组，修改的是 /etc/group 内容
  -a # 与 -G 合用，可 增加次要群组的支持，而非设置
  -l # 后面接账户名称，也就是修改账户名，passwd 第 1 字段
  -s # 后面接 Shell 的实际文件，例如 /bin/bash 或 /bin/csh 等
  -u # 后面就 UID 数字，passwd 第 3 字段
  -L # 暂时将用户的密码冻结，shadow 密码字段
  -U # 解冻用户密码
userdel [-r] username  # 删除用户的相关数据  用户账户、密码相关参数/etc/passwd /etc/shadow  使用者群组相关参数/etc/group /etc/gshadow  用户个人文件数据/home/username /var/spool/mail/username ...
  -r # 连同用户的家目录也一起删除
finger [-s] username   # 指纹
  -s # 仅列出用户的账户、全名、终端机代号与登录时间
  -m # 列出与后面接的账户相同者，而不是利用部分比对（包括全名部分）
chfn [-foph] [账户名]   # change finger
  -f # 后面接完整的大名
  -o # 您办公室的房间号码
  -p # 办公室的电话号码
  -h # 家里的电话号码
chsh [-ls]    # change shell
  -l # 列出目前系统上可用的 shell。其实就是 /etc/shells 中的内容
  -s # 设置修改自己的 shell
groupadd [-g gid] [-r] 组名    # groupadd group1       会修改/etc/group /etc/gshadow
  -g # 后面接某个特定的GID，用来指定 GID
  -r # 建立系统群组。与 /etc/login.defs 内的 GID_MIN 有关
groupmod [-g gid] [-n group_name] 群组名     # groupmod -g 201 -n mygroup group1
  -g # 修改现有的 GID 数字
  -n # 修改现有的组名
groupdel [groupname]     # 删除群组
gpasswd groupname        # 关于系统管理员 root 做的操作
gpasswd [-A user1,...][-M user3,...] groupname
gpasswd [-rR] groupname  # 若没有任何参数时，标识给予 groupname 一个密码 （/etc/gshadow）
  -A # 将 groupname 的主控制权交由后面的使用者管理，也就是该组的管理员
  -M # 将某些账户加入这个群组中
  -r # 将 groupname 的密码移除
  -R # 让 groupname 的密码栏失效
gpasswd [-ad] user groupname  # 关于群组管理员 Group administrator 做的操作
  -a # 将某位使用者加入到该组
  -d # 将某位使用者移除该组



crontab -l           # 查看当前用户的计划任务服务
rpm -qa              # 查看所有安装的软件包
chkconfig –list      # 列出所有系统服务
chkconfig –list | grep on # 列出所有启动的系统服务程序
cut -d: -f1 /etc/passwd # 查看系统所有用户
cut -d: -f1 /etc/group  # 查看系统所有组
locale               # 查看服务器的编码 “LANG”表示服务器编码格式 如LANG=zh_CN.UTF-8  使用的是UTF-8编码。
date +%s             # 将当前时间转化为时间戳  date +%s  ->  1681979884
date +%s -d "xxx"    # 将字符串指定的时间转化为时间戳  date +%s -d "2023-04-20 16:32:19"  ->  1681979539
date -d @时间戳       # 将时间戳转化为时间        date -d @1681979884 -> 2023年 04月 20日 星期四 16:38:04 CST
date -s "2021-11-23 17:00:00"  # 更改系统时间
  %H 小时 00..23      %M 分钟 00..59    %S 秒 00..61   %X 等于 %H:%M:%S
  %Y 年份 0000..9999  %m 月份 01..12    %d 日  01..31  %F 等于 %Y-%m-%d
  Unix时间戳（Unix epoch, Unix time, POSIX time 或 Unix timestamp）是从1970年1月1日0时0分0秒（UTC/GMT的午夜）开始累计到现在的秒数，不考虑闰秒

hwclock  -w          # 写入系统时间
cal                  # 日历  如 cal 2023 整年  cal 5 2023 单月  cal -3 前当后3个月
uptime               # 系统运行时间

systemctl stop WebExpress
systemctl start WebExpress
systemctl restart WebExpress
systemctl status WebExpress
systemctl list-unit-files         # 可以查看启动项
/etc/init.d/mxagentrun stop       # 停止服务 centos7
systemctl stop firewalld.service  # 关闭防火墙 centos7
services iptables stop            # 关闭防火墙 centos6

/etc/sysctl.conf
/sbin/sysctl -p      # -p修改系统参数生效


dmesg          # 系统内核信息
  dmesg | grep IDE       # 查看启动时IDE设备检测状况
  dmesg | grep -i eth    # 查看网卡信息

vmstat         # 侦测CPU、内存、磁盘输入输出状态等系统资源变化   man vmstat 查阅
  vmstat [-a] [延迟 [总计侦测次数]]  # CPU/内存等信息  -a 使用 inactive/active(是否活跃)取代 buffer/cache 的内存输出信息
  vmstat [-fs]        # 内存相关   -f 开机到目前系统fork的进程数  -s 开机到目前导致的内存变化情况列表说明
  vmstat [-S 单位]    # 设置显示数据的单位  -S 后面接单位，如 k、M 等
  vmstat [-d]         # 与磁盘有关  -d 列出磁盘的读写总量统计表
  vmstat [-p 分区槽]  # 与磁盘有关  -p 后面列出分区槽，可显示该分区槽的读写总量统计表
vmstat 1 3          # 统计目前主机 CPU 状态，每秒一次，总共 3 次
  procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
  r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
  procs：进程
    r：等待运行中的进程数量
    b：不可被唤醒的进程数量
    rb 越多表示系统越繁忙。因为系统太忙，导致很多进程无法被执行或一直在等待而无法被唤醒
  memory：内存
    swpd：虚拟内存被使用的容量
    free：未被使用的内容容量
    buff：用于缓冲存储器
    cache：用于高速缓存
    这里的含义与 free 指令一致
  swap：内存交换空间
    si：由磁盘中将进程取出的量
    so：由于内存不足而将没用到的进程写入到磁盘的 swap 的容量
    如果 si、so 的数值太大，表示内存的数据常常得在磁盘与主存储器之间传来传去，效率很低
  io：磁盘读写
    bi：由磁盘读入的区块数量
    bo：写入到磁盘去的区块数量
    如果这部分数值越高，代表系统的 I/O 非常忙碌
  system：系统
    in：每秒被中断的进程次数
    cs：每秒钟进行的事件切换次数
    这两个值越大，代表系统与接口设备的沟通非常频繁，接口设备包括磁盘、网卡、时钟等
  CPU：
    us：非核心层的 CPU 使用状态
    sy：核心层所使用的 CPU 状态
    id：闲置的状态
    wa：等待 I/O 所耗费的 CPU 状态
    st：被虚拟机（virtual machine）所盗用的 CPU 使用状态（2.6.11）


df [opt] file  # disk free 列出已挂载的文件系统  -a 显示全部文件系统 -h 方便阅读 -H 1000进位代替1024 -k 以KB显示 -m MB -i inode数量 -T 显示文件系统类型 -t 指定显示的文件系统 -x 指定不显示的文件系统
  df -T          # 只查看已经挂载的分区和文件系统类型
  df -t ext4     # 指定文件系统类型
du [opt] file  # 文件和目录磁盘使用查看 disk usage  -a 输出所有文件的磁盘用量，不仅仅是目录 -b 以byte为单位 -k KB -m MB -s 只显示汇总 -S 不包括子目录下的总计 -h 方便阅读 -c 额外显示所有目录和文件总和 -d 目录深度
  du -h ./wjg | sort -hr -k 1 | head -5 # 显示wjg目录下占用磁盘最大的前5项 指定按照第一项反向排序 并以方便阅读方式展示
  du -sh xx      # 目录xx的大小
lsblk          # 列出块设备信息 一般为磁盘   -d 仅列出磁盘本身，不列出该磁盘的分区数据 -f 同时列出该磁盘内的文件系统名称 -i 使用 ASCII 的线段输出，不要使用复杂的编码（在某些环境下很有用） -m 同时输出该装置在 /dev 下的权限数据（rwx） -p 列出该装置的完整文件名，而不是仅列出最后的名字 -t 列出该磁盘装置的详细数据，包括磁盘队列机制、预读写的数据量大小等
  输出列中 RM 是否为可拆卸装置（removable device）  RO 是否为只读
  lsblk -f         # 列出装置的 UUID 等参数
  lsblk /dev/sda1  # 查看某个分区
blkid          # 查看已格式化分区的UUID和文件系统
parted         # 列出磁盘的分区表类型与分区信息
  parted /dev/sda print  # 显示指定磁盘的分区表类型与分区信息
  parted /dev/sda unit mb print   # 指定开始 结束字段的单位
  parted -l              # 列出所有设备的分区信息
  mkpart [primary|logical|extended][ext4|vfat|xfs] 开始 结束   # 新增分区
  parted /dev/sda mkpart primary fat32 36.0GB 36.5GB # 最后分区end，为下一个分区起始 建立一个全新的分区槽，格式为 vfat
  rm [partition]    # 删除分区   如 parted /dev/sda rm 7 删除第7个分区
  parted /dev/sda mklabel gpt  # 改变硬盘成 gpt 分区   如 原盘为 Partition Table: msdos    # MBR 分区表
partprobe      # 将分区表的变更通报操作系统
fdisk          # 对MBR硬盘分区  gdisk(也适用于GPT格式) p 显示分区 n 新建分区 d 删除分区 w 保存修改 q 离开
  fdisk -l | grep Disk # 磁盘大小
  fdisk -l             # 查看所有分区
mkfs           # 建立文件系统  如 mkfs -t vfat /dev/sda7 格式化分区为 vfat 格式
dumpe2fs       # 查看文件系统的详细信息   -b 列出保留为坏轨的部分 -h 仅列出 superblock（超级块）的数据信息
  dumpe2fs /dev/sda1

hdparm -i /dev/hda   # 磁盘参数(仅适用于IDE设备)
hostname             # 计算机名
lspci -tv            # 列出所有PCI设备
lsusb -tv            # 列出所有USB设备
lsmod                # 列出加载的内核模块

/etc/fstab      # filesystem table 开机时的配置文件  利用mount进行挂载  dump备份  fsck文件系统检验
  [文件系统/装置/UUID等] [挂载点] [type] [文件系统参数] [dump] [fsck]
  文件系统/装置/UUID
    文件系统或磁盘的装置文件名，如 /dev/sda 等
    文件系统的 UUID 名称
    文件系统的 LABEL name
  挂载点 mount point # 一定是目录
  type  # 包括 xfs、ext4、vfat、reiserfs、nfs 等
  文件系统参数options
    async/sync（异步/同步）             # 设置磁盘是否已异步允许方式，预设为 async
    auto/noauto（自动/非自动）          # 当下达 mount -a 时，此文件系统是否被主动测试挂载。预设为 auto
    rw/ro（可擦写/只读）                # 让该分区槽可以擦写或只读的形态挂载上来，当这里设置为只读之后，在文件系统中对文设置 w 权限，也不能写入
    exec/noexec（可执行/不可执行）      # 限制在此文件系统内是否可以进行「执行」的工作？如果纯粹用来存储数据的话，就可以设置为 noexec 比较安全。不过该参数不能随便使用，因为你不知道该目录下是否默认会有执行文档。比如       将 noexec 设置在 /var ，当某些软件将一些执行文件放置到该文件下时，那么这些软件就不能运行
    user/nouser（允许/不允许使用者挂载） # 是否允许用户使用 mount 指令来挂载
    suid/nosuid（具有/不具有 suid 权限） # 该文件系统是否允许 SUID 的存在？如果不是执行文件放置目录，也可以设置为 nosuid 来取消 SUID 的功能
    defaults                           # 同时具有 rw、suid、dev、exec、auto、nouser、async 等参数。基本上使用该参数即可
  内否被 dump 备份指令作用 # ump 是用来做备份的指令，不过现在备份方案太多了，可以不关注该项目，直接输入 0 好了
  是否已 fsck 检验扇区  # 早期开机的流程中，会有一段时间去检验本机的文件系统，看看文件系统是否完整（clean）。不过该方式使用的主要是通过 fsck 来做的。我们现在用 xfs 文件系统就没有办法适用了，因为 xfs 会自己进行检验，直接填写 0 即可
/etc/mtab 与 /proc/mounts # 实际 filesystem 的挂载记录 当我们更动 filesystem 的挂载时，也会同时更动这两个文件
  mount -n -o remount,rw /  # 单人维护模式中 / 若是 read only 状态 无法修改  重新挂载下 / 就可以了修改了



查看 swap
free -m        # 查看系统内存 虚拟内存(交换空间) -b -k -m -g -h 单位参数 默认为k -t 显示物理内存与swap的总量 -s 不间断每几秒输出一次 -c 与-s同时处理，让free列出几次
swapon -s      # 查看所有交换分区(file(s)/partition(s))  同cat /proc/swaps

添加交换空间
  两种选择       添加一个交换分区或添加一个交换文件。推荐你添加一个交换分区；不过，若你没有多少空闲空间可用，则添加交换文件。
  新添了交换分区并启用它之后，请查看 cat /proc/swaps 或 free 命令的输出来确保交换分区已被启用了。

添加一个交换分区
  使用fdisk来创建交换分区（假设 /dev/sdb2 是创建的交换分区）
  mkswap /dev/sdb2      # 使用 mkswap 命令来设置交换分区
  swapon /dev/sdb2      # 启用交换分区
  /dev/sdb2 swap swap defaults 0 0      # 写入/etc/fstab,以便在引导时启用

添加一个交换文件
  dd if=/dev/zero of=/swapfile1 bs=1024k count=512    #创建大小为512M的交换文件
  mkswap /swapfile1                   # 使用 mkswap 命令来设置交换文件
  swapon /swapfile1                   # 启用交换分区
  /swapfile1 swap swap defaults 0 0   # 写入/etc/fstab,以便在引导时启用

删除交换空间
  swapoff /dev/sdb2                   # 禁用交换分区
  /etc/fstab 文件中中删除项目
  使用fdisk或yast工具删除分区。

删除交换文件步骤同上。


ls -l /lib/modules/`uname -r`/kernel/fs/  # linux 支持的文件系统
cat /proc/cmdline    # 加载 kernel 时所下达的相关指令与参数，查询此文件，可了解指令是如何启动的
cat /proc/cpuinfo    # 查看CPU信息
  cat /proc/cpuinfo | grep "processor" | wc -l      # 查看逻辑cpu个数
  cat /proc/cpuinfo | grep "physical id" | sort | uniq | wc -l  # 查看物理cpu个数
  cat /proc/cpuinfo | grep "cpu cores" # 每个物理cpu的核数cores  若所有物理cpu的cores数<逻辑cpu数，则该cpu使用了超线程技术
  cat /proc/cpuinfo | grep "siblings"  # 每个物理cpu中逻辑cpu的个数
  cat /proc/cpuinfo | grep "model name" && cat /proc/cpuinfo |grep "physical id" # cpu信息
  cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c   # 查看CPU信息（型号）
      8  Intel(R) Xeon(R) CPU            E5410   @ 2.33GHz  (看到有8个逻辑CPU, 也知道了CPU型号)
  cat /proc/cpuinfo | grep physical | uniq -c
      4 physical id      : 0             (说明实际上是两颗4核的CPU)
      4 physical id      : 1
  cat /proc/cpuinfo | grep flags | grep ' lm ' | wc -l  # 8  大于0, 说明支持64bit计算. lm指long mode, 支持lm则是64bit
cat /proc/devices    # 系统各个主要装置的主要装置代号，与 mknod 有关
cat /proc/filesystems # 系统目前已加载到内存中支持的文件系统
cat /proc/interrupts # 中断   目前系统上 IRQ 分配状态
cat /proc/ioports    # 设备io端口   目前系统上各个装置所配置的 I/O 地址
cat /proc/kcore      # 内存大小，很大？不要读取该文件
cat /proc/loadavg    # top 以及 uptime 的三个平均数值就是记录在这里的
cat /proc/meminfo    # 内存信息
  cat /proc/meminfo | grep MemTotal # 内存大小
  grep MemTotal /proc/meminfo # 查看内存总量
  grep MemFree /proc/meminfo  # 查看空闲内存量
cat /proc/modules    # 目前我们 LInux 已经加载的模块列表，可以看成是驱动程序
cat /proc/mounts     # 系统已经挂载的数据，就是用 mount 指令查询出来的数据
cat /proc/swaps      # 所有swap分区的信息   使用掉的 partition 记录在这里
cat /proc/partitions # 硬盘和分区信息   fsidk -l 会出现目前所有的 partition，在该文件中也有记录
cat /proc/uptime     # 使用 uptime 出现的信息
cat /proc/version    # 版本 类似uname -a
cat /proc/pci        # pci设备的信息
/proc/bus/*          # 一些总线的装置，还有 USB 的装置也记录在这里

dmidecode | grep 'Processor Information'    # 再完整看cpu详细信息
dmidecode | grep "Product Name"             # 查看机器型号
getconf LONG_BIT         #  32      当前CPU运行在32bit模式下, 但不代表CPU不支持64bit


watch    # 实时监测命令的运行结果  -n 间隔多少秒执行一次cmd -d 高亮变化  如 watch -n 2 "ss -antp | grep 8123 | wc -l" 查询端口的连接数
reset     #设定终端机的状态 cat某些二进制文件导致界面乱码用reset指令重置以后恢复正常 用od命令查看二进制文件就没问题
xftp

pip 安装和管理python包的工具
pip search "django"             # 搜索
pip install django[>=2.0]       # 安装 指定版本
pip install -r xx.txt           # 安装 可以将需要安装的依赖库写成txt文件 批量执行
pip install-U django            # 升级
pip freeze                      # 列出已安装的包
pip uninstall django            # 卸载





作业管理
bash 支持作业控制 sh不支持
command &               # 命令后台运行 显示 [1] 343635 表示作业号jid和pid 这种方式工作管理的背景与终端机有关，可以理解为是当前这个bash的背景，并不是放到系统的背景中去。在工作未结束时，你脱机了，该工作不会继续进行，而是会被中断掉。
nohup command &         # 后台运行 终端机无关   默认输出一个名叫 nohup.out 的文件到当前目录下
nohup command           # 前端运行 终端机无关   默认输出一个名叫 nohup.out 的文件到当前目录下
ctrl + z                # 将当前的作业停止并丢到后台 默认为stopped状态  如 tail -f  file
jobs                    # 查看后台作业 [jid]  +/-/空 (最后放置的作业 倒数第二个 其他) 状态 命令 -l 显示pid -r 仅显示后台running的作业 -s 仅显示后台stopped的作业
fg                      # 将最后放置作业拿到前台 即 + 表示的作业
fg %jid                 # 将后台作业jid拿到前台  % 可省
bg %jid                 # 将后台作业jid设置为运行状态 stopped -> running
kill signal %jid        # 删除作业 -1 SIGHUP 类似restart -2 SIGINT 同ctrl+c   如 kill -9 %1 同 kill -SIGKILL %1
kill signal pid         # 删除进程 -9 SIGKILL 强退 -15 SIGKILL 正常退出 -19 SIGSTOP 同ctrl+z
kill -l                 # 列出目前 kill 能够使用的信号    man 7 signal 查询相关资料
killall -signal cmd     # -i 交互确认 -e 精确cmd 不超过15字符 -I cmd忽略大小写  如 killall -9 httpd




进程
pstree           # 进程树状关系 -A 各树之间以ascii字元连接 -U 以万国码的字符来连接 -p 显示pid -u 显示用户
pstack 10901     # 查看进程的堆栈
pgrep            # p表明了这个命令是专门用于进程查询的grep  如 pgrep httpd
pidof            # 查询进程的pid  -s 仅列出一个 PID  -x 同时列出该程序可能的 PPID 那个进程的 PID
  pidof WebExpress   # 和pgrep相比稍显不足的是，pidof必须给出进程的全名
renice -数字 pid # 设置进程nice值
nice -n 5 vim &  # 后台启动vim且ni为5 范围-20~19
ps               # 进程
  ps aux         # 显示所有进程 同下
  ps -ef         # -e显示所有进程  -f扩展显示输出 UID启动进程的用户 PID进程的进程号 PPID父进程进程号 C cpu使用率   STIME进程启动时的系统时间 TTY进程启动时终端设备 TIME运行进程需要的累积CPU时间 CMD启动程序名称或命令
  ps -l          # 显示当前登录shell的相关进程  与当前终端机相关
  ps axjf        # 显示进程树
  ps -fxo (或-afxo) user,pid,ppid,pgid,command  # 自定义显示哪些列 显示进程树
  ps -afxo user,pid,ppid,pgid,stat,pri,ni,command | grep vim  # 查看进程vim优先级 也就是 ni列
top              # 实时显示进程状态用户
  top -Hp pid  # 某个进程的线程信息 -H线程模式 -p指定pid -d每隔几秒刷新默认5 -c显示命令行参数
  top -Hp   ` ps -ef | grep gvfs-goa  | awk 'NR==3 {print $2}' `  # 过滤某个进程ID并top显示 用管道不行
lsof  [-aUu] [+d] # list open files 通过进程去找它开启或使用的文件与装置  -a 与 -U 仅列出 Unix like 系统的 socket 文件类型 -u 接 username，列出该使用者相关进程所开启的文件 +d 接目录，找出某个目录下已经被开启的文件
  lsof                    # 列出目前系统上所有已经被开启的文件与装置
  lsof -p 127129 | wc -l  # 查看某个进程的打开文件数
  lsof -u root -a -U      # 仅列出关于 root 的所有进程开启的 socket 文件
  lsof +d /dev/           # 列出目前系统上所有被启动的周边装置
fuser [-umv] [-k [i] [signal]] file/dir  # 由文件找出正在使用该文件的进程   -u 显示用户ID  -m 显示所有使用指定文件系统或块设备的进程 -v 列出每个文件与进程还有指令的完整相关性 -k 杀死访问指定文件的进程 -i 杀死程序前询问 未指定 -k 选项时被忽略 -信号 发送指定的 "信号" 而不是 SIGKILL
  fuser -mv /mnt/volume1/  # 找出正在使用设备的进程
  fuser -uv .              # 找出目前所在目录的使用 PID、所属账户、权限
  ACCESS 权限项的意义
    c # 此进程在当前的目录下（非次目录）
    e # 可被触发为执行状态
    f # 是一个被开启的文件
    r # 代表顶层目录（root directory）
    F # 该文件被开启了，不过在等待回应中
    m # 可能为分享的动态函数库

/proc/sys/fs/file-max    # 系统级的最大限制 句柄数
/proc/sys/fs/file-nr

/proc/[pid]/limits   # 显示进程pid的资源限制
/proc/[pid]/fd       # 目录，包含进程打开文件的情况
/proc/[pid]/task     # 查看某个进程的线程pid的详细信息
/proc/[pid]/maps     # 查看某个进程pid的链接库




网络通讯
scp -r lixiang@10.248.14.215:~/code/llvm/foo_html/* d:/tmp/       # 远程复制文件夹
测试端口通不通
  telnet ip port    # telnet是windows标准服务，可以直接用；如果是linux机器，需要安装telnet
  ssh -v -p port username@ip  # -v 调试模式(会打印日志) -p 指定端口 username可以随意
  wget ip:port      # wget是linux下的下载工具，需要先安装
  nmap ... -p

wget    # 命令行后台自动下载工具 可在用户退出系统后在后台继续执行 支持http https ftp协议
wget [参数] [url]   # -r 递归下载 -c 断点续传 https://www.cnblogs.com/dingn/p/5658442.html

tracert xxx         # 跟踪路由路径 traceroute destination-hostname
ip a                # 网络
ifconfig            # 所有网络接口的属性
iptables -L         # 防火墙设置
route -n            # 路由表
netstat             # -a 所有 -t tcp包 -u udp包 -n 显示端口号 -l listen的服务 -p 列出pid
  netstat -a ip     # 查询主机名 netbios 协议 137端口 win
  netstat -lntp     # 所有监听端口        如 netstat -tunlp | grep 8123
  netstat -antp     # 所有已经建立的连接  如 netstat -antp | grep 8123 | wc -l
  netstat -s        # 网络统计信息进程

net.ipv4.tcp_tw_reuse = 1





归档压缩
gzip、zcat/zmore/zless/zgrep     # zcat等可直接查看.gz .zip文件   windows下 WinRAR、7zip 能识别.gz文件
gzip  file.txt          # 每个文件分别压缩成.gz 默认不保留原始文件 -r递归 -c 将压缩的数据输出到屏幕上 -v 可以显示出原文件、压缩文件的压缩比等信息 -d 解压缩 同gunzip -# #为数字 压缩等级 1压缩比最差 9最好 6默认
  gzip -c file > file.gz    # 原始文件则存在
gunzip file.txt.gz      # 解压缩
gzip -d file.gz         # 解压缩

zip -r my.zip ./my      # 压缩  -r递归 -q安静模式 -o后接输出到的文件 -[1-9]压缩等级9最高 -x 排除文件 -e 设置密码 -l 将换行符LF转化为CR+LF
unzip my.zip -d ./my2   # 解压缩  -d目标目录 默认为当前目录 -q 安静模式 -l只查看压缩包的内容 -O 指定编码


#bzip2、bzcat/bzmore/bzgrep    # 取代 gzip 并提供更佳的压缩比。使用方式几乎与 gzip 相同
bzip2 [-cdkzv#] 文档名   # 压缩成.bz2文件 -c 同 -d 同 -k 保留源文件 -z 压缩 默认不写 -v 同 -# 同


xz、xzcat/xzmore/xzless/xzgrep  # xz 比 bzip2 压缩比更高，用法也与 bzip2、gzip 就一模一样
xz [-dtlkc#] 文档名      # 压缩成.xz文件  -d 解压缩 -t 测试压缩文件的完整性 -l 列出压缩文件 -k 同 -c 同 -# 同


tar -czvf ip.tar.gz --exclude=Release/*.a --exclude=Release/*.so Release/   #排除指定的文件 其他的打包
tar -cvf bak.tar etc/          # 打包 -c打包 -v列出文件 -f归档文件 -x解包 -C解压到指定目录 -t只查看包内的文件
tar -zcvf bak.tar.gz etc/      # 打包 -z 使用gzip 格式tar.gz -j bzip2 tar.jz2 -J xz tar.xz -p 保留文件属性 -P 保留绝对路径
tar -xvf bak.tar               # 解包 注意 f之后必须紧跟 文件名 故不能写成 -xfv 等等
tar -xvf  bak.tar  -C ./dir    # 解包 解开一个tar到当前的 dir 目录中
tar -zxvf bak.tar.gz           # 解包 解压一个tar.gz包
tar -jtv -f filename.tar.bz2   # 查询 查看一个.tar.bz2包
tar -jxv -f filename.tar.bz2 etc/shadow # 解开单一文件 etc/shadow 为通过上面 -t查询出来的结果
tar -jcv -f new.tar.bz2 --newer-mtime="2023-08-04" ./  # 打包 仅比日期新的文件
tar -jcv -f new.tar.bz2 --newer ./12345.log ./  # 打包 仅比文件新的文件 文件必须以 / 或 ./开头

apt-get install rar unrar  # 安装rar unrar打包压缩工具
rar a dir dir.rar          # 归档  a 表示后面时目录 l 只查看归档文件内容
unrar x dir.rar            # 全路径解压
unrar e dir.rar dir2/      # 去掉路径解压





alsamixer               # 打开音量调节器
evince xx.pdf           # 打开pdf文件
eog xx.pgm              # 打开图片
sudo modprobe -r psmouse  # 禁用触摸屏
sudo modprobe psmouse   # 打开触摸板








hexdump 将指定文件内容以二进制文件转换为ASCII、八进制、十进制、十六进制格式进行查看
  hexdump: [-bcCdovx] [-e fmt] [-f fmt_file] [-n length] [-s skip] [file ...]
  -b 每个字节显示为8进制。一行共16个字节，一行开始以十六进制显示偏移值
  -c 每个字节显示为ASCII字符
  -C 每个字节显示为16进制和相应的ASCII字符
  -d 两个字节显示为10进制
  -n 只格式前n个长度的字符
  -o 两个字节显示为8进制
  -s 从偏移量开始输出
  -x 双字节十六进制显示



od(Octal Dump)将指定文件内容以八进制、十进制、十六进制、浮点格式或ASCII编码字符方式显示 默认显示方式是八进制
  -A RADIX (--address-radix=RADIX)  #选择以何种基数表示地址偏移 [doxn] d:decimal o:octal x:hexadecimal n:none
  -j BYTES (--skip-bytes=BYTES)     #跳过指定数目的字节
  -N BYTES (--read-bytes=BYTES)     #输出指定字节数
  -S [BYTES] (--strings[=BYTES])    #输出长度不小于指定字节数的字符串，BYTES 缺省为 3
  -v (--output-duplicates)          #输出时不省略重复的数据
  -w [BYTES] (--width[=BYTES])      #设置每行显示的字节数，BYTES 缺省为 32 字节
  -t TYPE (--format=TYPE)           #指定输出格式，格式包括 a、c、d、f、o、u 和 x，各含义如下
    a       具名字符；比如换行符显示为 nl
    c       可打印字符或反斜杠表示的转义字符；比如换行符显示为 n
    d[SIZE]       SIZE 字节组成一个有符号十进制整数。SIZE 缺省为 sizeof(int)
    f[SIZE]       SIZE 字节组成一个浮点数。SIZE 缺省为 sizeof(double)
    o[SIZE]       SIZE 字节组成一个八进制整数。SIZE 缺省为 sizeof(int)
    u[SIZE]       SIZE 字节组成一个无符号十进制整数。SIZE 缺省为 sizeof(int)
    x[SIZE]       SIZE 字节组成一个十六进制整数。SIZE 缺省为 sizeof(int)
    SIZE可以为数字，也可以为大写字母。如果 TYPE 是 [doux] 中的一个，那么SIZE 可以为C = sizeof(char)，S = sizeof(short)，I = sizeof(int)，L = sizeof(long)。如果 TYPE 是 f，那么 SIZE 可以为 F = sizeof(float)，D = sizeof(double) ，L = sizeof(long double)






ldconfig [参数]  通常在系统启动时运行，而当用户安装了一个新的动态链接库时，就需要手工运行这个命令。
主要是在默认搜寻目录/lib和/usr/lib以及动态库配置文件/etc/ld.so.conf内所列的目录下，搜索出可共享的动态链接库
  (格式如lib*.so*),进而创建出动态装入程序(ld.so)所需的连接和缓存文件，缓存文件默认为/etc/ld.so.cache，
  此文件保存已排好序的动态链接库名字列表。linux下的共享库机制采用了类似高速缓存机制，将库信息保存在/etc/ld.so.cache，
  程序连接的时候首先从这个文件里查找，然后再到ld.so.conf的路径中查找。为了让动态链接库为系统所共享，
  需运行动态链接库的管理命令ldconfig，此执行程序存放在/sbin目录下。
  常用参数
    -v 显示正在扫描的目录及搜索到的动态链接库以及所创建的连接的名字
    -n 仅扫描命令行指定的目录，不扫描默认目录，也不扫描配置文件所列的目录
    -N 不重建缓存文件
    -X 不更新文件的连接
    -f  CONF 指定动态链接库的配置文件为CONF，系统默认为/etc/ld.so.conf
    -C  CACHE 指定生成的缓存文件为CACHE，系统默认的是/etc/ld.so.cache
    -r  ROOT 改变应用程序的根目录为ROOT
    -l 进入专家模式手工设置连接
    -p 打印出当前缓存文件所保存的所有共享库的名字
    -c FORMAT 指定缓存文件所使用的格式
  注意:以下4种方法 择一即可 最后调用ldconfig 其实就是系统刷新下so文件
    1 在/lib和/usr/lib里面添加库文件，但是需要使用命令sudo ldconfig,否则无法找到库文件。 sudo ldconfig -v
    2 在上述两个目录之外的路径添加库文件，需要先将将库文件的路径追加入/etc/ld.so.conf。 echo "/usr/local/mysql/lib" >> /etc/ld.so.conf
    3 还可以用添加环境变量LD_LIBRARY_PATH的做法让系统识别到库文件 目录之间用冒号分隔开。 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/mysql/lib
    4 还可以在/etc/ld.so.conf.d/目录下创建.conf文件来添加库路径。touch opencv.conf;echo "/user/local/lib" > opencv.conf;sudo ldconfig

Linux使用cp命令复制不提示直接覆盖
  方法1       修改~/.bashrc文件禁用掉cp的alias
    vi ~/.bashrc
    把alias cp='cp -i'注释掉，执行source ~/.bashrc或者重新登录即可实现复制不提示覆盖。
      # User specific aliases and functions
      alias rm='rm -i'
      #alias cp='cp -i'
      alias mv='mv -i'
      source ~/.bashrc
  方法2       在cp命令前面加一个斜杠
    \cp -rf srcdir dstpath

Linux 指令前加反斜杠 ‘\’
  在指令前加上反斜杠，可以忽略掉 alias 的指定选项
  alias是shell的内置命令，可以用来设置命令的别名，如使用alias ls='ls --color=auto'设置使用ls时以彩色输出 在命令前加上反斜杠，可以临时取消使用别名
  例如       \ls 则直接调用ls的原始命令，而不会使用alias设置的带有color选项的命令
  同样的事情，常常出现在安装软件的介绍上，作者为了保证你使用的命令和他使用的一致，而不是各种系统别名，经常会在命令前面加一个反斜杠来去除别名。

scp远程拷贝命令
Linux下提供了scp(secure copy)命令，用于进行远程拷贝文件，功能类似cp命令，支持跨服务器，并且提供加密传输。
由于使用ssh，登录之后的本机地址是不需要给出的。但是也可以不登录直接跨主机拷贝文件，可能会需要用户名及密码。
基本命令格式如下
scp [...] src_file dst_file    -r迭代 -P 端口 -v显示进度 -4强制用ipv4地址 -6强制用ipv6地址

# 文件复制
$scp local_file remote_username@remote_ip:remote_folder    把local_file复制到远程的文件夹下
$scp local_file remote_username@remote_ip:remote_file      把local_file复制到远程 并改名为remote_file
$scp local_file remote_ip:remote_folder                    同上第一个 只是会提示输出用户名 和 密码
$scp local_file remote_ip:remote_file                      同上第二个 只是会提示输出用户名 和 密码

# 目录复制
$scp -r local_folder remote_username@remote_ip:remote_folder   -r遍历文件夹
$scp -r local_folder remote_ip:remote_folder

指定用户名是需要输入密码，不指定用户名需要同时输入用户名和密码。
假设主机A的ip是192.168.0.200，主机B的ip地址是192.168.0.100。
SSH登录之后
我们在主机A（0.200）上通过ssh远程登录到主机B（0.100）。

从本地复制到远程
$ scp a.txt tocy@192.168.0.200:~/a.txt    # 文件
$ scp -r src tocy@192.168.0.200:~/src    # 目录
从远程复制到本地
$ scp tocy@192.168.0.200:~/a.txt a.txt
$ scp -r tocy@192.168.0.200:~/src src
直接指定两个主机拷贝
$scp tocy@192.168.0.200:~/b.txt v@192.168.0.100:~/from_b.txt


syslog
1 syslogd 守护进程
2 /var/log/messages 或 /var/log/syslog 日志文件
3 logger shell命令 如logger -t mylog 'test msg'

# 多行写入 xx.cc
cat <<EOF > xx.cc
xxx
XXX
EOF


查看命令耗时
start_time=`date "+%Y-%m-%d %H:%M:%S"` ;\
make RELEASE=1 BITS=64 CENTOS=7 ;\  ###sleep 3s; \  #要执行的命令
end_time=`date "+%Y-%m-%d %H:%M:%S"`;\
#duration=`echo $(($(date +%s -d "${end_time}") - $(date +%s -d "${start_time}"))) | awk '{t=split("60 s 60 m 24 h 999 d",a);for(n=1;n<t;n+=2){if($1==0)s="0s";break;s=$1%a[n]a[n+1]s;$1=int($1/a[n])}print s}'`;\
duration=`expr $(date +%s -d "${end_time}") - $(date +%s -d "${start_time}")`;\
echo "开始时间        $start_time";\
echo "结束时间        $end_time";\
echo "累计耗时        ${duration}s"





top 命令
1 前五行是系统整体的统计信息，称为汇总区（Summary Area）。

第一行是时间相关和任务队列信息，同 uptime 命令的执行结果。
top - 16:07:48    up 4 days,  2:51     3 users        load average: 0.00, 0.01, 0.05
      当前时间     系统运行总时长分钟    当前登录用户数   系统负载 任务队列的平均长度 分别为最近1 5 15分钟的平均值。

第二行是进程信息统计数据。
任务:338 total,   1 running,         337 sleeping,   0 stopped,   0 zombie
     总的进程数    正在运行的进程数    睡眠的进程数     停止的进程数   僵尸进程数

第三行是 CPU 统计数据。
%Cpu(s): 0.4 us,     0.4 sy,      0.0 ni,     99.3 id,    0.0 wa,      0.0 hi,    0.0 si,    0.0 st
    用户空间占用  内核空间占用   用户进程空间内  空闲       等待输入输出的  硬中断占用  软中断占用  虚拟机(虚拟化技术)占用
    CPU百分比    CPU百分比      改变过优先级的  CPU百分比  CPU时间百分比   CPU百分比  CPU百分比   百分比
                               进程占用CPU百分比

第四行为物理内存的统计数据。 同 free 命令
MiB Mem :  31736.5 total,  26369.4 free,   1761.6 used,         3605.5 buff/cache
           物理内存总量   = 空闲内存总量   + 已使用的物理内存总量 + 用作内核缓存的内存量
free尚未被内核占用的空闲内存 被内核占用用于buffer/cache的内存 是可以被进程使用的 只是内核没有将之算到free中。

第五行为交换分区（即虚拟内存）的统计数据。 同 free 命令
MiB Swap:   2048.0 total,   2048.0 free,      0.0 used.          29490.4 avail Mem
            交换区总量       空闲交换区总量     已使用的交换区总量   实际可用物理内存总量

第六行是空行。从第七行开始，显示了各个进程的状态信息，称为任务区（Task Area）。各列含义如下
PID        进程id
USER       进程所有者
PR         进程动态优先级，是进程在内核中实际的优先级值 范围为0-31，数值越低，优先级越高
NI         nice值。范围-20到+19，进程静态优先级，新的进程优先级 PR(new)=PR(old)+nice，nice负值表示高优先级，正值表示低优先级
VIRT       进程使用的虚拟内存总量，单位 KB
RES        Resident Memory Size，进程使用的、未被换出的物理内存大小，单位 KB
SHR        共享内存大小，单位 KB
S          进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=停止 t=跟踪 Z=僵尸进程
%CPU       上次更新到现在的CPU时间占用百分比。多核下若进程是多线程 而top不是在线程模式下运行 该值由多个核的值累加 可能>100%
%MEM       进程使用的物理内存百分比  RES/物理内存总量 *100%
TIME+      进程使用的 CPU 时间总计，单位 1/100 秒
COMMAND    进程名称（命令名/命令行）

top 可输出的全部进程指标可以使用命令top -O查看，其它指标的介绍这里不再赘述，具体可参见 top manual。

交互命令
  q 退出
  l 切换显示 平均负载 和 时间信息
  P 根据cpu使用百分比排序
  M 根据内存驻留集大小排序
  N 以 PID 排序
  T 由该进程使用 CPU 时间累积（TIME+）排序
  i 忽略闲置和僵死的进程 开启
  k 终止进程 会提示输入PID  给予某个 PID 一个信号(signal)
  r 给予某个 PID 重新制定一个 nice 值
  E 切换单位显示，比如从 KB 切换为 G 显示
  c 切换 COMMAND 的信息，name/完成指令


free 系统内存
https://lotabout.me/2021/Linux-Available-Memory/
              total        used        free      shared  buff/cache   available
Mem:       32498200     1827024    26968232       48596     3702944    30174996
Swap:       2097148           0     2097148

total = used + free + buff/cache     #总内存
available ~= 26968232 + 3702944      #可用内存

cat /proc/meminfo                   #内存的详细分布

进程内存
         |----------------------|--------------------|       VSS = 1 + 2 + 3
         | 1 分配但尚未使用的内存 | 3 共享库占用内存    |       RSS = 2 + 3
         |    虚拟耗用           |                    |       PSS = 2 + 3.1
         |----------------------|--------------------|       USS = 2
         | 2  进程占用内存       | 3.1 按比例分配的    |       注 3.1 是3的一部分 即 3.1 = 1/N * 3
         |                      |   共享库占用内存    |
         |----------------------|--------------------|

首字母分别是Virtual/Resident/Proportional/Unique   SS表示Set Size
VSS       虚拟内存，不直接对应到物理内存 包含共享库占用的内存 包括尚未在内存中驻留的部分 对确定单个进程实际内存使用大小用处不大
RSS       常驻内存，可以理解成映射的内存的总和 即实际使用物理内存(包含共享库占用的内存)
PSS       实际使用的物理内存(按比例分配共享库占用的内存) 自己独占的内存+1/N共享内存部分 若一个共享库N个进程公用 则单个进程分摊1/N
USS       进程独占的内存，即扣除了共享内存 即进程终止，USS就是实际被返还给系统的内存大小
ps aux  | head -n 1 ; ps aux | sort -rn -k 5 | head     #VSZ 和 RSS 可以直接通过 ps aux 输出
SS 和 USS 可以通过 /proc/<pid>/smaps 中的字段统计得到。也可以用工具 smem 直接输出和统计。
cat /proc/<PID>/smaps | awk 'BEGIN {i=0} /^Pss/ {i = i + $2} END {print i}'  #PSS       通过 Pss 字段相加得到
cat /proc/<PID>/smaps | awk 'BEGIN {i=0} /^Private/ {i = i + $2} END {print i}'  # USS       通过 Private_Clean 和 Private_Dirty 相加得到




find-----------------------------------------------------------------------------
find /usr/include -type f  -exec grep CLOCKS_PER_SEC -n --color -H {} \;
find . -maxdepth 2 -type f −name "∗.h" −o −name "∗.cpp" -exec grep foo {} \; 查找所有的.h .cpp文件用 -o 链接 深度是2
find / -name "xxx" 2>/dev/null 权限不够的文件不显示
find  -path XXX -prune 排除XXX目录 -o or表示或  -a and表示与 -not或! 表示非
  -prune 不进入目录，所以可用于忽略目录，但不会忽略普通文件。
  -print 打印文件名
  find path -option [-exec/-ok command {} \; ]  [-print]   find命令结合-exec/-ok
  find path -option [-print] [|xargs command]              find命令结合xargs
  \(  XXX \) 表示表达式的结合。即指示 shell 不对后面的字符作特殊解释，而留给 find 命令去解释其意义。
    由于命令行不能直接使用圆括号，所以需要用反斜杠'\'进行转意(即'\'转意字符使命令行认识圆括号)。同时注意'\('，'\)'两边都需空格。
    find ./ \( -path ./googletest -prune -o -path ./cmake-examples -prune  -o -path *build* \) -o \( -name *.cpp -o -name *.c -o -name *.h \) -print | xargs wc -l
  或find ./ \( -path ./googletest -o -path ./cmake-examples  -o -path *build* \) -prune -o \( -name *.cpp -o -name *.c -o -name *.h \) -print | xargs wc -l
  上句意思是 排除当前目录下googletest cmake-examples 目录中或者子目录中包含build的目录 查找后缀名为.cpp .c .h的文件 并 统计行数
  find ./ \( -path ./googletest -o -path ./cmake-examples  -o -path *build* \) -prune -o \( -name *.cpp -o -name *.c -o -name *.h \)  -exec wc -l {} \; | awk '{print $1}' | awk '{sum+=$1}END{print sum}'
find / -type f  ! -regex /va.*  ! -regex /pro.* ! -empty -mtime -3 -mtime +1  查找三天前一天内的文件，并且排除/va*、/pro*
find / -type f -mtime -3 ! -path '/var/' -prune -o -name "*.log" -print       查找所有三天前被修改的log文件，并排除/var目录
find . -path "./abc" -prune -o -print  # 在当前目录下排除abc目录，查找所有文件
find . -path "./abc" -prune -o -name "*.txt" -print   # 在当前目录下排除abc目录，查找所有以.txt结尾的文件[方式一]
find . -name "*.txt" -not -path "./abc/*"  # 在当前目录下排除abc目录，查找所有以.txt结尾的文件[方式二]
find . \( -path ./abc -o -path ./def \) -prune -o -name "*.txt" -print  # 在当前目录下排除abc和def目录，查找所有以.txt结尾的文件
find . \( -path ./abc -o -path ./def/h.txt \) -prune -o -name "*.txt" -print  # 在当前目录下排除abc目录和def/h.txt文件，查找所有以.txt结尾的文件
find . \( -path ./abc -o -path ./def/h.txt -o -path ./jk \) -prune -o -name "*.txt" -print  # 在当前目录下排除abc目录和def/h.txt文件和jk目录，查找所有以.txt结尾的文件
find . ! -name "*.html" -type f  # 在当前目录下查找所有不是以.html结尾的文件
注
  -path "./abc" -prune -o -print 是 -path "./abc" -a -prune -o -print的缩写  -prune 返回为真
  其含义等同于伪码 如下
    if -path "./abc" then
      -prune
    else
      -print

  find . \( -path ./abc -o -path ./def \) -prune -o -name "*.txt" -print
    圆括号表示表达式的结合
    \ 表示引用 即shell不对后面的字符做特殊解释 而留给find去解释含义
    查找到某一确定文件 -name 等选项加在 -o 之后

find
  linux下的实时查找工具，通过遍历指定目录下的文件系统完成文件查找。
  命令使用格式       find [OPTION]... [查找路径] [查找条件]... [处理动作]

    查找条件
      根据文件名查找
        -name "文件名"       支持使用通配符 *，?，[]，[^]
        -iname "文件名"       不区分字母大小写
        -regex "PATTERN"       以PATTERN匹配整个文件路径字符串，而不仅仅是文件名 （默认只支持范围，不支持通配符）
        -regextype egrep -regex    支持egrep同标准的正则
        -inum n   基于inode号查找（只显示名称，长列出则加-ls）
        -samefile   基于相同inode号的查找（查找硬链接）
        -links n   硬链接为n的文件
        -ipath p, -path p : 路径名称符合 p 的文件，ipath 会忽略大小写
        -empty : 空的文件-gid n or -group name : gid 是 n 或是 group 名称是 name

      根据属主、属组查找
        -user USERNAME       查找属组为指定用户的文件
        -group GRPNAME       查找属组为指定组的文件
        -uid UserID       查找属组为指定uid的文件
        -gid GroupID       查找属组为指定gid的文件
        -nouser        查找没有属主的文件
        -nogroup       查找没有属组的文件

      根据文件类型查找
        -type TYPE
          f       普通文件
          d       目录文件
          l       符合链接文件
          s       套接字文件
          b       块设备文件
          c       字符设备文件
          p       管道文件

      根据文件大小来查找
        -size  [+|-]#[U]   (常用单位       b,c,w,k,M,G)
        #数字 U单位 可省 默认为b b 512-byte blocks  c bytes  w two-byte words  k Kilobytes  M Megabytes  G Gigabytes
          #U       (#-1, #]如       6k 表示(5k,6k]
          -#U       [0,#-1]如       -6k 表示[0,5k]
          +#U       (#,∞)如       +6k 表示(6k,∞)

      根据时间戳来查找
        以“天”为单位
          -atime [+|-]#
            #       范围为大于等于#天，小于#+1天
            +#       范围为大于等于#+1天
            -#       范围为大于等于0天，小于#天
          -mtime，-ctime同上

        以“分钟”为单位
            -amin
            -mmin
            -cmin

      根据权限查找
        -perm [/|-]MODE
           MODE       精确权限匹配
           /MODE       任何一类(u,g,o)对象的权限中只要能一位匹配即可   （或关系）（“+”从centos7开始淘汰）
           -MODE       每一类对象逗必须同时拥有为其指定的权限标准      （与关系）
           注       0 表示不关注。
           Example
             find -perm 755   匹配权限模式恰好是755的文件
             find -perm /222  只要当任意人有写权限时
             find -perm -222  只有当每个人都有写权限时
             find -perm -002  只有当其它人（other）有写权限时才会匹配（/002也可）
      根据目录深度查找
         -maxdepth levels       设置目录最大几层
         -mindepth levels       设置目录最小几层

      组合条件
        与       -a
        或       -o
        非       -not，!
      德·摩根定律
      (非 A) 或 (非 B) = 非(A 且 B)
      (非 A) 且 (非 B) = 非(A 或 B)
      Example
        ! A -a ! B 等于 !(A -o B)
        ! A -o ! B 等于 !(A -a B)

    处理动作
      -print       默认的处理动作，显示至屏幕
      -ls       对查找到的文件执行ls -l命令
      -delete       删除查找到的文件
      -fls filename       查找到的所有文件的路径信息保存至指定文件中    配合重定向使用（> file）
      -ok COMMAND {} \;        对查找到的每个文件执行由COMMAND指定的命令，每个文件执行之前都会交互式要求用户确认 （交互式确认）
      -exec COMMAND {} \;        对查找到的每个文件执行由COMMAND指定的命令，无需用户确认  （非交互式）
        {}       用于表示find查找到的文件
    注意       find传递参数至后面的指令时是一次性传递所以符合条件的参数，有些命令可能不能接受过多参数，命令可能会执行失败，可以用管道接xargs命令规避此问题。
          使用-ok和-exec时，必须以“ \;”结尾
      Example
        find -name "*.conf" -exec cp {} {}.orig \;    备份以“.conf”结尾的文件，并添加.orig扩展名
        find ~ perm -002 -exec chmod -w {} \;        在你的主目录中寻找可被其它用户写入的文件，并取消这些文件其他用户的写权限

用find命令查找时例如命令find /home -name w*如下会出错，查文档找出
find: paths must precede expression
Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec]
[path…] [expression]
This happens because *.c has been expanded by the shell resulting in find
actually receiving a command line like this:

find . -name bigram.c code.c -print

That command is of course not going to work. Instead of doingthings
this way, you should enclose the pattern in quotes or escape the wildcard:

find . -name '*.c' -print
find . -name \*.c -print

出现这个提示因为*代表当前目录下所有的文件 然后被当作shell展开
也就是查找多文件的时候需要加 单引号


kill-----------------------------------------------------------------------------
kill -s SIGUSR2 $(pidof bluesky)  向blusky进程 发送SIGUSR2信号

kill PID  默认发送的信号是SIGTERM  编号通常为15  该信号可以被目标进程捕获 SIGTERM信号不一定能够“杀死”目标进程 可通过以下四种方式发送SIGTERM信号
kill PID
kill -s TERM PID
kill -TERM PID
kill -15 PID
kill -s 15 PID

kill -9 PID 发送的是SIGKILL信号 编号通常为9 SIGKILL信号不会被进程所“截获”，它只能由主机系统内核处理，由其负责提供可靠的控制进程执行的方法，SIGKILL会杀死进程。
kill -s KILL PID
kill -KILL PID
kill -9 PID
kill -s 9 PID

kill不能杀死进程原因
  1. 用户授权 若进程欲向另一个进程发送信号，发送信号的进程的所有者必须与接收信号的进程的所有者相同，或者发送信号的进程的所有者是超级用户root。
  2. 超级进程 root用户也无法向PID为1的进程发送信号。 PID为1，又叫超级进程，也叫根进程。它负责产生其他所有用户进程。所有的进程都会被挂在这个进程下，如果这个进程退出了，那么所有的进程都被kill。如果一个子进程的父进程退了，那么这个子进程会被挂到PID 1下面，即PPID为1。
  3. 内核态进程 当一个进程执行系统调用而陷入内核代码中执行时，该进程由用户态转为内核态，处于内核态的进程将忽略所有信号处理。如果进程在执行系统调用时无限期地阻塞，则可能无法终止该进程。
  4. 僵尸进程 进程停止后，该进程就会从进程列表中移除。但是，有时候有些进程即使执行完了也依然留在进程列表中。这些完成了生命周期但却依然留在进程列表中的进程，我们称之为 “僵尸进程”。
    a. 僵尸进程的产生 一个进程可能会产生很多子进程。这些子进程执行完毕后会发送一个Exit信号然后死掉。这个Exit信号需要被父进程所读取。父进程随后调用wait命令来读取子进程的退出状态，并将子进程从进程列表中移除。但若父进程未能读取到子进程的Exit信号，则这个子进程不会从进程列表中删掉。
    b. 找出僵尸进程 ps -aux | grep Z
    c. kill僵尸进程 通过SIGTERM信号、SIGKILL信号、SIGHUP信号来尝试kill僵尸进程。
      kill PID
      kill -9 PID
      kill -HUP PID
      如果僵尸进程没能kill掉，则可查看僵尸进程的PPID，找到父进程，令其回收子进程；如果无效，则可直接kill掉僵尸进程的父进程，父进程死后，僵尸进程成为”孤儿进程”，过继给1号进程init，由init负责清理僵尸进程。
        方法一，传递信号给父进程，命令其回收子进程的资源 kill -HUP PPID
        方法二，直接kill父进程，将此进程变成孤儿进程，交给init进程管理，由init进程回收此进程的资源 kill -9 PPID

kill -s 9 `pgrep httpd`   杀掉 所有进程过滤为httpd的进程
killall -9 httpd          杀掉 所有进程过滤为httpd的进程   killall后面的需要接完整的程序名称，否则会报未找到进程


crontab-----------------------------------------------------------------------------
https://crontab.guru/  在线工具
1 以配置文件方式设置定时任务
2 系统服务crond每分钟从配置文件中刷新定时任务 所有任务由 cron (crond) 系统服务来调度 这个系统服务是默认启动的
3 单个用户的定时任务用 crontab 来配置，系统级别定时任务的直接修改文件 祥见 文件栏

文件
  /var/spool/cron/用户名 或 /var/spool/cron/crontabs/用户名 # 用户级定时任务配置
  /etc/crontab     # 系统级定时任务，每行都多了一个执行用户，并且直接编辑该文件而不是使用 crontab 命令来管理
  /etc/cron.d/*    # 系统级配置文件脚本
  /etc/cron.hourly # 该目录下脚本文件在每小时1分钟后5分钟内执行
  /etc/cron.daily|monthly|monthly  # 这3个由/etc/anacrontab执行(ubuntu)  (/etc/cron.hourly/0anacron centos)
  /etc/cron.allow  # 文件控制哪些用户可以使用 crontab
  /etc/cron.deny   # 文件控制哪些用户不可以使用 crontab
  /var/log/        # 日志  如 /var/log/cron*  /var/log/cron  /var/log/cron.1  /var/log/cron.2
  sudo vim /etc/rsyslog.d/50-default.conf # Ubuntu默认不生成cron日志文件  把cron.*，把前面的 # 去掉
  sudo service rsyslog restart            # 重启系统日志
  sudo service cron restart               # 若还没日志，重启cron服务

service cron start      #启动服务
service cron stop       #停止服务
service cron status     #服务状态

/etc/crontab      #文件格式与说明如下
  SHELL=/bin/bash
  PATH=/sbin:/bin:/usr/sbin:/usr/bin
  MAILTO=root
  # Example of job definition:
  # .---------------- minute (0 - 59)
  # |  .------------- hour (0 - 23)
  # |  |  .---------- day of month (1 - 31)
  # |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
  # |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
  # |  |  |  |  |
  # *  *  *  *  * user-name  command to be executed
  前几行配置crond任务运行的环境变量
  第一行SHELL变量指定了系统要使用哪个shell，这里是bash
  第二行PATH变量指定了系统执行命令的路径
  第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，若为空，则不发送
  第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。
  用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。

crontab [-u username] [-l | -e | -r]
  select-editor            #更改crontab使用的文本编辑程序
  crontab -e               #修改 crontab 文件 不存在会自动创建 如果要停止某个定时任务 使用 # 将其注释即可
  crontab -l               #显示 crontab 文件。
  crontab -r               #删除 crontab 文件。
  crontab -ir              #删除 crontab 文件前提醒用户。
  crontab file [-u user]   #用指定的文件替代目前的crontab。
  crontab -[-u user]       #用标准输入替代目前的crontab.
  crontab -1[user]         #列出用户目前的crontab.
  crontab -e[user]         #编辑用户目前的crontab.
  crontab -d[user]         #删除用户目前的crontab.
  crontab -c dir           #指定crontab的目录。
  crontab -u username      #帮其他使用者建立/移除 crontab 工作排程  只有 root 才能进行该任务
  sudo crontab -u root -e  #便可编辑 root 用户的配置

crontab文件的格式       M H D m d cmd
  *    *    *    *    *    cmd
  -    -    -    -    -     -
  |    |    |    |    |     +  要执行的命令 最好使用绝对路径
  |    |    |    |    +----- d 星期 (0-6) (星期天为0)
  |    |    |    +---------- m 月份 (1-12)
  |    |    +--------------- D 月中第几天 (1-31)
  |    +-------------------- H 小时 (0-23)
  +------------------------- M 分钟 (0-59)

  特殊值
    * 所有，如对于 minute 来说，* 等价于 0-59
    , 数组，如 1,3,5
    - 时段，如 1-3 等价于 1,2,3
    / 间隔，如对于 minute 来说，*/2 代表每 2 分钟

问题
  通过 systemctl status cron.service 查看守护进程cron是否 running
  使用 journalctl -u cron.service 还可以查看更多的日志信息

参考
  man 1 crontab
  man 5 crontab
  man 8 cron

例如
  0-59/10 * * * * echo `date` >> ~/12345.log   #每十分钟写日期到指定文件



anacron       # 是一个程序，不是一个服务，以天为单位的频率运行，主动执行时间到了但却没有执行的定时任务

anacron [-sfn] [job]..
anacron -u [job]...
  -s   # 开始一连续的执行各项工作 job，会依据时间记录文件的数据判断是否进行
  -f   # 强制进行，而不去判断时间记录文件的时间戳
  -n   # like进行未进行的任务，而不言辞（delay）等待时间
  -u   # 仅更新时间记录文件的时间戳，不进行任何工作
  job  # 由 /etc/anacrontab 定义的各项工作名称

cat /etc/anacrontab               # 配置文件
SHELL=/bin/sh
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root
# the maximal random delay added to the base delay of the jobs
RANDOM_DELAY=45            # 随机给予最大延迟时间，单位是分钟
# the jobs will be started during the following hours only
START_HOURS_RANGE=3-22     # 延迟多少个小时内应该要执行的任务时间
# 天数            延迟时间            工作名称定义      实际要执行的指令串
1                 5                  cron.daily       nice run-parts /etc/cron.daily
7                 25                 cron.weekly      nice run-parts /etc/cron.weekly
@monthly          45                 cron.monthly     nice run-parts /etc/cron.monthly

天数(period in days)        # 当前与时间戳(/var/spool/anacron/)相差的天数，若超过此天数，anacron就准备开始执行后续的指令。@daily、@weekly、@monthly 代表每天、每周、每月一次。也可以使用数字：1 - 每天、7 - 每周、30 - 每月，或 N - 几天。
延迟时间(delay in minutes)  # 在执行一个任务前等待的分钟数，超过天数要执行任务，担心立即启动会有其他资源冲突
工作名称定义(job-identifier) # 写在日志文件中任务的独特名字(/var/log/cron)，通常与后续的目录资源名相同
实际要进行的指令串(command)  # 要执行的命令或 shell 脚本

实际发生
1 anacron会检查任务是否已经在 period 内被被执行了。若没有，则在等待 delay 后，执行 command 指定的命令。
2 一旦任务被执行了，它会使用 job-identifier 指定的名称将日期记录在 /var/spool/anacron 目录中的时间戳文件中。

anacron 的执行流程应该如下（以 cron.daily 为例）:
1 由 /etc/anacrontab 分析到 cron.daily 这项工作名称的天数为 1 天
2 由 /var/spool/anacron/cron.daily 取出最仅一次执行 anacron 的时间戳
3 anacron会检查任务是否已经在 period 内被被执行了，即步骤2与目前的时间比较，若相差 1 天以上（含 1 天），就准备进行指令
4 若准备进行指令，根据 /etc/anacrontab 的设置，将延迟 5 分钟 + 3 小时（看 START_HOURS_RANGE 的设置）
5 延迟时间后，开始执行后续指令，即 run-parts /etc/cron.daily 指令
6 执行完毕后，anacron 程序结束


cron                             anacron
它是守护进程                      它不是守护进程
适合服务器                        适合桌面/笔记本电脑
可以让你以分钟级运行计划任务       只能让你以天为基础来运行计划任务
关机时不会执行计划任务             如果计划任务到期，机器是关机的，那么它会在机器下次开机后执行计划任务
普通用户和 root 用户都可以使用     只有 root 用户可以使用（使用特定的配置启动普通任务）
主要的区别在于 cron 能在那些持续运行的机器上有效地运行，而 anacron 是针对那些会在一天内或者一周内会关机的机器。





at                     # 仅执行一次的工作排程
sudo apt install at    # 安装at服务
systemctl restart atd  # 重新启动 atd 服务
systemctl enable atd   # 开机自动启动
systemctl status atd   # 查询 atd 状态

/var/spool/at/         # 使用 at 指令产生的工作，会以文本方式写入
/etc/at.allow          # 在该文件中的使用者才能使用 at
/etc/at.deny           # 在该文件中的使用者无法使用 at  如果两个文件都不存在，则只有 root 可以使用 at 指令

at [-mldv] TIME
at -c 工作号码
  -m # 当 at 工作完成后，即使没有输出信息，也以 email 通知使用者该工作已完成
  -l # at -l 相当于 atq，列出目前系统上的所有该用户的 at 排程
  -d # at -d 相当于 atrm，可以取消一个再 at 排程中的工作
  -v # 可以使用较明显的时间格式列出 at 排程中的任务栏表
  -c # 可以列出后面接的该项工作的实际指令内容
  TIME # 时间格式，定义什么时候要进行 at 工作的时间
    HH:MM                       # 4:00，在今日 4 点执行，若该时刻已过，则在明天的 4 点执行
    HH:MM YYYY-MM-DD            # 4:00 2020-03-06 ，就在该时间点执行
    HH:MM[am|pm] [Month] [Date] # 04:00pm July 30，就在该时刻执行
    HH:MM[am|pm] + number [minutes|hours|days|weeks] # now + 5 minutes、04pm + 3 days 在时间点再 + 时间之后执行

at now + 5 minutes                 # 按回车后，输入要执行的指令
at> echo 123 > 3                   # 使用 at 指令会进入 at shell 环境，让你下达多重指令的运行
at> <EOT>                          # 需要使用 ctrl + d 结束输入
job 3 at Fri Mar  6 14:22:00 2020  # at 工作已经创建，他的 ID 是 3， 会在 2020-03-06 14:22:00 执行

atq                                # 查询目前主机上有多少 at 工作排程  与at -l 貌似差不多
at -c 3                            # 将上述第 3 项工作内容查询出来
#!/bin/sh                        # 可以看出来是通过 bash shell 执行的
# atrun uid=0 gid=0
# mail mrcode 0
...                                # 设置了很多环境变量
cd /home/lixiang || {              # at 在运行时，会跑到当时下达 at 指令的那个工作目录
         echo 'Execution directory inaccessible' >&2
         exit 1
}
echo 1234 >> 3                     # 就是我们要执行的指令了   at 的执行与终端机环境无关


batch                  # 系统空闲时才进行背景任务 会再 CPU 的工作负载小于 0.8 的时候，才进行 at 中的任务
batch                  # 例子
at> /usr/bin/updatedb
at> <EOT>
job 6 at Fri Mar  6 17:05:00 2020
[root@study ~]# date;atq                # 查询
2020年 03月 06日 星期五 17:06:25 CST
6 Fri Mar  6 17:05:00 2020 b root       # 时间已经过了，缺没有执行at任务   当cpu负载降下来之后才会执行



ulimit-----------------------------------------------------------------------------
ulimit [-aHS][-c <core文件上限>][-d <数据节区大小>][-f <文件大小>][-m <内存大小>][-n <文件数目>][-p <缓冲区大小>][-s <堆叠大小>][-t <CPU时间>][-u <程序数目>][-v <虚拟内存大小>]
ulimit为shell内建指令，可用来控制shell执行程序的资源。
  -a                 # 显示目前资源限制的设定。
  -c <core文件上限>   # 设定core文件的最大值，单位为区块。
  -d <数据节区大小>   # 程序数据节区的最大值，单位为KB。
  -f <文件大小>       # shell 及其子进程可以写的最大文件尺寸，单位为 Kbytes。
  -H                 # 设定资源的硬性限制，也就是管理员所设下的限制。
  -m <内存大小>       # 指定可使用内存的上限，单位为KB。
  -n <文件数目>       # 指定同一时间最多可开启的文件数。
  -p <缓冲区大小>     # 指定管道缓冲区的大小，单位512字节。
  -s <堆叠大小>       # 指定堆叠的上限，单位为KB。
  -S                 # 设定资源的弹性限制。
  -t <CPU时间>       # 指定CPU使用时间的上限，单位为秒。
  -u <程序数目>       # 用户最多可开启的程序数目。
  -v <虚拟内存大小>   # 指定可使用的虚拟内存上限，单位为KB。
  -l                 # 可用于锁定（lock）的内存量

ulimit -a            # 用来显示当前的各种用户进程限制
  core file size          (blocks, -c) 0                  # 只要为 0 则表示没有限制
  data seg size           (kbytes, -d) unlimited
  file size               (blocks, -f) unlimited          # 可建立的单一文件的大小
  pending signals                 (-i) 1024
  max locked memory       (kbytes, -l) 32
  max memory size         (kbytes, -m) unlimited
  open files                      (-n) 1024               # 同时可开启的文件数量
  pipe size            (512 bytes, -p) 8
  POSIX message queues     (bytes, -q) 819200
  stack size              (kbytes, -s) 10240
  cpu time               (seconds, -t) unlimited
  max user processes              (-u) 4096
  virtual memory          (kbytes, -v) unlimited
  file locks                      (-x) unlimited

ulimit -f  10240     # 限制用户仅能建立 10MBytes 以下的容量文件
  dd if=/dev/zero of=123 bs=1M count=11  -> File size limit exceeded (core dumped)

ulimit -n 2048        # 修改的是open files
ulimit -d unlimited   # 数据段长度
ulimit -m unlimited   # 最大内存大小
ulimit -s unlimited   # 堆栈大小

ulimit -c            # 查看开启或关闭core文件的生成，0为关闭 很多系统在默认关闭
ulimit -c 0          # 手动关闭
ulimit -c 1000       # 设置core文件大小最大为1000k
ulimit -c unlimited  # 设置core文件大小为不限制大小

对core文件更精确的设定 需要root权限
echo <pattern> > /proc/sys/kernel/core_pattern
echo <"0"/"1"> /proc/sys/kernel/core_uses_pid
pattern格式
  %% # 相当于%
  %p # 相当于<pid>
  %u # 相当于<uid>
  %g # 相当于<gid>
  %s # 相当于导致dump的信号的数字
  %t # 相当于dump的时间
  %e # 相当于执行文件的名称
  %h # 相当于hostname
除以上这些标志位外，还规定
1、末尾的单个%可以直接去除；
2、%加上除上述以外的任何字符，%和该字符都会被去除；
3、所有其他字符都作为一般字符加入名称中；
4、core文件的名称最大值为64个字节（包括'\0'）；
5、core_pattern中默认的pattern为core；
6、为了保持兼容性，通过设置core_uses_pid，可以在core文件的末尾加上%p；
7、pattern中可以包含路径信息。

sysctl -w kernel.core_pattern=/tmp/core-%e-%p   # 也可以完成对core文件更精确的设定

kernel.core_pattern=/tmp/core%p    # /etc/sysctl.conf文件中增加 若想重启依然有效的话
sysctl -p /etc/sysctl.conf         # 不重启也生效 /etc/sysctl.conf

ulimit -S -c 0 > /dev/null 2>&1    # /etc/security/limits.conf (红帽) 或 /etc/profile 重启有效


gdb ./bin ./core.pid # 进程挂掉 gdb调试core文件 bt -> frame
gcore pid            # 进程没挂 某个线程停住，一般是死锁或者消息接受超时
pstack pid           # 查看进程堆栈

curl-----------------------------------------------------------------------------
  例子       curl -i -X GET -H 'Cookie: mxsessionid={E842CEF8F8C04E52-0199-5948-C308-E66520ADD8E5}' -o /dev/null -s -w 'DNS解析       %{time_namelookup}\n建立tcp时长       %{time_connect}\n请求开始到响应开始传输的时间       %{time_pretransfer}\n客户端到服务器时长       %{time_starttransfer}\n从开始到结束时长       %{time_total}\n下载速度       %{speed_download}\n' http://192.168.8.202:8121/mxlogin.BSI
        curl --location --request POST 'http://127.0.0.1/gettree.BSI' --header 'Cookie: mxsessionid=1f1c22fa-1d7d-403f-921e-0bf336d1f799;' --form 'id=""' --form 'isClearEmptyGroup="1"' --form 'isGetTree="1"' --form 'MaxLevel="9999"' --form 'isTopnTree="1"' --form 'functype="netcfgmgr"' --form 'devType="Network"'
  参数有空格 需要使用引号把参数括起来 curl -A "are you ok?" http://aaa.com
  参数本身有引号的时候 使用单引号把参数括起来（不过在Windows中不管用） curl -d '{"name":"fool"}' http://aaa.com
  数据很多时，我们可以指定一个文件 curl -d @param.json http://aaa.com
  -i --include 输出中包含协议头
  -L --locatio 跟随302跳转
  -X --request 请求方式 GET POST等
  -H --header 自定义的协议头
  -o --output 输出文件
  -s --silent 不输出任何东西
  -F --form POST方式中 在内容发送额外的参数
  -K 指定参数文件 curl -K 11 http://baidu.com
  -w --write-out 格式化输出   或者指定 curl -w @12 -o /dev/null -s -L http://baidu.com   其中@之后表示文件 其他类型参数类似
    time_appconnect 从开始到SSL/SSH/等连接/手摇完成到远程主机的时间，单位为秒。(7.19.0中新增) #ssl才会有，http的话为0
    time_connect 从开始到TCP连接到远程主机（或代理）完成的时间，单位为秒。
    time_namelookup 从开始到名称解析完成的时间，单位为秒。
    time_pretransfer 从开始到文件传输即将开始所花的时间，单位为秒。
    time_redirect 在最终事务开始之前，所有的重定向步骤，包括名称查询、连接、预传输和传输所花费的时间，单位为秒。 (新增于7.12.3)
    time_starttransfer 时间_starttransfer 从开始到第一个字节即将被转发的时间，单位是秒。 这包括time_pretransfer和服务器计算结果所需的时间。
    time_total 整个操作持续的总时间，单位为秒。
    time_appconnect The time, in seconds, it took from the start until the SSL/SSH/etc connect/handshake to the remote host was completed. (Added in 7.19.0)
    time_connect The time, in seconds, it took from the start until the TCP connect to the remote host (or proxy) was completed.
    time_namelookup The time, in seconds, it took from the start until the name resolving was completed.
    time_pretransfer The time, in seconds, it took from the start until the file transfer was just about to begin.This includes all pre-transfer commands and negotiations that are specific to the particular protocol(s) involved.
    time_redirect The time, in seconds, it took for all redirection steps including name lookup, connect, pretransfer and transfer before the final transaction was started. time_redirect shows the complete execu tion time for multiple redirections. (Added in 7.12.3)
    time_starttransfer The time, in seconds, it took from the start un til the first byte was just about to be trans ferred. This includes time_pretransfer and also the time the server needed to calculate the re sult.
    ime_total The total time, in seconds, that the full operation lasted.

vi 11
 -i -X GET

vi 12
timelookup:  %{time_namelookup} \n
time_connect:  %{time_connect} \n
time_appconnect:  %{time_appconnect} \n
time_redirect:  %{time_redirect} \n
time_pretransfer:  %{time_pretransfer} \n
time_starttransfer:  %{time_starttransfer} \n
            ---------- \n
time_total:  %{time_total} \n





[root@bogon ~]# cat 789.sh     每三秒过滤8123的 WEB CLOSE_WAIT 数量
#!/bin/bash
for ((i=1; i<=5000; i++))
do
echo `date`
netstat -antp | grep 8123 | grep CLOSE_WAIT | grep Web |  wc -l
sleep 3
done
[root@bogon ~]# cat 123.sh     每三秒 用curl 登录系统
#!/bin/bash
for ((i=1; i<=5000; i++))
do
echo `date`
curl --location --request GET 'http://192.168.11.40:8121/mxlogin.BSI?username=TXDCGuAvaJyMZHiNmIo2wQdez7bBPnYK'
sleep 3
done
[root@bogon ~]# cat 345.sh     每三秒过滤文件句柄
#!/bin/bash
for ((i=1; i<=5000; i++))
do
echo `date`
lsof -n|grep WebExpress| awk '{print $2}'|sort|uniq -c|sort -nr|more
sleep 3
done
